{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0-XSTEWjMCc"
   },
   "source": [
    "# Stock Deep Recurrent Q-Network \n",
    "This notebook provides an implementation of a Deep Double Recurrent Q-Network which can solve Partially Observable Markov Decision Processes. This notebook applies the technique on time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cW8HdUyHjMCj",
    "outputId": "e2714934-2536-4799-e785-9e184c90dce8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed is:1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from helper import *\n",
    "from StockEnv import StockEnv\n",
    "import pandas as pd\n",
    "from GeometricBrownianMotion import * \n",
    "from MCSAmericanOptionPricing import *\n",
    "\n",
    "seed = 1 #time.time()\n",
    "random.seed(seed)\n",
    "print('Seed is:' + str(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\n",
      "True\n",
      "/device:GPU:0\n",
      "['/device:GPU:0', '/device:GPU:1']\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"So = 100 #spot_price #110 #90 #100 110 #127.62 #90\n",
    "strike_price = 100 #130 #100\n",
    "mu = 10/100 #risk_free_rate #0.001 #5/100\n",
    "sigma = 0.20 #volatility # the historical vols or implied vols\n",
    "dividend_rate = 0.0 #0.0163 #dividend yield of 1.63%\n",
    "num_seeds = 20000\"\"\"\n",
    "risk_free_rate = 5/100\n",
    "mu = risk_free_rate\n",
    "sigma = 0.20\n",
    "num_seeds = 200 #60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWJSeJ1K9zzu"
   },
   "outputs": [],
   "source": [
    "save_model_freq = 10000 #5000\n",
    "Normalization = False #True #False\n",
    "Window_Normalization = False #True #False\n",
    "test_data_ratio = 0.2 #0.3 # 0.2\n",
    "\n",
    "architecture = 0 #3 #0 #1 #2 #3 #4 #5\n",
    "nbFilters = 32 #16 #1\n",
    "paddingType = 'same' #'causal' # 'valid'\n",
    "huber_loss = True #False\n",
    "dueling_type = 'max' #'naive'\n",
    "mask_type = 'default' #'maskFirstHalf' # 'maskByWeights' 'default'\n",
    "apply_dropout = True\n",
    "batch_size = 128 #16 #32 #128 #60 #20 #4 #How many experience traces to use for each training step.\n",
    "memory_capacity = 10000 #3000 #1000\n",
    "learning_rate = 0.00005 #0.00025 #0.01 0.025 0.0025 0.0001\n",
    "apply_grad_clipping = True\n",
    "grad_clipping = 5 # Maybe test with bigger values, e.g. 40 or 30\n",
    "optimizer_type = 'Adam' # 'GradientDescent' 'RMSProp'\n",
    "\n",
    "Colab = False\n",
    "scriptDirectory = os.getcwd() #\"C:\\Code_RL\\2019_11_21_shuffled_GBM_version\" #\"C:\\\\Code_RL\" # os.getcwd()\n",
    "\n",
    "history_t = 15 #5 #15 #2 #15 ##\n",
    "option_T = 50 #65 #50 #100 #365 #100 #200 #365 #65 #30 #15 #40 #30 ##\n",
    "#build_warm_up_state_t = option_T // 3 #option_T // 2\n",
    "input_size = history_t + 2\n",
    "is_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"stock_names = ['hpq.us.txt', 'aapl.us.txt', 'goog.us.txt', 'ibm.us.txt', 'ups.us.txt',\\n              'jnj.us.txt', 'msft.us.txt', 'pg.us.txt', 'tsn.us.txt', 'usa.us.txt',\\n              'tex.us.txt', 'sam.us.txt', 'salt.us.txt', 'tlys.us.txt', 'trq.us.txt',\\n              'trno.us.txt', 'trk.us.txt', 'tnp.us.txt', 'tjx.us.txt', 'tpx.us.txt',\\n              'fb.us.txt', 'jpm.us.txt', 'v.us.txt', 'bac.us.txt',\\n               'ma.us.txt', 'hd.us.txt', 'tsm.us.txt', 'dis.us.txt',\\n               'intc.us.txt', 'vz.us.txt', 'rds-b.us.txt', 'tm.us.txt',\\n               'cvx.us.txt','wfc.us.txt', 'nvs.us.txt', 'ko.us.txt',\\n              'mrk.us.txt', 'ba.us.txt', 'pfe.us.txt', 'cmcsa.us.txt',\\n               'sap.us.txt', 'chl.us.txt', 'ul.us.txt', 'bud.us.txt',\\n               'un.us.txt','wfc.us.txt', 'mdt.us.txt', 'hsbc.us.txt',\\n              'mcd.us.txt', 'nke.us.txt', 'adbe.us.txt', 'crm.us.txt',\\n               'tot.us.txt', 'ptr.us.txt', 'cost.us.txt', 'bp.us.txt',\\n               'pm.us.txt', 'amgn.us.txt', 'abbv.us.txt', 'hon.us.txt']\\nstocks_train_data = []\\nstocks_test_data = []\\nreal_stocks_train_data = []\\nreal_stocks_test_data = []\\nfor stock_name in stock_names:\\n    #train_data, test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\\n    train_data, test_data, real_train_data, real_test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\\n    stocks_train_data.append(train_data)\\n    stocks_test_data.append(test_data)\\n    real_stocks_train_data.append(real_train_data)\\n    real_stocks_test_data.append(real_test_data)\\n    plt.plot(range(len(train_data)), train_data, color='b')\\n    plt.plot(range(len(test_data)), test_data, color='r')  \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"stock_names = ['hpq.us.txt', 'aapl.us.txt', 'goog.us.txt', 'ibm.us.txt', 'ups.us.txt',\n",
    "              'jnj.us.txt', 'msft.us.txt', 'pg.us.txt', 'tsn.us.txt', 'usa.us.txt',\n",
    "              'tex.us.txt', 'sam.us.txt', 'salt.us.txt', 'tlys.us.txt', 'trq.us.txt',\n",
    "              'trno.us.txt', 'trk.us.txt', 'tnp.us.txt', 'tjx.us.txt', 'tpx.us.txt',\n",
    "              'fb.us.txt', 'jpm.us.txt', 'v.us.txt', 'bac.us.txt',\n",
    "               'ma.us.txt', 'hd.us.txt', 'tsm.us.txt', 'dis.us.txt',\n",
    "               'intc.us.txt', 'vz.us.txt', 'rds-b.us.txt', 'tm.us.txt',\n",
    "               'cvx.us.txt','wfc.us.txt', 'nvs.us.txt', 'ko.us.txt',\n",
    "              'mrk.us.txt', 'ba.us.txt', 'pfe.us.txt', 'cmcsa.us.txt',\n",
    "               'sap.us.txt', 'chl.us.txt', 'ul.us.txt', 'bud.us.txt',\n",
    "               'un.us.txt','wfc.us.txt', 'mdt.us.txt', 'hsbc.us.txt',\n",
    "              'mcd.us.txt', 'nke.us.txt', 'adbe.us.txt', 'crm.us.txt',\n",
    "               'tot.us.txt', 'ptr.us.txt', 'cost.us.txt', 'bp.us.txt',\n",
    "               'pm.us.txt', 'amgn.us.txt', 'abbv.us.txt', 'hon.us.txt']\n",
    "stocks_train_data = []\n",
    "stocks_test_data = []\n",
    "real_stocks_train_data = []\n",
    "real_stocks_test_data = []\n",
    "for stock_name in stock_names:\n",
    "    #train_data, test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    train_data, test_data, real_train_data, real_test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    stocks_train_data.append(train_data)\n",
    "    stocks_test_data.append(test_data)\n",
    "    real_stocks_train_data.append(real_train_data)\n",
    "    real_stocks_test_data.append(real_test_data)\n",
    "    plt.plot(range(len(train_data)), train_data, color='b')\n",
    "    plt.plot(range(len(test_data)), test_data, color='r')  \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value of data: 50.55108446618011, max value of data: 75.71320001340916\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 160.41750891209688, max value of data: 232.0053569320216\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 117.39052913848273, max value of data: 239.65281150191407\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 61.68717100789021, max value of data: 93.3981808897496\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 56.87545268912853, max value of data: 90.88754177619106\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 94.06358565243866, max value of data: 245.37303421922587\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 129.93675878153329, max value of data: 232.31137151669466\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 129.9534825322404, max value of data: 258.1770676311054\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 35.20913894154504, max value of data: 65.18331821536977\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 101.39621501443278, max value of data: 159.54608974168164\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 162.61745200633712, max value of data: 289.41747349894536\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 74.1227187551618, max value of data: 146.9048689726847\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 58.28755258481948, max value of data: 117.47007576272676\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 120.73998326364462, max value of data: 248.91561167359893\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 51.870723592789105, max value of data: 101.84733307434726\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 61.763316116879416, max value of data: 114.14460153595954\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 122.0976750411443, max value of data: 204.82192967437015\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 172.8307076337207, max value of data: 277.7232810155937\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 69.02469259777676, max value of data: 95.05863406211094\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 80.30002210669456, max value of data: 155.22139996208327\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 130.06822347846474, max value of data: 287.54747254546055\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 192.35973116377357, max value of data: 299.9797803495469\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 74.4695148777661, max value of data: 170.2562557086905\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 104.18639662032017, max value of data: 167.74138657916143\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 95.3582186897327, max value of data: 288.6465513661703\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 142.2879579412418, max value of data: 240.86826761860183\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 162.50628507972561, max value of data: 448.78829838423997\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 72.42495029320605, max value of data: 113.77240785322473\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 111.33461867597589, max value of data: 196.0581497082629\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 101.12033624621186, max value of data: 277.0036094253246\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 106.40327280958459, max value of data: 201.6937526111208\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 120.03455410952766, max value of data: 197.23176456636926\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 130.49515682501604, max value of data: 283.0980110838277\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 110.10791571939971, max value of data: 157.0394416462132\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 63.726343163387405, max value of data: 133.89338811114152\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 135.087971896783, max value of data: 194.75921480190055\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 57.43249393049274, max value of data: 83.55199124233059\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 154.4395565331445, max value of data: 261.5228459633382\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 108.18888569074292, max value of data: 182.3210159028102\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 76.85304041530713, max value of data: 125.01599630803486\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 122.48177590176051, max value of data: 314.0912345573345\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 142.94089734569235, max value of data: 411.5629522805149\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 87.57205619653513, max value of data: 123.25785528336135\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 63.81624653030204, max value of data: 138.87407596076386\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 81.83229963548187, max value of data: 114.3112220260568\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 112.3339279668143, max value of data: 245.57090338983718\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 69.97572612218099, max value of data: 133.39421698505217\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 58.06493299398143, max value of data: 123.13471644287766\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 136.3707382370677, max value of data: 189.2744250171474\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 86.50076295759276, max value of data: 137.69370467523188\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 50.29573981702655, max value of data: 90.95983649239555\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 123.97395770807307, max value of data: 185.5400638329749\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 155.8004299603986, max value of data: 269.3345070918139\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 179.79847017885749, max value of data: 397.0678439031538\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 79.95632709982871, max value of data: 152.84367833986036\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 73.90494738148726, max value of data: 122.62091203225977\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 90.05001226239112, max value of data: 160.38107390794187\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 36.6303011149387, max value of data: 66.64377895337711\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 45.52349361662141, max value of data: 90.01651126870374\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 133.11741082696895, max value of data: 221.14951529776368\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 145.08556883059236, max value of data: 224.77990369483206\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 48.389693359738274, max value of data: 70.06650037407222\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 117.22198590648556, max value of data: 166.89164415787218\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 184.812590692264, max value of data: 385.47214129721283\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 169.07258977252775, max value of data: 261.970059239397\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 94.19382490679594, max value of data: 145.11832958569133\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 166.94128617700014, max value of data: 236.1314973547528\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 81.37252756500024, max value of data: 132.71741046568025\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 74.51109034610072, max value of data: 111.82673040677788\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 61.603231820672576, max value of data: 94.6047405628399\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 127.61535572854977, max value of data: 302.970447130219\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 51.95531481560235, max value of data: 161.7027155780683\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 137.43718592964825, max value of data: 285.09556403775946\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 55.34679634118422, max value of data: 79.18392902514401\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 180.40201005025128, max value of data: 369.1862320082132\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 39.61706656354847, max value of data: 72.02560199636807\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 64.82147525262653, max value of data: 136.3944347975968\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 46.71578322762698, max value of data: 70.06545747121811\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 53.220619094506695, max value of data: 82.03012378550287\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 40.71023490550947, max value of data: 53.92932110146881\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 97.46683575996006, max value of data: 151.58854374833567\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 100.72923239943299, max value of data: 276.08106247993646\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 67.18755589377986, max value of data: 127.41377095363416\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 112.74628904361093, max value of data: 366.867420031071\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 151.68741205249185, max value of data: 421.2113843794178\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 133.66576415623067, max value of data: 213.5506707289966\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 95.80531789077246, max value of data: 221.4928961091726\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 150.84702397328533, max value of data: 288.1759671929826\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 83.8600982994072, max value of data: 154.9611055157746\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 92.16941768632032, max value of data: 130.98141125511253\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 48.04897910251737, max value of data: 72.03113313235542\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 61.04035677738481, max value of data: 99.29858184854024\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 91.54982992948514, max value of data: 177.3839579880631\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 45.88885028736087, max value of data: 74.70256708722648\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 69.12344144483173, max value of data: 113.70906495870797\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 52.878777953340716, max value of data: 91.01764270078725\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 155.71813521301254, max value of data: 472.07881403908044\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 58.31649006535755, max value of data: 93.15843999971837\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 36.53280690426879, max value of data: 98.92378215905383\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 73.28904913671795, max value of data: 121.76404244613975\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 144.8928914513805, max value of data: 312.50105623853807\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 77.42582707068361, max value of data: 162.70533444551316\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 119.90705869590275, max value of data: 211.21143696204788\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 122.3962073980726, max value of data: 200.2756606432389\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 133.8593729141564, max value of data: 236.77429909723827\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 136.17394061139834, max value of data: 254.2470071026088\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 177.19917202946374, max value of data: 325.9417751256182\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 76.72518381525703, max value of data: 126.50502854244583\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 62.43007473801602, max value of data: 81.43294577369316\n",
      "train_size: 743\n",
      "test_size: 185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value of data: 65.81878233954379, max value of data: 123.13336838242353\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 129.75919449158962, max value of data: 297.5782815189494\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 107.20941103954466, max value of data: 175.71647684991703\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 113.55693080213581, max value of data: 203.7149842060761\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 104.34672031943305, max value of data: 180.31041192358717\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 160.99363232055768, max value of data: 249.0386496152161\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 31.28416003503076, max value of data: 64.79461891409876\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 110.25013747453391, max value of data: 215.74940391091883\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 97.63925797801754, max value of data: 264.52166485449385\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 176.16707811915666, max value of data: 333.06819287743\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 50.31275750016771, max value of data: 90.47507798922747\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 72.61507754267953, max value of data: 126.10243257825478\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 37.66059137586361, max value of data: 84.42491508385788\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 120.27641067941983, max value of data: 187.95133060324198\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 78.26540749320638, max value of data: 132.09175503181794\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 52.26130653266332, max value of data: 104.37908319099631\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 145.06090276461327, max value of data: 270.3896765553696\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 168.15603729029849, max value of data: 385.1328010889352\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 179.6991059364167, max value of data: 301.8235053109573\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 127.31481119807711, max value of data: 227.51434330967498\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 170.91435824284528, max value of data: 366.12010683502103\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 72.8811800158935, max value of data: 101.81813776996648\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 54.31995795202487, max value of data: 101.68318219489177\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 81.6310851509863, max value of data: 202.2912738770003\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 69.20905576106334, max value of data: 210.3165386303053\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 75.6601840657818, max value of data: 108.70903675111036\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 83.96346817847505, max value of data: 148.30818831029856\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 141.1347439101807, max value of data: 207.0661597349018\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 170.51919325334157, max value of data: 454.96528249896966\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 135.70918985287278, max value of data: 284.1525872986346\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 139.235726554772, max value of data: 248.60763407018942\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 113.44942137316572, max value of data: 239.72881025441276\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 72.7540839562092, max value of data: 146.91714682809985\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 126.4150876258856, max value of data: 277.3558053666696\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 178.5390602760942, max value of data: 371.4252978345242\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 180.87446172613406, max value of data: 326.208934870905\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 44.19917717275642, max value of data: 76.59735269586632\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 124.00698080554704, max value of data: 222.40760776175298\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 74.44562809186398, max value of data: 165.77572077710965\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 49.36151415728396, max value of data: 82.27239403263717\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 101.2250203379136, max value of data: 284.9251888941833\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 57.25295276371069, max value of data: 149.30368240652567\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 90.93174790170883, max value of data: 157.59145096111465\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 95.20020524911295, max value of data: 204.39357608093786\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 89.58492685511544, max value of data: 155.3766771470686\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 78.18590557616965, max value of data: 142.30321061999567\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 106.29806168925282, max value of data: 174.8253565157384\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 84.4976699234519, max value of data: 128.89113144650608\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 108.77340731471352, max value of data: 185.48315448025463\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 187.51106943870218, max value of data: 504.3618438694861\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 123.16434530808712, max value of data: 193.36002889416167\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 74.18599503832695, max value of data: 165.83354358919536\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 60.76476316010792, max value of data: 149.72079441466028\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 123.87433611486108, max value of data: 275.6959410499721\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 138.35615080612948, max value of data: 302.1886985821918\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 63.92391038750283, max value of data: 102.91124143555368\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 136.79428448847708, max value of data: 284.95195360257793\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 48.92477566865407, max value of data: 92.73684922573361\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 87.73488510334046, max value of data: 142.43863610035052\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 79.99340873489997, max value of data: 162.01807868049855\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 190.08438769050454, max value of data: 337.4627862480816\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 146.05649021468898, max value of data: 220.50590979475763\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 45.97779356746825, max value of data: 87.4712925297993\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 112.5783162659565, max value of data: 223.41064138423712\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 104.14753088036113, max value of data: 291.6383024691855\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 170.2822511166909, max value of data: 386.80505748990737\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 109.29376831323926, max value of data: 160.8419739292777\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 139.07143783838444, max value of data: 238.6354321123026\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 145.0792526539348, max value of data: 493.71826439722554\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 118.40554474445254, max value of data: 182.87014857771305\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 107.17704560092749, max value of data: 205.28594510162122\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 148.74371859296483, max value of data: 249.56245115139154\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 70.69270851981415, max value of data: 119.76514614834507\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 126.58989616423136, max value of data: 184.34192168675278\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 99.09746015930872, max value of data: 207.61777792034073\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 51.159381105556115, max value of data: 120.78578367376592\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 59.33227364269413, max value of data: 123.0347989324063\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 73.50629801869935, max value of data: 122.07448683759432\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 185.00192071718854, max value of data: 329.98823613806996\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 161.25001961997847, max value of data: 370.8190053661807\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 143.0131741458352, max value of data: 236.9968829160791\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 69.28625346925665, max value of data: 115.63522803531589\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 92.73240157112161, max value of data: 123.60951155991822\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 87.03709852281355, max value of data: 177.38143409886692\n",
      "train_size: 743\n",
      "test_size: 185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value of data: 101.2696130728169, max value of data: 203.14626914118196\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 43.81193076015413, max value of data: 109.56940531644427\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 89.0243542854382, max value of data: 153.03421267209765\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 117.68866946678845, max value of data: 182.73931328362562\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 105.99864066267097, max value of data: 182.91659679162893\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 181.98674479880574, max value of data: 569.0112275945369\n",
      "train_size: 743\n",
      "test_size: 185\n",
      "min value of data: 125.64229401508895, max value of data: 229.2135004855168\n",
      "train_size: 743\n",
      "test_size: 185\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOxdd3gUxfv/bAqEhBICoYQQIPTeEQQBAQFBKYqAHQQrYvkpCvYCFuzY9SuKIiIWBBVRilIFBASkd6R3Ugik3fz+eG+c2b3du727vVzKfJ7nfbbNzs62d2beqjHGoKCgoKBQvBAR7gYoKCgoKDgPxdwVFBQUiiEUc1dQUFAohlDMXUFBQaEYQjF3BQUFhWKIqHA3AAAqV67MateuHe5mKCgoKBQprFu37hRjLNHsWKFg7rVr18batWvD3QwFBQWFIgVN0w5YHVNiGQUFBYViCMXcFRQUFIohFHNXUFBQKIZQzF1BQUGhGEIxdwUFBYViCMXcFRQUFIohFHNXUFBQKIZQzF1BQUHBiOPHgRkzwt2KoFAonJgUFBQUCg0yMoBq1Wi9c2egVq3wtidAqJG7goKCgox9+8T6TTcBs2b5PiczE3j1VSAnJ3Tt8hOKuSsoKCjIOHlSrC9fDgwbJrYffRTQNFrfvl3sf+cdYNw4YOLEgmmjDSjmrqCgoAAAp08Dn30mmHtqqmeZyZNp+b//AY0bA7/+SttnztDys89C3UrbUMxdQUFBAQBGjiRaupS2//gDuPdeWl+2DLh4UZSdMoWWO3eSjH7mTNo+cgTIzy+wJnuDYu4KCgoKAHDAHWBxxQqgfHkgORl48kna17UrMHq0KPvPP+Kcn38GDh6kMvn5wNGjBdtuCyjmrqCgoAAAkZG03LQJaNqUZOtVqojjX37pec5rrwHXX0/rd99NyyNHQttOm1DMXUFBQQEA8vLEetOmYn3kSH25CROAb74BBgwQ+6Kjhcnk6dOha6MfUHbuCgoKCjk5wI4dYltm7lOnAhcukFy9alXghRdo//z5oszgwUDlyrReSJi7GrkrKCgovPmm3ka9SRP98VdfJeb9xBNiX5kytBw8mEQ2lSrR9qlT9q+7Zg3gcgXWZh9QzF1BQaFkIy+PmHvPnmJf48b6MjVqACdOCOsZAOjTh5ZjxwJRUUB8PC2PHbN33Q8+AC65BHjppeDabwHF3BUUFEo2DhwgCxeuGAWApCTPctx5ieOqq4iRX345bUdEAA0bAlu3UofhzSTy7FmhgJ09O7j2W0AxdwUFhZKD7Gzg66/1ytNnn6Vl/fpiH7ec8YWqVfXbLVsCa9cCHTsCzZtbnycraX/6yd61/IRi7goKCiUHM2YAw4cLT1MA+PZbWhrl7IGgWzeaBaxbB2zbBnTpYl6O28K/+65nB+EQlLWMgoJCycHOnbRctUrsa9QISEwkhen//gcwFnj99erpt1esMC/XtCkpU++6K/Br+YAauSsoKJQcbNlCy61bxb6zZ4Wz0qhRek9Uf8FDBcswiwt/7hwx+IjQsWDF3BUUFEoONm+m5b//ChPEc+eAihWdqd+Mud94o+e+tDSyrgkhFHNXUFAo/mCMRCb79pH4JTeXsi2dP+8so61YERg6FBgzRuyLjfUsd+4cUKGCM9e0gGLuCgoKxR/r1gF79tB65860XL4cKFuWGH/16s5cR9PIGufpp8W+rCzycOVgjDqZmjWduaYFFHNXUFAo3vjuO6B9e7HNmft774l93swWA0FiIiXw4GaWhw+LYydPkpy/USNnr2mAYu4KCgrFG0OGiPXGjUXArz/+EPtbt3b+umPGAJdeSuucua9aJUwfW7Vy/poSFHNXUFAoWti9G4iJ0QfuMsO0aUDv3mI7NpasZBo2BOrUoX3ly5OSNS4uNG1NTqblCy9QQLF582g7MZFCD4QQtpi7pmn7NU37R9O0DZqmrXXvS9A0bYGmabvcy4pS+Qmapu3WNG2Hpml9QtV4BQWFEoj69cnT9NFHvZcbMQJYsEBsZ2WJdR4yoHdvfQRIp1GjBi1/+w3o3x/46itS6B4/LgKPhQj+jNwvZ4y1Yoy1c2+PB7CIMVYfwCL3NjRNawJgOICmAPoCeE/TNJu+vAoKCgo2sWkT8Pbb5k5Hubme+3ioXkCE5+UjeKcwbhywcqXYLldOrK9eTbOOU6c849SEAMGIZQYCmOZenwZgkLR/JmMsmzG2D8BuAB2CuI6CgoKCgGxlct99lDhj5EiRJg/Qe37OmkUdwIQJYl9mJi15gg0nkJ5OoYG5wjbMsBt+gAH4TdM0BuBDxthHAKoyxo4CAGPsqKZpPB9VDQCSby8OufcpKCgoBIeNGylfqYxhw2jZpAmNnAFKsAEAt90GXHedZz2PPkq25rfe6lzbDh0y31+7NrB/v9j+5RfnrukFdkfunRljbQBcCWCMpmldvZQ1m294zJs0TbtD07S1mqatPXnypM1mKCgolGh4k7PPmCG8TnnArjfeMC+bkkIJNsqWda5tsrljRoZYlxl7TAzQt69z1/QCW8ydMXbEvTwBYDZIzHJc07TqAOBennAXPwRAts5PBuCRMZYx9hFjrB1jrF1iYmLgd6CgoFB8wRhwzTXA+PFkM/7rr7Rfjr3OsWGDYObnzgGDBpE1TEFBHrnv3m1e5uJFalsBwCdz1zQtTtO0cnwdQG8AmwHMBcDnNLcCmONenwtguKZppTVNqwOgPoA1TjdcQUGhBOD0aUpm8fLLwDPPiP3Tp5MjUJRbssytUubOpdH73r3OytPtQGbuR9zj2WXLPMv99VeBNMfOyL0qgOWapm0EMemfGWPzAbwE4ApN03YBuMK9DcbYFgCzAGwFMB/AGMaYl5QkCgoKChYwytcBsjSJiKB4MN9+C7RpQ7L4tm1puWcPmT2G0sTRDDJz5yKaL7/0LLd0KbU5xEzep0KVMbYXQEuT/acB9PQ8A2CMTQIwKejWKSgolGxw5h4TQyINgEQ0HAMHEgFkDTNkCPDJJ7RdkMz9zBng99/J03XzZiGWqWFiSzJxIi27daPAZSEyi1TJOhQUFAov+Gi4XDlyXDp2TNioG9GrF4lpXnmFtp3IrGSFHTuoHZUq0XaHDjRjuOEG6oh4kg5ZsWrEhQvAwoWUmo/Hk3cQKvyAgoJCgWLLFr1JulccPEj5TE+eJOVqfr51gosKFSiWi8tFQblCFS991y6qf9Qo2n7vPRFxsnp1Erls3kztzcigUANG9OtHy969g0sO4gWKuSsoKBQYtm8HmjXzY1D91VfE0Dl27SJG//775p6pPPG0HE/dadx9Ny3nzqWORr7Www8T409Pp1lGerreS7VFC2r7Qw+JfXL8GwehxDIKCgoFBm7BKId58UB2NjkhJSR4DvF37ACef57EGV27esrVR4wgE8hQjdpPnwYWLaJ1Y+cydy5lYuKhfJOTge7dyRzz55/JcubZZ4FSpfRp/ho0CElT1chdQUEhYOT7YQfncon81DxHhinefRe45x5g+HD9/ipVKNTA+vW0LTNIGaFMX7dkCS2vvVbsa92aRuhXX03bjRvT0uUCFi+mDFD9+gEvvkiMHdAnB/nf/0LSVMXcFRQUAsIvvxAfnTvXXvlJk8SIPTMT+OADi4L//qvfTkkB1qyhUAK//06MFNB7foYa58+TbJwz9ZtuouUnn1BnI4tekpIEowdI0WuE3AG19DBGdASKuSsoKASEGTOIScu+Rd7wzTe07OoOXnLPPRYF//mHRsM8ANeTT1ImpbZtgbw8IoBEJAWF5cuFiSVA5pdHjlCHY4SmkeMVh5kzlWz+OHasc+2UoJi7goJCQOC89e+/SRRuhYwMkkb88w9tv/iiOOYhmtm3j0QZHTqQm/7gwcKaxJjntCCZ+5YtYv2VV4g5e8u7GhkpFAzcXNKINm0oSYg86ncQirkrKCgEhDNnhPf/0aPW5Q4cEOHV+/cna0UutZAVq9OmAZ/c5fbavP56SmjBU9IBpKyUES7mnpJi75z33gM+/hho1878eGIiKYRD5MSkmLuCgkJAOH0aSE2ldS4GN8O2bWKdm3z37+953uefA1i3lja6d6ekFjJzT0oCoqNpvWVLfRTGUGPzZmrT/PkUyMwO4uNp1mHFvE+etHbIcgCKuSsoKASEU6dEIqO0NPMy+/YBQ4fqzwFEsMbLLqMYXwDpTHtF/q6vQGbuZcqQDGjBAhJ1bNhgfWEnkZVF123fHujTR0xXgsHnn5MiVr4/h6GYu4KCgt84eZJE4q1b07bVyN0YG+v++2nJmfuePcCbb5K+sl3m76h1Yq3+BKM8umlTkt8sXgzk5NDoONTimS1bSK7UqZNzdT72GC3lrFIOQzF3BYUijg0bRI6KgsLq1bTk/O7MGc8yFy4IZg6Q5SK3CpR59uzZNIL/F5Ism5sHli7tWbExsbRZWF0nwePb1K7tXJ0dO9JSDoLmMBRzV1AoonC5KMBg69bAc88V3HXz84VCtGtX8i367jt9u/bto1ADx46J/QkJYl2WRnDeuRduAX7FipRk+vXXzeXbxiBbPK5LKHD+vGhDcrJz9e7eDVx+uWdH5SAUc1dQKKKYPZtMwAGRoKggsMqdIbl3b5KKjBoFbNpEfHD/fgq9kpoqGH7PnuTzI4/WGzYkMfbp07JFoYb18ZeDNW4MxMYCDz5IJoVGnD+v3961y3uDDxygqcHx4/7fLM93mpDgnPJz926KO89TAYYIirkrKDgIxkhpmJkZ+mvJnqEFlLkNS5YInvTtt7Ts2JHue+NGUrB+9BHtn+TO6PDjj8AXX3jW1aoV8cxt20jm3qwZEJV9Hpqv1HhG5v7hh97LjxpFF5g1y3s5GWfOkJXL00+TAvX4cedMFrlnrZnnqoNQzF1BwUFMn07mfiHyS9Fh5kyxvn27d3PEYPHXXxSviwdEvP12cY9t2tCSy+GN8CV5qFCBnFEzMoCE6AzfSaszMykJxuefi31yFiQjeKAvf14Knw1s3Ur29U5YyAAk07riClo3S+ThIBRzV1BwEPPmiXVvjj3BYM0aSjhkDNrFM7o9+CDw1FPOXnPcOKpz2zbg0UeBt98Wx2rUoFE4z00t4/bb7V/jxAmgXP45YsLz5gGTJ9OBCxf0SS/OnycRyfXXi9juNWuS52iPHjTKvuce4L779D2LP1Y18uzAmyeqPzhxQq+cCDFzVyF/FRQchBwPavRoYM4c5wZ9HIMHU1gTLiUoW5YGs3v2EMN/803an5wM3HGHdT2Zmd4HyefPUwyv668nkQvHFVfojVg0DXjiCepwOMqX988EPTcX6HHhJ1TAUWJ63MspNhZ49VWq7OxZukEu/4mK0psJPfIILYcPB/74w/MiJ0/ab5DcEVSsaP88b5C1yPv3U8amEEKN3BUUggBj9J8ePUrOOAcOAM2bk4HFvHki25pTuHiRGDu/NkBMOiKCfHseeECUnTuXeN/SpfoYLn/8QVFpy5XzNDTJygLWuk3Nhw2jpBoyYweEGEbGNdfojVj8tRpMSwMWoSdW9X2GpgYcY8fSQ+VKhV27aHvYMNrm4XVlWHmuvvwyvSjZhMcKnLnfcAMwZYrt+7DEypVivVw582BiDkMxdwWFIPDRRzSITEoC6tYl8W7nzpRrAtD/007AStTjcpHFyjvviH0ZGSQn79aNIjdqGg2IL7+cZPQAnSPjnnvIEfPoUWEowlGpEo3QzQaymibyVI8eTUpUf5CWBlxEGewY/jRNJ8ymFOfPUxgAgAKLAfooZBxmI3Qel6Z2bRKz8HqssHUriXQ++4xMe4LF75Lnrbe8qg5CMXcFhSAwZ45+OyeHsq5VqEA8hCenCATXXw/07avfZ1SaPvGE9flLlwqLFm4HL+sEAOH6L58DUGdldIwaMYI6Cyu89RaFAf7oI/uxtTi4CKdCBfcOM1nWvn0iPR3PdmQWcVE2HVq2jBgrjy+ck0NL3rtZYdUq8tDisWyChWyG2aOHM3X6AmMs7NS2bVumoFBQmDWLsWrVGHv0UcamTw+8ngMHGCOBh544unRhrHNnxo4etV/np58y9uyzjF24IOr7v/9jLDeXjn/7Le1r04axdu1o35Ej5u3wRg0bivXVq8X1a9b0LJuczNirrzKWkRH4s/KFn3+may1dyhjLyaGNCRP0DXnuOc+HvHat+Q1eey0dS0sT+zp2FOuvv27dmIwMKhMXx5jL5cwNDh3KWIMGjG3ezNi//4r9GzZQGwMEgLXMgq+GnbEzxdwVChAnTnjygXnzAqtryBB9Pc2aMTZunDh+zTXi2MCBjOXnm9ezZQtjp04xduiQKH/ZZfq64+OpDN+uUYOxYcNEHX37WjPy2rXF+vXXM6ZpjO3fz1ifPnpe+f335ufPnx/Y8/EHjzxC7UpLY9QbAoy9+y5jZ87Qg2vcmLGEBNo/ZIg4MS+PsXvuYaxpU32jn3iCjk+bJva1ayfW77zTujGpqaLciRPO3GDXrtTby8jMpBd55ZUBV6uYu4KCG3yEaMYH/EVqKmOJicR0Fy70PH7HHfrrHDliXg/AWJUqjI0da82gAeoE5G2ZP82YYX3eX38xtmcPY+npNBC9cIHO6dFDz9xvuMHz3O+/D+zZ+AOXi7HKlamzYYwxtnEjXXzWLFHopptEo5Yu9azk/HnG+vdnLDJSlPv6a/3NNGqk3/6///OsZ/FifZmtW525yZQUxm68Ub9v2bKgH7I35q5k7golCgcPeu6zYzxhxI8/krz6/vtJ7Nuzp2cZozjYzPudm1OfOEGZiozKygMHxDq39OO47DKx3qyZWJ81SzhtNmpEJpGpqWSkoWnCAk8Ocnj2rLk5d/36nvucxqlTRP/pF/iD4sHfAb2NqTFpB0Amkz/9RMTBLWrq1qUHwZj+nGnT9Nvp6Z7y8J9/tn0flrh4kZysePB7Du6p2qRJ8NcwgWLuCiUCWVmk6HvtNdpOSqJlfLw5w/cFrtczKjxlyLwJMO9Evv9erP/xh/7/f/55UkzydJwyn2nThqz0OJo2Fev9+wvnoe3biWkbHZ4AsqDhIQI2byY9ZFIScOONooxTFnvHj4tY7kZwZ9AGDdw7FiwgRWaLFqIQj+fQq5f3Hqd3b8997dqR01OVKqSBXrCATJzOnhX5WPPzhSerjHHjvN6XJRgj08u33yajf5dLRILk4MzdX+2z/TYosYxC8cb27Z7ihj//ZOy77xi76y7GSpe2r9Nav57Or1uXsfbtvZc9c4axSy8V13zsMcayskiRe/IklTETEdWqRet5eVTmr788y730kuf1fvqJ6uaQy69dS/t++IGxgwdFmX//peO33MJYuXKMNWlC+0+edFbWDjBWqpTn/nnzGJs8mY5v2uTe2auX58MdNIgKffut74ulpzNWsSKVT0wk2fagQfTSPv+cHux77wnRDX/AsuKidGmxnpPj/w3/+qvnSxs7lo5lZTH2+++kFa9a1f+6JcAJmTuASAB/A/jJvZ0AYAGAXe5lRansBAC7AewA0MdX3Yq5K4QS//uf53/G8cMPtC1bjBiRlcVYp06MvfEGdQYAiXbNRLZGHD6sv265crScNImOA4y1aqXnI+fOkXKVQ1a0cvr1V9/XLlVKlB88WNxrs2aiTF6eXkxdv77vev1Fbq6o/8AB/TH5nk6dcu+sWZNk7DK2b2fs6quJUdvBggXE0LnM/PbbxYV+/JGsVrhy9pVX9A156y166VOn0vbu3f7fdK9eni+Nf3j33iu2GzXyv24J3pi7P2KZ+wFI2RAxHsAixlh9AIvc29A0rQmA4QCaAugL4D1N00zidioohAYvvECi1ylTKA6Lt1Sb3D/lt9+AkSNpln76NM2geU7k+fOBP/8kW/H582lffj7FU/GFpCS9zwpfz84WEoFrriEZ+Y03kjSiQgV92JFq1YABA/T1WolLMjKEKffGjcC779L67NnAoEG0vnkzhW3Zu5ci6sq6AWPARSewY4dYl+PPyObokZHueO/5+fTCjC6uDRuSy21cnL2L9upFN809WGVHpB9+IDlW377kCCCLXuLiyCa+TBmS1QP+x4s/fRpYuJDWNU1vKz9hgt7TzOnYFDKsuL5MAJJBDLwHxMh9B4Dq7vXqAHYwMWqfIJ37K4BO3upXI3cFfzF/PmPLl3vuz8/XD5SiooTVyqefMvbLLzQo48jO1pdfvJixK64Qogp51Fy9OmNlytB6dLS19YsZzAZx779Pyzff9H0+b0dEBA1geR2y6ISbh193ndh38aL+mvJovmlTTwvC22+3f092wa9RvTpZGHHTcdlEvWlTd2HZDNJJLF0qLpaY6Plg5FE9x8GDoi0LFjC2a5c4tmkTY8eOmV9rzRpRX7VqjJUv73md11+nF7VtW1C3hWDFMgC+BdAWQHeJuZ8zlDnrXr4D4CZp/ycAhpjUeQeAtQDWpqSkBHWDCiUH//xDjNUoXuHgMmSZunQh0YcV5LJt24r1e+/V+80YmaSV3boZpkyh2b9sQs1p6lTf519yiXk7OnSg4xcvMjZxovlziY+n89euJacts3u57jrSQ1y8aP+e7IJf58UXaXn2LO3/6SdxrHNnd2Gu1HDaBtPlopdw/fVU/9y5ng/ivx7GDeNIQX6wAHl3ybjzTsbuu4/kd7x83bo0Ihg6lLEdO8T+9HRHbiso5g7gKgDvudftMPd3TZj7td6uoUbuCkasXs3Yb7957n/8cf2/ZmSw991nzgT797e+VvXq5ufUq0cdA8DYqFF6ZggwNmdOYPd25oz+Ot995/uciAj238hdPjcxkeTmrVuLfa1b68+9cEE8J5eL7OXHjxflo6Otr3v+vP/6xCVLSG/AGL1HgPjd55/TOh8A9+8v2tC8ufvkOXNox6pV/l3ULn780fNF85G12Qs1lv30U33HwHH6tPkIgY9E3niDbpzvb9eOsZkzg+5Ng2XuLwI4BGA/gGMAsgBMV2IZhVBBHuBwqxLG9Io5Tjt36s8dOtScUd9xh/X1ZE9NTrKOrVUroho1aFs2qggU27cz9vDD1FH88495mfx80uVxb3jO3KtVo+Nvv037Vq4Ux/kI3w5Dlj1sjV72Lhf5EPHjZk5aZuBtuftu2h43jvjbmTNkGcPb++GHom5NY6xSJXcFfPrh0MjWA3l5ni97+HDrDmXtWvIwM/uo+AcwZQqFO+D7+Ici0zffMPbyy577H388qNsJWizzX2H9yP0VAOPd6+MBTHavNwWwEUBpAHUA7AUQ6a1exdxLLjZv1jscfvWVPr7J33+TXPzwYRFXhe8HPE0Cu3Qh1/0pU/T/0OTJ1m1o3pyx7t1JPg+Q+ODcOc//kFu1cMfHChWCv39voUu4sYaReEwZPsh97TVaLljA2AMP0PrVV/u+dl4eY/36UfnnnyerIt4eM/GNHXDRC5dw9OxJVo3Z2cJaR+40ALLeARh7fzQJ4V2lS9u7mC+cO0dyqzfe0O+3YtRyzBcjxo5lLCZGX75aNXpgZnVFRjL2wQdiu3t382nlLbcEdYuhYu6V3ErWXe5lglTucQB73KP7K33Vq5h7yYT8XzCmH7FzWrLEM4bLBx/QuQ0bEvOQkZpKbvSMMbZ3rzjnjz/M27B+PZkn3n03zZojIyleFWOkfDWTdZ87J8Sqx487/1xOn6ZR/WOP6a/LtzdvpnLcPJt75m/apB/l24l5tWmT/hrr19M9mfErO/WNGEFlS5UiGT5AZpi80zGjrl1p2ae25JDgDX/9RSMCLtJwuainkzXljOmD5Tz7rNj/zjskiuEjdoDs2j/9lNbHjqXgOzKef96z4XFxnraunFq08BwhdO1KCpDbbmOsd2/a95+yITA4xtxDRYq5l0zs3y+++6++Iv2U8R/58Ue9hQcgHI4GDdLrwFwuGlw9/LDYx8/p1o2Y4O7dNNPu3l1vbjxxIpWvWZOxm2+mdVmMymnQIDq2cCFtL1zoXOBADm7dI8/077yTOrmaNcX1zpwhkUblyvqOhlv7cLm3L8j39+ab5jFmAHu29ZxnyTR6NM2OONM3Hucjd4CxObXv01us+GpwZiYpZwDGnnySepTx46mckSFfvEgf3Usv0fbdd4tjv/8uvMc4/edVxRj76CN9R9ChA60/9ZT5wxoyRDhecapWTTwImW67zd6LMn0UirkrFEJYRSH84gv63uV9kyeToQN3/mFMML9bbyVRCVdUytFcp07VM0krmj2bynfsSKP/efP0YXEfeoiWDz5I5Y4d058frIiYO0dVqMBYnTq0npgo6m/ZkngP71w45Ci23KP1iy/Evnvv9S1/N85OkpLE+saNwgzz5Zd930fHjnrnTv7seJCym2+mTlbWczRoINb587WEHOURoGBcDz9M6/JIXDZ9lEcQ8vbjj4sOYMwYGlUbz+HeZFyWxGViLhcFAzNquLnopnNnWhrrlD+qatVoqaJCKhQ3xMV5/kszZtAxY4zyBQs8zx89Wl/mmWdoOXYszdw5zDxUZbr9dpIJ3323kLvL9P33FPn1+utFbHajqHXJEnG9NWtoQJmfT5Yqdkb2vjofTkavWFkxyWH0fP/mG+/XPnOGsS+/1J8zaJAIWcAY8aGRI33fR+PG1BEZ281H7HzAK5OmifX33nPoQXHmCniaJwEkzzt+XG/BYkY8ZOjs2bQ9ahTFWuYxE6yIT6c4cZMs3pPJTH7UKN8P1vJxKOauUMjATYirV9czI47MTLGvQwcyyTMiK8v7/3X0KDHWbt28l2OMbK+tjhuZ87p1QonJiYc8WbSItuUZ/7Rp3p+Fmcm1Fb3zjv5cfj352RnDFXzyia1XonMqMloFdu9O5topKSSJYIysdeROjTEyFOED6AoVfN+PUUyzaJGXBnKNrD/Eg/Xz7RtvpODx/INyufQdAUCB+N96i9bvvZcUrbm51LvxmDSAXp4EmI9WjMSZPLcLBbzHlvcBxdwVCh0++0wwK3mULuP110nJ6g1jxniO4OV/hg+4eJ4HgMwchw4lMUfNmlSPLN4wkizWcLkYi42l/ePGkbEDv4/Dh80Vh0alL8fatUKZCJA5oBxjvWZNYtRyso2fftLXsWeP+bN78UWh9DWGEbeCPBsxWgUaxWRypijGiIceOcJY2bL0DIYNs8d75QEs4Bl75j/k5OjlVKmpwiEJoFRRxsrlePCvv05mVEa78ijGILsAACAASURBVLw84TgFkHyP9+aNG+s7CYBu0NsNVa2qD9ZjRpddRjFv+LYxjo4fUMxdoVCAB4ZKTxff9ZdfCqYShOiR3Xor1fHII6LuJk2I+QNi9l2rljgnN1ekr5M9xOvW1f+LK1dSmW3bhOkgQDP2vDwafcojdSPVq2feZrkMT9Kzb5/gKaVLk7hIdrKSRSWMiZADRubOUaYM8RrZvNtK0ZqfL+7PqNM0WtXwPBP8OfNnC3i3jDES7yg53XdvvmCuaWk0/fruO+FcwF9Uq1YkbvnpJxqFW42aH3mEpkZ16pD5lBFcDv/iiyKLCQf/eAB9Wi1/ySiXB0jO98wzdF924k9YQDF3hbCDh9t46SUxau/fX8yOjx71/Lf8QVYWjfr27aO6q1Qh55kWLShAH2M05ZedojhcLmKkY8fSIGr7dpJlX3UV+2+Q+O23ekuQevWoE2CMscsvN7cC4Xq+iAiS68vm1sbQJtx8kzESwfIBIleOPv+8db5Xb8xdtoHn5QYOpHs0Qrarf+wxz+ODB4vjRqWpTGZ5WPv188xMZaTLsYilR1agvKKMeQa+AYRSJClJNMzMRMeMuNacQ45/UL489fTTp9MHypje2L9+/cCZOyDCgXKSs0TJ9+InFHNXCDuMSrY6dZw3IWRMeJfL1hhPPun9HJ6b1GwAJfutyHFheMyZqVOFbbdMpUvrfViMDJjPJLhliiyXb9aMRDnyeStWWLd/2jSyyTe7r5076XzZkITTsWN0H/feS4Pb//s/2l+jBpmlGq1sTpzQZ7vzhzi8dQop2M8YwPJfeZUKWxWsVImYPI+pYBwZG2U9nGRt7fnzniIWWTyTliZGIU7QxInCRhXQT1lGj7Z+uT6gmLtCWOFy0axZlnvff39ornXPPVS/HLvJVwLsTz6hcmZ5IMzk+V9+aW3G+fLLwvLEzGudg4txvv6a5P916hA/SU8n65FnniGzwPbtabbjT5AyxoQl4NNPW/Mbzsw5DRpE74g/j7//9qzXGEXTDslRKp98Un/sww/14V5OoDJzRUYKDyiZ+APlvSlPXm0UyZiZPAFCE8wYJcowHn/hBbH+3HP2ZwR2SP74jRRIvHg3FHNXCCu4TfiUKSTCAMTM12lcdx1Zm8nersb4MzJkRyqz0CLy/w4IWXR2tucotGJFOuZyeZo3V61Kx0eNEnkijNS/vxCNmI3E/cE773jW37273kKvXj3PMvXqidH+xx+b183LynUZc08bOzzGiBcbj735pl6RuxsmYTNlkh/65Mmedu9WlJpKio1du4QTk7/kS1EaKD3ySMDvWTF3hbCC66yWLiUaNYrc5J1Abq6IBcMYmT1edpnemsPMweiTT0iOLYs+5exHHB9/rOcrsijp1Clxfu3aZCLJceWV+v+XZ30DrAeWnGJj7SccsgK35ONUrhyJspct80wSNHGiiHV1ySV0jxUqWFvobdhAZfk5HTvqY8wDZC3DLZBSUug5yYpWrqN47jmq85tvGGsDQz7BqlWdYZ69e4vwnmYkG9qHg7hSKAAo5q4QVowZQ8zFX9GCHfBgYvfeS9uNG5NhA2Pi3zGCBx2T6aWXzHUAy5eLMlZOPDymiwwepmTQIJGUw4qMesPevelZ9e5NTl3jxumDq9nBhAme15Etbaza0qMHHee80MzAhNvlc3+cAQNIeS3zyAED6HpcYmLkn0ePkpRFjtY5aaQPh6JAqXZt4Q1a0CQrm2680fO4pimZu0LRREYG6a06dXKuzvx8sgI5dUrI1ocOpcQ5ERHC0mP6dBotGiFbfQDCDNEKb75J5aZMsd/GrCwKL7JuHZkhtm9v/f8/8AAxQ779wQfC6kcmX+BK3jlzyEooJYW2OV+TlbZmhigAjbZPnBDnmsW1uu8+ml3wMoHQ5s0k9pbNX7OyGHONsnBasEP+ik2MUR7tkGxrb4eaNBG2td27m5cJAoq5K4QNPMnF8OHO1Ldxo7CrvuEGYYDQq5dQcq5Z470OrnR95hkasZuJY2S4XGRGGczMIzubEldw0USfPmSOCNAI9+xZkrNzHaFZTglvgcDMYt3XqEHOle+/L3JGVKpE95Oc7OlgCZCuQI7FExVF4Rtk9OpF8a8iIvQGIFbZoowDVYB8igYOpDb++KMUo0t2gpBp5ky9EwOgT4phxlTNzJhksuNRGizVrEneXYcP682t5CBl/KUHAMXcFcIGPr03s7wIBFbi0erVRYJ7nsbNCkOH0n8WDrhcZL1z3316MdC+fXpXfqMi19szPHvWPH5O794iP0SlSmI/D4J22WXmDFl2zOT0zz/Eg2RmLus2ZT7pLezAY48JvmY0j83Odt/Qnj36mC9ffEEOCs8845mKyxuZRWDkDybUTJ1TbKyQbck3LJsq9esX8PekmLtCWJCbS0wlyHwE/4HnTjYSj6gI0IDNDBcvkpKSe7IG4fEdFGQLv7g4MRvg+xjzjHPFww/8/LN5nQMHej6TN94gfsi3jT40nNq1s8ejzAJ+8eiVRkZv5e9Tvz69A6souXKwN7Znj6h08WLhjZWc7OnWapaA2h+ySt/lJDEmRu6PPUbXTE6mn+O11wL+nhRzVyhwXLggvmVf4bnPniWd0qefeh7LzaW4JmvWMDZ/vuc/M3UqDYzi4mhUaZZMx+XyFJUGmv80WBjbz2PP8+3sbL0DVmamMNds08ZT6ctDnhjp7Fl9nC2jRMOK/PGyN+tUGjQQvHfMGNIDvPQSWQvxXBqy4+eVVwprxv+CohkDhC1Zop96AHo7TFlhEQwZe0BjZEd/yOhYdfYs6QQiI2m6VK4cLRcvDvJ7UsxdIQhwU8ZbbiHm8tBD9NMaZdDp6YL5/PMPnVO7tm9PVHmG6nKJ8i6XiGFSvrzwjhw5kmT5Bw+KOrKzra9jZEL16lEijlDg4kXK+8Db//77IgsUj4QJ6HVr3EMW0FvsDRxI5+XkCFHJV1/RNfr1sw5RzJ2G5H08lEIwJOsrjUppI73/vvUz4nb0AFk71a5NdZfCRfZt64n2GmAW74GTMYwvz/0XTjLGVJbJX1MoCYq5KwQF+Tv85Rex/t13okxaGhkfDBlCo3Yug+WMzgoZGULZB5AjUcWKZCfdv7/nf9CyJTE3mbH7qt/sfzImvXAKXES0bZuweClTho5xb3ae2JqTMeIsJ9nWPT9fhCrwxagfekjfkQCekgxvVK6cd89WO8Tjzqel0azB6IR58CCVe+IJcc7lWGhdoRw9zRtFRNAFWrSg7euu00dgDIRSLRyr/LGPNwsexonb7gYAxdwVAoYxRaRsoHD77aLckiVivzxL3rLFe/085C0PsuWL1qwh++ioKBrxnjnjvX45OxogLG0Aspqxi7p1zYNpGcF1Zj/8oE8GJAcK40xeVk4ayey5eROtyArNLl2oc7HLd/r39x7zJRDi9vLyoFkO35ybS7xR1m2Wh5RzdM8ez/CcdohnSjp5kirv0SP4kfv06WTLy7f9NYf0Rl272kg/ZQ3F3BX8wp49Ih8nT6TxwAMizlLduiRWuOQScQ63VDGSN/GHHK52yxbv/8ATTxDD+ktyYuQZ0j7/3PoavvjD8uUkDpUzPWVl0WCPQ04c4guyG74cl0pOGMIVitwu3UjLlon6XC7iTdu2Wc9CzMiOCTdPuH3kCHmIGgeo3gabZsTvnTuW7t6tz8fKc9NyVK5M70e2rvmvosxM+4pSWcaVkECJbTdvpqTYfL9ZqEo7dMMN1DNPmSLi0bRubV1eHs1z7b03io8n+VqAUMxdwRIuF9mHV6hAbuhyCOuVK8Uoc/duoei78Ub6HuPiROhYo8nxoEHeRTL5+fqIq75c8rmybeZMz2OlS1vnCbXiD5Mm0bJxY2ExwtvLR5M8HLFsZvjiiyS2OHaMZg2TJtG1XS7PoFi+aNUq8/1yuAQu2omJsbYW4mSVtMSKMjIYe/RRvcjEznlm5uGaJmZh3LyyXz+ayfAYNl260DVHj6b7ateOOhA5dEFujLtyMxl1mTJ6Ex3OHPm6MQaCTAMHBjbijooSPZS38wcOJEcEf2YJXBuu4rkrOA1vqeU4cRfzBg1IoVmjBjF92ZP6q688xY/ff299XV/p8QCSu7dqRX4obduSRyVjJE+OivJU6L3wgud1XC5ql/GfbN+eBmPGDmXiRP0z6dNH5E4F9B6Zl14qRqgDBnjyHDvEGMnojYYgL75Ix2bMEJmeAN+Dz6uv9hx99+ypNwJp2ZJs3+UZTadONFC2817skFHE9tBD5qaURqoKH72XkVJT9aMRs6mQv9MPTsaXYkbcQ4+/TA6zrFDe6N13A/6HFXNX8MCKFeZy1h9/1MvPAf0Uf/FiMer1RrJYgzGyZjl8mNaNgas4yTHHZfPJBx+kQVt+PjG4q67SKww7dKDZuNF6h1tlyGnqNI3O/+QTuq+ICGJuZcrQvyor+ADa9uYIaUZ2B4gcOTmeURzNPE5lkgOReaPNm6kjkvfJeVdluu46/+7Tivr1038zv/7qO580wFgv/MayEe3fxSZ6sa6xoqio4GIn8Dp4/OOOHT1/MG/xJow0YkTA/7Fi7grs+HGyl168mAI/cS9FI2Vk6FNTAsJKwx+aPJkYCzdP5H4icrRGIx04IP4JGTwnMbeE46FoFy+m2C3vvkv7d+wQDP6cpJurV49o8GDzEWRmpp4BtmkjLFp4ZEO7zBQQ0RK9UWSkaKucB5XTkCGB8x0zatyYTDIB83DAAHX2ZhZKdvgcXzczDbfzPADGNOSx22HIcCJ7mZoZ1pv1pHasWCpVCsxTtUwZmg7Vrk0vb8sWc8WSrGzwRcoUUiFQZGR4mgXL0/09e2ikeOwYlbey/LJLmiaY5dixejvu334T6y1bkmnlypWk1GOMmH9amr79p0/r6zdmJeJKX4DipTCmt0RJTBQe3mbM67339KIEHktdHvFzxhgI8Wf/0kv6nA0//0ydH++82rXzj6n7E+hw4EC6Vtmyetn8hAn6ULzeIuPaJW/hB3xRTilJoM9lgqEif1PnGUU8Zo4VLhd9xDffbL/effsC/rcVcy+ByMwkObScO1OmFi0occZ/8TzcyMsz/8HLlvWtMKxVS4yiORMzDqJk/ZdVvKQVK+g4Nz2UkzsDItE2h9x5AOYzbh4SWI7Pzv/X++4j5ens2SJ0rywWadRIzAQCFeHWqmU+A3r4YRrkVa9OfMFKKWrm3i9b5/miAQPo3uRnY0dUEmp6/XX99naEmKF7o1KlaGQu7/PmIDBiBE2DOS5eFNMUb9lLjNS/f8D/uWLuJRBmgaeM1KULMTEZZnE/4uJoRMnDe8jEmTlAFmIyA/M2A0hIsG67XC43V8xwExIozWVOjqd83UrMxJnxL7+Q7o1bdHCKjCRFJL9unTq0LusdUlMpyFawvMNbEMIaNTwZnRWNG+ffdSMj/RMr2SWeVSsQ4p0+T+kHMBaFHJaDKObydbJZOEs7D9kXjRpFPTzgmV/VG3HIcRU42WHyffsG/J8r5l4CYZasAfBMHfnKK1R+wQKy+ZatKD78UAxc/vyTxDdGqxA5V6mRvFl33HuvuZfp+fP6cnfcIdZnzqSMPvXq0ag1P5+sW7gpozcnRl/haPv1E+u//EKWOt7KV6sWWAIff3hPRATFXTGaS0+ZYm46apYWVI4s6wQ9/zzpLk6eDF58Z6R62OnfCWZyqWC8sfbs0cdGsEtXX6133eahOAGaKlq5IHPissQAEBRzBxADYA2AjQC2AHjWvT8BwAIAu9zLitI5EwDsBrADQB9f11DM3VnISsOdO0WyiVGjSMSx0ODlLYfQlgcs/N+RjQEGDfL+nVaoYF90UaMG1XnmDHUssvjFKnKgN2rVigZBTjIcKzJLfm2HNM13x2GkFi2ok+XM+5ZbfPsFmF032HueOZPe14UL9K6MoYEvu0x4/XPyh9feho+Db2SgVL483ZwxboNd4h99+/aeFgm+iLvzBoBgmbsGoKx7PRrAagAdAUwGMN69fzyAl93rTdwdQWkAdQDsARDp7RqKuTsHX16MmZmUHELe5y0xO0CydsbIMgUgpsyDiRlp4UKKFWM3KU5aGgUCA/QxV4yDMtkowtg5cZLNjsNNZoYdnMzipRc2evJJmiHI+1avFsmsb7hBz7hbtiQZfmwsvTs5GJxdqoV97BB8xJDxV+nhrVcbNkxMTbt1E84Zr73mGQte9oaz+mEqV/aM12yklBTGxo/X72vVKuD/3TGxDIBYAOsBXOIelVd3768OYId7fQKACdI5vwLo5K1exdztIS+P4otYKdc3b/bN4KpXFyFWvQXWk2nbNqrfyqR42TIKAdCqlT5euR368ENhR85FPka77Pr19d6sWVmhkSH7S8YIsbJttxxXxo4pqbEz7NLF2RAmgZDxfX//PcX28XVeMOIaW4WCyYcaF0cPu1cv0ugbj3NlTufO4jqJiSQL9NWxxMeLuNRWComPPvKUbX7xRcA8IWjmDiASwAYAmdII/ZyhzFn38h0AN0n7PwEwxKTOOwCsBbA2JSUl4JsrSeBhdFNSaIQ+dCgx+hdf9HS+AfTp0o4dE1Yw3pzv+PfLM5SNHy/iovToYX5OdraI1c0TVnMqVUovYjHm7hw71lMObVR61qunj+Iq/2N2xA1W/6S/KTe9kTGWi8z4rfKVeiOjeCNUNHEiYxs2eC8jG4yYdTj+MvOEBHMFdSlQdDWfClUgcMUp/7hee83cG+/qq0mLX7kymS4984z3j8hfMpu2rVsXME9wcuQeD+B3AM28MPd3TZj7td7qVSN3e5BtxLkc3UhVqzJ2//20fuQI5RzldttmSZfNqFIlMao3G3VaxWt59VXPTuauu+ja3PaZ65rKl7cnj23YkJYrV/r3f8XGEvP2Jpu+5Rb/6rQqW7q0/3L0UJE/dupVqohvi/NKf7LY8TpWrQos17Rx5piK3YwBLJ/veOop8wdrt1c2M7h/9FFazplDYhmATKN4ABxAmIW98oo+Up1d4nEp7FL79gHzBEetZQA8DeBhJZZxHvn53pM7c3GKHUpO9jzf5XImacOOHfrUdt6Izzg3bybmv38/jbbteo074VRjRXJQKztkNUsoX554RbDtSU31HsXSDk/btEkvLo6KMrfqS0ggyQHH/PkiVv6gQb4V54GQNwtGgLFu+F2/49w570kufJHZ6KFrV+rJuH0tj6WeleXpNLVli++fLj7e0zZe/jB8KbQA0pQHiGAVqokA4t3rZQAsA3AVgFcMCtXJ7vWmBoXqXqVQtQc+YPj9d2KEkyaJeOU7d+rTr3F6+WVKnGxM9N6ggfk1gnVc4bkQGKOUdmZlZJHCzp3m7cjN1Ts0FTTxUXggVjlm5E96OjPSNOrcfenj/CVfis1ly4jfvf46MXaOYLxMZYq2GSqmVy/GGmOz2JGURA3hcYmdIuNUbtUq/Ye5YgUx/6FDqayZ5UtEhGfGFTNKTBRmVd6coXhUvAAQLHNvAeBvAJsAbAbwlHt/JQCL3KaQiwAkSOc87raS2QHgSl/XKOnMff16MrHlSS64WAUQYg0+7W3WjL6rF17Qe2oaR3VRUbRfduc/cID+GeMPZ2YLvWmT+Xf455/6ti9YQLlPebySZs3oXm69lTooMw/tM2f88xFxmoLNpxwqOnaMlt5Sd5oNEqOiAtcfyIPbxo3FOwr2XvyNHNCyJWN9YUgIO3Kkf1M3f5Ub5crRB7p7NymOVq/Wx4b3Rl9/7dyL95aQwAccFcuEgkoyc09L8/7eGzemRAp8e8gQzzq2bxfH9+2jH3bSJDrGnXO47NpI8fGkNzp0iCw85BgqsbF6UcTw4Z7Xzsuj7EZcqSZHUFy+3Pyeg8k77AT5k3IuUJLl82bORYGSWcaqAwf0IZgB6xHzvfd6HpNnUB99ZG7DL3cCmuZdkZ2crI+B74vkGD4fD/3Ns0BkJFVqVUEwtqVyiFJvvb4T5llWShtjDkI/oJh7mLF0KWNTp5J3nxHe7KG9/UDcOoUxMlEDyH6dMRqArF5tP3OPHAvd2NnI7RszxrP9csdiFHGOGEFtys+nDqRv38AcAL2RXXNOM/LXEcgfksU0Zu8xkPjvZmTsxH2RmTe8/ByCcfD0lgbQSFY6R1e+S8/tOfkz1TML/Wk02i9M1KlTwLxFMfcwggfB4iRn2XG5hJUC19vYjRTKA2ExJixnTp4kZScvY/eH556HHMeOkahlxQoxa2jRgmYFxlg0Zs5MxlnC2LHh/384vfOO3kTUX8MGJyjYQSCPFVOnDom4zp8niYQ/oQacNrWsXZs6cSvxkBwaQtOs88cyxvw32QFE6jtjpEc+LeGxmznJcYiTk0Ucjauv9j+lVbAUGRkwf1HMPYwwMrpevWj/+vXCvnjqVNp39iwt5RC2VlSqFPlg8LAVcXHUWXjz7zCOcvmIbfVq6/bzxA41a9K15FflclFIbONs1kn78VDQ00+b7zeal/q6D6t4NQV5//K13nrL3jkJCd6Tc/tDpUvTt8dFdlazIR7PH6Bw6Hx9xgzh76NpjB2Zvsj7FMDuiAWgxuTm6sUhTZqQXHDGDGFWxJ0S6tenjDLGDyHQ/Kt2qXr1gPmLYu5hBGcAs2aJd8kjNvKp+7//ivLHjwuZdIUK+hkmV6bxn0P+kfjMjncmcrx24/mA3i45Koq+9TFjqO5z54Sy1swihjvxffFFaL/5UJP8PF5/ne5JPm5HNu9LvOKU+MUOLV3qnK+NXeIhlG+4wXuaPivHOXnwEwNDBfxm5Bch9wy+PNi2bPF8qZxcLnPPv3BQqVIB8xfF3MOErCwa2Tz0EA0Y+LuUZ4Q8xGxamj58rpHi4/XiBPkbBxi7807GPnAnsTEblVmJAri9udl/smSJiCUiE4/DbmRcgwfbcxx0yswuWOJ5WG+6ie5Hzt5kl/wRsQwdStfyVc5O+k6ZPv204CUJZmSMXukvdcUf5geM8iZvzgAyrV9P9p2aRgxUzjBuJtcPF5lZSdiEYu4FjI0byZyRWwwsXqwXBcpT6ZEj6Zx777V+9/ffT4rIrCzGPvvM87gvJZgxBgqniAjvPiIREeZOT6tW6b1lOV19dcFFZQyEJk0iRmjczzNQrVzp/XxfXpgLFnh31Nm6Vaxfeqnne6lfnzrx777z776uvdbajybcZBRRebN7T8YBdgF+anR797ZWnHTqJGRwXbqQ+aKVc4aRzLzbnAitaUZlygTMaxRzL2BwufdVV9HIzuWy9oSMiDA3BNi6lezFX35ZpHrMzCSRiJVZo10qV86e45wVOe1qL4sSnBArGOO6c5vryZPF7IbTvHnkC+Ard2gguUWNJJsY5ucLByPOM7j0wTgrKynUE7+x7bCZ+o5/KPfcQz/dE0/QA/b1oqyyuoSC7AbdSU0NmNco5h5ivPkmBdjiML437pziD82Z46kAjY2lvJt2pvbeyN9pf1Ej2db+jTf0fgIAdW7cU3fYME/vXjPyNvsB/O9wx461Lxlo2JD41ksvhf/ZhpIaYJu9h2F1zF/b1mrVCoeM8LnnAuY9irmHELJMetEicnST31v9+vZCvhaEK35h9cx0irp100/7e/XyLgf29V6sREyPPEIKaLtGFFWq0OwhMlLErjeSt5g/EyeGTiJQmCgK2ey5xLcozKlVIac/YlkZFi4yhkDwA96YewQUgsKcOWJ93jxgwABaT06m5b59wLFjvus5d875thmRmRn6aziFmBjPfdWqee575hmxvmQJ8OKLYnvhQmDaNOtrHDnivQ3z59OySROxr1MnqvPKK4H69b2fz1GrFtVRrRqQkmJepl8/8/2aBjzxBHGB4ozSpYE8lML8lDuB3butC6anO3vh6tWBjh2drdNfPPVUaOq14voFSUV55M6jI9qxEjH6UQBkOeNtVDZkCC2TkshLedMmEcclFGSlEAwmGbI/FBFBeoqrrxb7rBSZL71E7+Dzz33Xm5ISeJu4d3v9+vqEzoHQd9+Zh0vh0Wft0Cuv6Le9WVmF+l35e46vGcjs6GsDa4wTGcyB4FyeAyVlLVM4kJHB2N69FFMlK8s7U7fjMWjGdGQFa4UK5DIeHc1YTg61YdUqffl69UKfus2f0LiBkpVTkFl2qUOH6FlkZ3t2SH37eo/n0qCBZ7BBX/dXqxZZ4Fml+HOaJ8idG+Dd5j6YkAGFjcLeADMKxvrADsXFBcyPFHMPAtu2kVzd5fJMMeZrNHjokPWxQELExsaSmaW8DZAzkZx8XVb+DRtGP39RkNmaKTavuUafDa19ezJX5jAy248/Np8hGYkn2LFLcoRXbtvuRAz34kJO6Ixa4u/w30g4SIUfKHhw13uAsZtvprCk/ryzI0dC+0307SvivfORarVqNKu47TZi8tyhKSWF3NOdSNYRKjJ2QBER5FjEGKXvGz6c9u/YQV7lTz0lTJx5R2c2irWydLFLzZrR9cz+yYJ8PsawKYFSMO0eOVI/y5k71/zdBUI34rOCfaCFhebPD5hHeWPuSqHqBatWifUvvgA2bvR9To0aYj0pyfN448bBt4vjxAng/vuBSy4B1q+nfX36ALNmAV9+SesLFtD+WrWAO+8Eli937vp2Ubu2vXKM6bddLuCxx2j/tdcCkZGkYHzqKbqP554Djh8HmjUDzp8HevQAsrP1dURHAxkZwbW/Y0cgKgrYu1evoM3P15erXt3+vdpFQgIQG0vrZ886U6ex3f5g/nzSd/bsCdSrByxeDLRrJ97d7bcHXncSjgIAchEZWAVlywZ+8XDi++9DU68V1y9IKqwj92uuoRHv4497l63LzinePE3tUjCRCmfPFus8qFgoKRAzYX9HedHRnuIXOS/DihX0voyJtY0UqH+AnMTCLA8t1+W98AJ5vIf6mRcGkhOhy/H5t271DL1uVycQjzPsFTwY/psLFVlpoFu1CphHQYll7MPlIoekYcNEDBhZhmvmPj1mDAX4at9e5N81kq8gVBERevFB5856Z7twKPFDRa1aOasDyMkhsYmvZ9ytG2MTkNcU3wAAH1hJREFUJniPnDlihHlUzuPHSefywAO0/fXXIsrsmjX+O4Z5i0nD6y1osis3T021tp6yUoqb0cMPi/g+MmWgkMZSCJasPvrY2ID5lWLufsBujtH27WlpDB0QzKj7+efFuhwiNRzkROIZK6pc2Z5polm8FDO5s+yR6i+ZDaYWLPB93s6dep2MWYYkb2TlOxMd7eyzt6NcBuw52jlJ3btTJx8Xp++U70aY7DrDSdHRAfMrxdxt4u+/CyYFm0zx8fopbjgp2Jg1/pCvTrBJE8buu69g799M0WiVC7RDB++Z3zgVFiulUJtL2g3U6I0aYCvLRyF5YIFSuXL6sK92KDExYJ7ljbkrhaqE1q2BrKzAz2/WzP9zpk8HBg4EypcP/Lq+YObtaYbExNC1wYjjx2kpK6BlbN0KTJlifb6mOd8mM0Xjzp3mZdesAQ4dsq6rVClaMqbf/9xzgbXNF6yeI4dR0ew09uwJvo5KOIvdqBd8RQWNhASxnpFB2w8+CFSoYO/8yAAVyD6gmLsbOTnm+yPcT6hKFd8MZfNm/64ZEwP070+WGOPH075evYA6dfyrxxcuXrRXzmlLmjJlfJc5fDiwuo1MM9zgzJzD6nt6//3QXD/Q52gGszAPBYE/cSm2o2F4Lh4MzpzRb//zD41e0tLsne90SAU3Shxzf/VVYMQIMtlKTxc/xbJl+nItWgAdOpA5HkBmh04zlIsXyZzsySfJ5C8ykuKh7Nvn7HXCBbszgaio0LajIGDFzI04etTZ65YuTUuzgUerVvrtmjVpduoN5cp5xkKSB6ahmDEJMCxHZ/2uiCBYVOXKwZ0fDGbMsF/WODJwClbymoIkp2Tuf/xBTjvbt1OIACOMoV+5jFU2q+PEU8gZZaaBOJIE60RjJGO8cpn8SRIfavI3AmtBU0ICY+PG+X+ebPpaGMjKwu7KKykfAEDhDMqUIUswf+pu0kQkby8oyoV0Q2fP6k3UHn+8eAa8DxAoKQrVTp3ojrjt9c8/i2MXLtgL7mX8YXr3Jn0H3+8tc1Ew5C1DTWEiu8GiCiqXpzGomD8KzKee8uzYQ6EADZdStXRpMhAIdnBhR3HsBDXCFrYbhtyNv/2m13QfP062x0DoE1fLFMrobCEyhSw2YpnZs4E//6R1LuqaPVsoyfbtIy/GCRPsObJxcczFi8BDD4n9S5c612aOiAggN9f5en2Bez7aAX9m/Ln4glU5p6f1Lhd5hgIk1oqOFseGDfN+7nPPAVu26Pcx5mz7QlWnHWRnk4FAsB663hTH3uDP9wUAcTiPutin3zlsGP3E/MVeeSXw7rvkjrx1a2AN8wfJySQr7dzZd9lAMW5caOq14voFSU6M3AcPJttpo1lhx450nMfAkG3J/aVrry0+zkRTpxb8NZ1Oz8eJzxKMkRSTk52LBKsoMKpWzXfuWU61sN9+xW+95V+c5EDo+++JeezdS4wkJkbkvORUo0bwdqZVqwbM91DcxTIXLpDo5MYb+Q3rKTa24MQE4Sa7IgCev7Mw0YNBep7LSXqs5OIrVgQmZy+uVJj+i4SIM+wTjGCucDaiUSP6ibp3J1npCy+IYy+/TAzm/vv9r7dFC6rb7JjyULXGHXfQnXz9tXUaM0V68kfGX9DRD0Mlo46KonDBhV3Ry8lfX5hQkhw/JpS0Ec3De6O33EJLY68XFUXJkBmzlx3GH6pVK2DeFxRzB1ATwO8AtgHYAuB+9/4EAAsA7HIvK0rnTACwG8AOAH18XSMY5n7+fHi/BU6cWa5bV3SYh1n7/aFJkyjRM98uDkkjnOhYoqKcHxEXh2drRvJ3Vxt7GANYfkFdfORI/3qt1FT6wb2VCSSxR1JSwPzPG3O3o1DNA/AQY6wxgI4Axmia1gTAeACLGGP1ASxyb8N9bDiApgD6AnhP07TQuGBBn98ynOAK0bQ0IC8vvG3xFxUqeCp0W7b0fk5CAjB8OPDRR8JO/bLLQtO+ggC3F3fCLDovz77i2Q7i4ux7GRc1yN9dG6wDAITUlF7Gp5/692D37gXatvVexujQZAd9+vh/jg34/JQZY0cZY+vd6xmgEXwNAAMB8OjW0wAMcq8PBDCTMZbNGNsHGsF3cLrhAPDXX8CBA6GoOXD06BHuFljDyqnIzJHOV+z6M2eARo2IiT3xBO1buDC49oUT3D0/mFjnTsDMmuj8efvOjnbQpo1zdTmJhegNoACZOxC4KZCTWLMmJNX6NU7RNK02gNYAVgOoyhg7ClAHAKCKu1gNAAel0w659xnrukPTtLWapq09efKk/y0HMGlSQKeVWJg95pQUz312PUZzc4l+/DG4dikIMBZ8HVazD95x8MQuwSAUs7R0VMBP6O98xYUdO3aEpFrbzF3TtLIAvgPwAGPMWzAEs47X45NljH3EGGvHGGuXGGDEqlB57ZYk/Puv5z5/xUrr1jnTFo4QxVEqMbASCTnRcXAYw3U4gfZYjZo4iLzi435jD1Wq+C4TAGw9RU3TokGM/UvGGM8JdVzTtOru49UBnHDvPwRSwnIkAzjiTHP1CCaCo4J9JCbSaP7BBwvmeuEWjSiEB3tRFw2xHZFwUGFRFHDppSGp1idz1zRNA/AJgG2MsdelQ3MB3OpevxXAHGn/cE3TSmuaVgdAfQAhESrFxYWiVgUjTp4k+fobb4S7JQrFGWkojzTEF6zMPZzQNGDkSIpmGALYGbl3BnAzgB6apm1wUz8ALwG4QtO0XQCucG+DMbYFwCwAWwHMBzCGMRaSsVhmZihqVTCDv+GMFRT8RU8sRNX/BAAWKA6yWG6axRhZ7DRvHpLL+FSdMcaWw1qB3dPinEkAQq7u5M9IQUGh6GM1OgIgBZ3l6D0cQZichjFzitMJHNwo0pqL4vCeFYoWnn/e+Tp9ZVEqKUhHee+MHXBOK3zddc7U4wutWlFc+WHDgJkzzct88UVILl2kmbudTD8K4YWZWV65cmI9lMH2nMbAgcCmTWJbjkAZKOLigLfeonV/oygWN7gQidOo6N9JgYYZ/eabwM7zFxs2AKdOAV9/TV5/RrRoAVStGpJLF2nm7qRpl4KzSE6mpZlZ3nvvifUVK0JmLOA45szR8wQnZo7nzwM33kjryvpLw3WY5d8pjFEPGdoUUc6DO5Ns2gR07BiSSxRp5q7EMnrcfrv/54RKP+XN8e/mm/XbK1eGpg0FjUqVgAED/D8v1MmrixKuwjz/Tzp/nph8UWLwsjNJiNzsizRzL0rvsiDw8cf+x0apXdt8v1JW+4/Tp4G5c8PdisKBQP7NSOTiBnwV+EWL6lTeTvagAFCkmbuaxnrC34BVO3ea71ejSWcxcCBw993hbkXBIRA+2w1LUB3HPN3ZizsuXgxJtUU673xJV0ApFH6ULk0d5Zw5vssquHAISagRGof2wosQxdso0iN3ZS2jUNihZkD2kYZ4bIKPWNPFESGKt1GkmXuwiX+LC3qaupIpKBQt7EAjtMHakhN+gCNEliFFmrnL9tIlGYsWhbsFBCfsvhWcQVGc1V5AGVRDYOG/FTxRpJl7Tk64W6AgIzcXaNw43K1QAJzJKFXQiMFF5BdtllSoUKSfpGLuhQ/btoW7BQoAmX47gYI0Nz6PcmiBjbiAAHMK1qzpu0xhRIgecpFm7nYzBikoKASGgjQd74zlWIquiEGApoEHD/ouUxihmLsniloiagWFwoqEhHC3ADiNiohGXslTqDqZTV1CkWbuKh2bgkLgaNBArJ85UzDX9Dbb3omG+BS3QCXicgZFmrkXRaWRgkJhgZV3cijhbbbtQiQOonbJG7mHCEWaParAYQoKhQsJCYF7jrfEBryKcUWbKQWCW24JSbVF+jmqHKoKCoULZ84EHvPpDCo525iigi+/DEm1RZq5OxVvp2tXZ+pRUFAIHEklLaYMhwo/4AmnRu5LlzpTj4JCKBEfH+4WhBbpKIeLKAYJsP1FiEaXRZq5HzsW7hYoKASP8uX121ax9M+dC31bwonDSEJESQr4yy1CNmwITfUhqbWAUBhscxWKB6pWBerWBdq0Kfhrp6frt0tqJMl0xOMoqoW7GaGFbL/N7dtD5GpfpJm7cmJSCBSJifrtkyeBPXuA9evD0x5/MWRI8TMFfhQTUQtF1MvULszk6yGK8lakP48LF8LdAoWiipOG4IMhchIMGb79NrA2ly4NVK7sfHucwB40DHcTwoMQyduKNHNXsWUUFPxDdjZw6pT3MuHKTTwb1+APdAvPxYNFMPGuQxTAp0gz9+JuPaCgEA6EK890C2xES2xEXlFiSzHuCJbcozIurtAkNihCT9ETSiyjoFB8sAsN8DWGIgqFWEZWvjzwzTdA9+60bXS2OX++0LjO+2TumqZN1TTthKZpm6V9CZqmLdA0bZd7WVE6NkHTtN2apu3QNK1PqBoOqHjuCgrFCQ2wDQMwN9zN8I70dGDkSGDzZuc02mFUqH4GoK9h33gAixhj9QEscm9D07QmAIYDaOo+5z1N01TsRgUFBZ+ohUNIQhFwXsnMJMWFU1r46tWdqccAn8ydMbYUgDEg6EAA09zr0wAMkvbPZIxlM8b2AdgNoINDbfWAlbOHQvGH0fFHoehjNgZhJoaFuxkFjxMnQlJtoPOKqoyxowDgXlZx768B6AxVD7n3hQSFRLSlEAYYHX8Uij76YR6G4+twN6PgkZkZkmqdVqiaGVGZ6t41TbtD07S1mqatPWk0OrZ7sUIa+FmZaAaPiAhhiKBQMrAVjZEOFerVKQTK3I9rmlYdANxLPq84BEDOUpsMmId6Y4x9xBhrxxhrl2h0F7SJwsrcleds8HC5nIv6qVA0kItIbEJzzwMREcU7vnfD0DhvBcrc5wK41b1+K4A50v7hmqaV1jStDoD6ANYE10RrlCqBAeScRr164W6BggIhBYeQgkOeB1wuMjEMFoV1Sn34cEiq9Xm3mqZ9BaA7gMqaph0C8DSAlwDM0jRtFIB/AVwHAIyxLZqmzQKwFUAegDGMsZClRFQju+Cxe3e4W6CgQEhDvDlzdwqFdUodotgXPpk7Y+x6i0M9LcpPAjApmEbZhUqQraBQcIiICA0fiosDhg8Hjq2KxfotrdAaG0pWHtVAU1f5QJH2UFVOTAoKBYdQBVc7fx745BNg+5Y8HEYy8os2Wyo0KKRCKHsorApVBQUF/1ERabgaP4W7GQWPEJmFFekuMlCv3dhYoGNHoF8/oYQvV051FgoK4cQ6tMWjmFSYI8uEBrGxIam2SI/cA1WoZmUBq1bp92VkBN8eBQWFwNEAO3AXPi7aI85AcMYYAMAZFOnnWFwUquXLA61ahbsVCgWJ4pZFyQnUwEFEopBatBRBFOlPrLj8IOnpIcuRq1BIUdQyPxUEDiMF+5AKV8mylQlZ/PcizR6Ly8hdQUEB2IV62IaG0MwjlhRfhChIVpFm7ipwWOFAYc3JGQg0TSnWw4WBmIu78LEyhXQIRfopZmeHuwUKgO+cnIUVZmI9xsKXZi7UiI8H3nkHeO89ICnJ83ipUuEVde5HMlahfeHOxBQKXHppSKot0tYyKp67QjAoaXLvc+eA++4DqlUDjh2juEInTojwyeF2CsxBDPJQAgNGrV0bkmqLNHNXOVQVCguioyku1YULtDSGMSlblsrk5oYsfLcOzZsD//4LpKXp97tcwBF3nNbCFleoCk6hC1b4LlimDI3szp0T+3iM6Lw8oFEjoEoVcmY5c4aY57FjdE5GBnD6tDMy3dhYeqA5OcFN+UIkByzSzF3JRkMDTSueoolSpYIfncbGmocCyc0V/MIsPpUvhh4VBdSoQc/93DnaDsb8+Z9/Aj+3oBAbCzRrBlStCiQmAh1SW2D5ro/QZcVk6nmio4l55htiD164QDLZZ58FkpOp7IEDQN26wPTptB0XB0ycSOVr1yaGf/AgMXmAjl+4QFYZjRsDXbtSb7hmDU1nrKZ1FSoAQ4YAn35KH0LlyvRyjU43PXsC998P/P47te3XXz0jW0ZGAu3bA2++GfSzNAVjLOzUtm1bFghuv513l4rMSNOIwt2OUFOpUuI+o6IYK1fO9zlVqzJ2+eWMTZ7M2D33MNahA2Nly3o+v3DcT1wcY+XLi+0rrmBs0iTGxoxhbNAgxqZMYWzAAOevGxVF1/b3vDp1GKtfX19P5crmz7xqVf2+yEg6t3p1xq6osoFtKtWG5f25hm5YfpGNGtlrTO3ajF16KTXioYcY++UXxrp2ZaxmTcbi4+lC8oMeO5axnj2p/p49GTt8mLH8fMYOHGBs+nTGJkxgbM0axnJzGfv2W8YqVaJzk5LonB9+YCw9nbHPP2dszx7GRo8W9SckMFamDK1HRDAWHU3taN2asdRUUe7NNwPif4wxBmCtFV/V6Hh40a5dO7Y2ALnTokXA1VcHJ57ho3+zx1C6NJCaSk5Gq1cHfg078CfiXlQUdfr5+USF4BWGDXaem6ZRuTJlSJFYoQLw11+eZRijd+6Pol7TgEqV6BvMzaUBYd26JA6JiaFQ3efP03VLlSKRSFYWnRcT47+IJjKS7rcwvXP+PebkUBgPsxSIERE0Um/cGLjpJvqvjh8H5s0jSUl+PlD51FZM294JMTnpNCKvVIlG4cYRb0oKULMmsG8fkJBAU50jR+jBNGpEF6pTh441bkwv9MMPgf376fzISHpJO3eKOlNTgb176Wfv3x947DGaVnDk5dGNpqUB48YBM2cKt/bERJol3HEHbR87Bjz+OLB1KzEOxoBu3Wj555+eIqHkZJpVBABN09YxxtqZHivKzJ0jLQ3YvBl48kkSs7VsCXTqBPz2GzB5MrBrF5WrVIne+d69NOWNjaX3xRhwww3AAw8As2eTvLJlS/ohuS19fj45Gmkavcvy5clKZM4cmskNH07vu0cPKvvPP/Qz16sHvPEGXdMfxMTQN2CckXoDZ/jcnM/I9IziFk0Dxo8Htm+n+y5olC9P/0+dOtT29HRgyRK675gYoEEDemc1alCymh9+oHfA5cicsVvdr9OIj6fvJSOj6Ftq+SN6499VcjI9A5eL+FYgSEqi/yYpid5flSrA2bPAjh1AU2zCMnRDRZzTnxQVRQ120vY5IgIYPBg4ehTo0gV49FFisEOHCqbfsiVdU9OIiVSpIjoRM8TF0cPKzrb3gZQpQ3V17kwj1QBQ7Jm7L5w9Sx0vz+Z38iSNMmqELHW3HtnZxLQ2bQKWLgX27KEfKyqKmFdqKtChA3VQycnA338Df/xBIxuOevXoG9i4kZRzLVvSfQwYAAwbBrz2GsXLufJK4PrraQSVnw/89BPw/vv07XBZcGQkMdXBg2lQdOwYMazNm4WSrWJF2udvfoMqVfTJ3FNTgQcfpNFabCxw6BCJH/fsoWexfr1nBxYRQWJSuUOMjqb3V6EC1X/6NN1HYiK1PyKCOovWremfWbgQuOQSGomfPUvnpKX5n1jbjAnGxJjHNapUicpbmYaWKUPnXrhgfn5SEtUB0H3GxtJ9P/EE6QSnT6f6Dx+m+weE/L9cOfoujh+nMlWqEN8C6DmVLUvPZ8gQ4MUX6bnk5lJneeEC8ZhVq+i97N9P38Xu3fSNAZ76iqgoz1nj4ME0qDpwgAY3l1wC/Pgj1WPnO7oCv+E39PFdkCM6mm48MlI0NCaGfji5YeXLA02aUNk//rDuJGJiqAwf+eXl0cM0U7JER9PMQNOEHN8XzDTtAH2069fbq8OAEs/ciyJcLpp1vvsu8N13pOsBaFaxZQsdHzOGvsd77qGZ6v79RC4XfXctWhDTX7aMvle7oqWaNWkQU7o0/azx8bR+111A9er0Pc+fTwOVjRuBQYPoeikpVHb5ctFB/fKLGMS0aEGMltfdvDn9N6dO0Wz64kWgVy+6h19+oe2cHE/mX66cvUBvsbHUrkOHqCM/exa4+27g8svp/CVLqE09elCbYmKApk2BFSvo3tq5f5kdO4jZ8udasSLxB8aASZOIkU2YQM8KIOb7zTfEb9q2JYb9/PPEMF0uYpTDh9P/PHUqnVOjhv1sa6VKkRKSK3F5RxcfT+8uPZ0GmPn5dD+aRkybd2wJCdQp1qtH0oPkZHqPR49SB3/8OA0aBgwgu/gJE2gw0aEDzYYPHPBsT3y8vlOX30FWFnUumZmenWXfvtTpLV8OVDu5EZ/iNrRO2I+IzEyqdOBAoHdv6iH+/ZdexMWLNFrZu1eIbKx6XI7oaOrxmjenhm7YIEbgfGriDVWr0os/doxGCWZ8s3JlKnfiBH3UVrw1KYmmq/v3088xejT1uAFAMfdigL17gRkziNGXKkWioEDQvz/9zLVr00/KGCns4+LI/vnSS6n+9HQxywwG//4LfPklMTtuMdapE33Tu3YRw3W5qC2lStG/Gh1NM4ucHBLN1K0LjBgBLFgAfPyx6Axuu42YdGoq1ZOTQ/e2fz8xz3Ll9G1xuQpfPKJ9+4DXX6dOnDFq84ABxKQ3bqQyO3YQE2/bljrFI0dIdGscBJrNMipUIJ6TlETnx8dTh1+nDs0kjeCj/uPH6f03b06dx65dQJs2NBqvXJk6+ZgYasvGjUS5uUCfPsRjFy8WJpdyO2UdSf36NGBo3py+vdXLshF97iRunVCDLvrnnyT/adaMaOdOOqlmTaro3XeB77+nhzJjBsneN26kXuTTT2mZnw+sW0cXLF9ejBgqV6ZofSdOULm9e0UPZNZYGb46En/BH3gAUMy9GCI7m8QaCQnA3Ln0vZYpQzoHTaP/YtcuEtN07Uo/T2HND8yRnU0im86dhXiipCA9nWZXtWrZM/HlM7mKFYWIJjGROruzZ4nRrllDIjqes4AjP5867T//pG+IMarH5QJGjaLvZPly4OuvqY6yZWm28/33NAvi1/OGjh3p2wSIL1evTh1Lv37EPz/8EJg2Tc/TemIhftAGoywLwBEgIoIabrR1LVuWRgHJycAHH1BPc+wY9aLGG9E0mgZfeilNazp0oOnd1Kn0M2kasHKlKN+0KU23zhl0BBylStEopFUrmhqePk0PcuVKodFPSaFeM0Cll2LuCgoKjiEjgzqGY8eoE4mNpUGxy0W8rn59EnX56qQyMkhctHGje1CecBo9Z92JmrUiqEdKSaFRSc2a1Kts2UKVr11L63XqkLzr6FFi3Dt3ApddRucmJADdu9O01KohmzbR+YyR3KlvXyrvDX//Dbz9Ni15KNfRo+lazZtTnbGx1MN++y0xcqOixzjFGjiQrAUCgGLuCgoKCk4jM5NmAvHx1mUuXqTp0YkTpFiZOpU6n8REmrYkJAA33kgdQwDwxtwL+URdQUFBoZCibFnfZWJiSCHMcfnloWuPAYVMvaSgoKCg4AQUc1dQUFAohlDMXUFBQaEYQjF3BQUFhWIIxdwVFBQUiiEUc1dQUFAohlDMXUFBQaEYQjF3BQUFhWKIQuGhqmnaSQAHfBa0RmUAFoFWSwzUMyCo50BQz6FkPINajLFEswOFgrkHC03T1lq54JYUqGdAUM+BoJ6DegZKLKOgoKBQDKGYu4KCgkIxRHFh7h+FuwGFAOoZENRzIKjnUMKfQbGQuSsoKCgo6FFcRu4KCgoKChIUc1dQUFAohijSzF3TtL6apu3QNG23pmnjw92eUEHTtJqapv2uado2TdO2aJp2v3t/gqZpCzRN2+VeVpTOmeB+Ljs0TesTvtY7D03TIjVN+1vTtJ/c2yXuOWiaFq9p2reapm13fxedStpz0DTtQff/sFnTtK80TYspac/AKxhjRZIARALYAyAVQCkAGwE0CXe7QnSv1QG0ca+XA7ATQBMAkwGMd+8fD+Bl93oT9/MoDaCO+zlFhvs+HHwe/wdgBoCf3Nsl7jkAmAZgtHu9FID4kvQcANQAsA9AGff2LAAjStIz8EVFeeTeAcBuxthexlgOgJkABoa5TSEBY+woY2y9ez0DwDbQxz0Q9JPDvRzkXh8IYCZjLJsxtg/AbtDzKvLQNC0ZQH8A/5N2l6jnoGlaeQBdAXwCAIyxHMbYOZSw5wBKE1pG07QoALEA/r+du3eNIgqjOPw74AeY1Eo0QiIE61iJ6YylaCWkiASxVMFK0L/AQsTORrQxTYgB02lhv4ofINFOJVmNJpWCldFjcW+xxWZXhCTMve9T7bwzA3fP7rw7c3eYL9SXwaaa3NwPASsdy+1cK5qkEWAcaAEHbK9C+gEA9ufNSs7mDnAN+NNRqy2HI8A68CBPT92TNEBFOdj+DNwCloFV4Lvtp1SUQT9Nbu7qUiv6vk5Jg8Aj4KrtH7027VJrfDaSTgNrtl/+6y5dao3PgXTGegy4a3sc+EmagthMcTnkufSzpCmWg8CApOleu3SpNTqDfprc3NvA4Y7lYdJlWZEk7SY19lnbC7n8TdJQXj8ErOV6qdlMAGckfSJNw52U9JD6cmgDbdutvDxPavY15XAK+Gh73fYvYAE4QV0Z9NTk5v4CGJM0KmkPMAUs7vCYtoQkkeZX39u+3bFqEZjJr2eAxx31KUl7JY0CY8Dz7RrvVrF93faw7RHS5/3M9jT15fAVWJF0NJcmgXfUlcMycFzSvnx8TJL+i6opg5527fQA/pftDUmXgSekO2fu217a4WFtlQngPPBW0ptcuwHcBOYkXSR92c8B2F6SNEc64DeAS7Z/b/+wt02NOVwBZvOJzQfgAulkrYocbLckzQOvSO/pNelxA4NUkkE/8fiBEEIoUJOnZUIIIWwimnsIIRQomnsIIRQomnsIIRQomnsIIRQomnsIIRQomnsIIRToL1tkvj4N0x2FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate stocks data\n",
    "stocks_data, _ = GBM(num_seeds, is_training).generate_stock_paths(mu, sigma, 928, num_seeds, is_training)\n",
    "stocks_train_data = []\n",
    "stocks_test_data = []\n",
    "real_stocks_train_data = []\n",
    "real_stocks_test_data = []\n",
    "for stock_data in stocks_data:\n",
    "    #train_data, test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    #train_data, test_data, real_train_data, real_test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    train_data, test_data, real_train_data, real_test_data = prepare_company_stock(stock_data, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    stocks_train_data.append(train_data)\n",
    "    stocks_test_data.append(test_data)\n",
    "    real_stocks_train_data.append(real_train_data)\n",
    "    real_stocks_test_data.append(real_test_data)\n",
    "    plt.plot(range(len(train_data)), train_data, color='b')\n",
    "    plt.plot(range(len(train_data), len(train_data) + len(test_data)), test_data, color='r') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvbblMrQjMDP"
   },
   "source": [
    "### Load the game environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FbJ69FFjMDh"
   },
   "source": [
    "Setting our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "option_T: 50\n",
      "history_t: 15\n",
      "build_warm_up_state_t: 12\n",
      "###############################\n",
      "num_batch_episodes_per_epoch: 1059\n",
      "num_episodes_per_epoch: 135600\n",
      "min value of stock: 126.80873014680922, max value of stock: 229.2135004855168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a64132890>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################################################################\n",
    "#env = StockEnv(train_data, risk_free_rate, history_t=history_t, option_T=option_T)\n",
    "env = StockEnv(stocks_train_data, real_stocks_train_data, risk_free_rate, history_t=history_t, option_T=option_T)\n",
    "#max_num_observations = env.max_num_observations\n",
    "num_batch_episodes_per_epoch = env.get_total_num_episodes_per_epoch() // batch_size\n",
    "build_warm_up_state_t = env.get_build_warm_up_state()\n",
    "trace_length = option_T - build_warm_up_state_t\n",
    "num_samples = batch_size*trace_length\n",
    "print('num_batch_episodes_per_epoch: ' + str(num_batch_episodes_per_epoch))\n",
    "print('num_episodes_per_epoch: ' + str(env.get_total_num_episodes_per_epoch()))\n",
    "print('min value of stock: '+str(min(train_data)) + ', max value of stock: '+str(max(train_data)))\n",
    "plt.plot(range(len(train_data)), train_data, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa=1.0\n",
    "num_tau_samples=64\n",
    "num_tau_prime_samples=64\n",
    "num_quantile_samples=32\n",
    "quantile_embedding_dim=64\n",
    "\n",
    "# to remove and keep num_quantile_samples only\n",
    "#num_quantiles = num_quantile_samples\n",
    "double_dqn = True\n",
    "num_actions = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JmiYKRi3jMEQ"
   },
   "source": [
    "### Implementing the network itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-s-_kz6jMES"
   },
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,myScope):\n",
    "        \n",
    "        self.scalarInput = tf.placeholder(shape=[None,input_size],dtype=tf.float32, name='scalarInput')\n",
    "        \n",
    "        # depending on the chosen architecture, data is processed through differents layers\n",
    "        \n",
    "        # convolutions are used in all type, except architecture 0 which only uses LSTM\n",
    "        if architecture != 0:\n",
    "          self.InputConvIn = tf.reshape(self.scalarInput,shape=[-1,input_size,1], name='InputConvIn')\n",
    "          self.conv1 = tf.keras.layers.Conv1D(filters=nbFilters,\n",
    "                                               kernel_size=3,\n",
    "                                               strides=1,\n",
    "                                               padding= paddingType, #'same',\n",
    "                                               activation=tf.nn.relu)(inputs=self.InputConvIn)\n",
    "        \n",
    "        if architecture == 0: # LSTM only\n",
    "          self.scalarInputFlattened = tf.keras.layers.Flatten()(self.scalarInput)\n",
    "        elif architecture == 1: # only one convolution\n",
    "          self.conv1flattened = tf.reshape(self.conv1,shape=[-1,self.conv1.shape[1]*self.conv1.shape[2]], name='conv1flattened')\n",
    "        elif architecture == 2: # only one convolution followed by max pooling\n",
    "          self.maxPooling1D = tf.keras.layers.MaxPool1D(pool_size=2, strides=2, padding='same')(inputs=self.conv1)\n",
    "          self.maxPooling1Dflattened = tf.reshape(self.maxPooling1D,shape=[-1,self.maxPooling1D.shape[1]*self.maxPooling1D.shape[2]], name='maxPooling1Dflattened')\n",
    "        elif architecture == 3: # only one convolution followed by average pooling\n",
    "          self.AveragePooling1D = tf.keras.layers.AveragePooling1D(pool_size=2, strides=2, padding='same')(inputs=self.conv1)\n",
    "          self.AveragePooling1Dflattened = tf.reshape(self.AveragePooling1D,shape=[-1,self.AveragePooling1D.shape[1]*self.AveragePooling1D.shape[2]], name='AveragePooling1Dflattened')  \n",
    "        elif architecture == 4: #VGG (one block of 2 convolutions followed by avg pooling)\n",
    "          self.conv2 = tf.keras.layers.Conv1D(filters=nbFilters,\n",
    "                                               kernel_size=3,\n",
    "                                               strides=1,\n",
    "                                               padding= paddingType, #'same',\n",
    "                                               activation=tf.nn.relu)(inputs=self.conv1)\n",
    "          self.AveragePooling1D4 = tf.keras.layers.AveragePooling1D(pool_size=2, strides=2, padding='same')(inputs=self.conv2)\n",
    "          self.AveragePooling1Dflattened4 = tf.reshape(self.AveragePooling1D4,shape=[-1,self.AveragePooling1D4.shape[1]*self.AveragePooling1D4.shape[2]], name='AveragePooling1Dflattened4')\n",
    "        elif architecture == 5: #Lenet (conv, avg pooling, conv, avg pooling)\n",
    "          self.AveragePooling1D = tf.keras.layers.AveragePooling1D(pool_size=2, strides=2, padding='same')(inputs=self.conv1)\n",
    "          self.conv2 = tf.keras.layers.Conv1D(filters=nbFilters,\n",
    "                                               kernel_size=3,#5, #3, #maybe unstable calculations because of 5 instead of 3\n",
    "                                               strides=1,\n",
    "                                               padding= paddingType, #'same',\n",
    "                                               #activation=tf.keras.activations.hard_sigmoid\n",
    "                                               #activation=tf.keras.activations.sigmoid\n",
    "                                               #activation=tf.keras.activations.tanh\n",
    "                                               activation=tf.nn.relu)(inputs=self.AveragePooling1D)\n",
    "          self.AveragePooling1D5 = tf.keras.layers.AveragePooling1D(pool_size=2, strides=2, padding='same')(inputs=self.conv2)\n",
    "          self.AveragePooling1Dflattened5 = tf.reshape(self.AveragePooling1D5,shape=[-1,self.AveragePooling1D5.shape[1]*self.AveragePooling1D5.shape[2]], name='AveragePooling1Dflattened5')\n",
    "        elif architecture == 6: #Googlenet (Inception net: combine (conv&avgPooling) + conv1 + conv3 + conv5)\n",
    "          self.AveragePooling1D = tf.keras.layers.AveragePooling1D(pool_size=2, strides=2, padding='same')(inputs=self.conv1)\n",
    "          self.conv11 = tf.keras.layers.Conv1D(filters=5,\n",
    "                                             kernel_size=1,\n",
    "                                             strides=1,\n",
    "                                             padding=paddingType,#'same',\n",
    "                                             activation=tf.nn.relu)(inputs=self.AveragePooling1D)\n",
    "          self.conv3 = tf.keras.layers.Conv1D(filters=5,\n",
    "                                             kernel_size=3,\n",
    "                                             strides=1,\n",
    "                                             padding=paddingType,#'same',\n",
    "                                             activation=tf.nn.relu)(inputs=self.AveragePooling1D)\n",
    "          self.conv5 = tf.keras.layers.Conv1D(filters=5,\n",
    "                                             kernel_size=5,\n",
    "                                             strides=1,\n",
    "                                             padding=paddingType,#'same',\n",
    "                                             activation=tf.nn.relu)(inputs=self.AveragePooling1D)\n",
    "          self.filterconcatenation = tf.concat([self.conv11, self.conv3, self.conv5, self.AveragePooling1D], 2, name = 'filterconcatenation')\n",
    "          self.filterconcatenationflattened = tf.reshape(self.filterconcatenation,shape=[-1,self.filterconcatenation.shape[1]*self.filterconcatenation.shape[2]], name='filterconcatenationflattened')\n",
    "        \n",
    "        self.trainLength = tf.placeholder(dtype=tf.int32, name='trainLength')\n",
    "        self.batch_size = tf.placeholder(dtype=tf.int32,shape=[], name='batch_size')\n",
    " \n",
    "        #We take the output from the final convolutional layer and send it to a recurrent layer.\n",
    "        #The input must be reshaped into [batch x trace x units] for rnn processing, \n",
    "        #and then returned to [batch x units] when sent through the upper levles.\n",
    "        if architecture == 0:\n",
    "          self.convFlat = tf.reshape(self.scalarInputFlattened,[self.batch_size,self.trainLength,input_size])\n",
    "        elif architecture == 1:\n",
    "          self.convFlat = tf.reshape(self.conv1flattened,[self.batch_size,self.trainLength,self.conv1flattened.shape[1]])\n",
    "        elif architecture == 2:\n",
    "          self.convFlat = tf.reshape(self.maxPooling1Dflattened,[self.batch_size,self.trainLength,self.maxPooling1Dflattened.shape[1]])\n",
    "        elif architecture == 3:\n",
    "          self.convFlat = tf.reshape(self.AveragePooling1Dflattened,[self.batch_size,self.trainLength,self.AveragePooling1Dflattened.shape[1]])\n",
    "        elif architecture == 4:\n",
    "          self.convFlat = tf.reshape(self.AveragePooling1Dflattened4,[self.batch_size,self.trainLength,self.AveragePooling1Dflattened4.shape[1]])\n",
    "        elif architecture == 5:\n",
    "          self.convFlat = tf.reshape(self.AveragePooling1Dflattened5,[self.batch_size,self.trainLength,self.AveragePooling1Dflattened5.shape[1]])\n",
    "        elif architecture == 6:\n",
    "          self.convFlat = tf.reshape(self.filterconcatenationflattened,[self.batch_size,self.trainLength,self.filterconcatenationflattened.shape[1]])\n",
    "        \n",
    "        # use cudnn-based cells to leverage Nvidia GPUs\n",
    "        single_cell = lambda: tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(h_size)\n",
    "    \n",
    "        # NOTE: Even if there's only one layer, the cell needs to be wrapped in MultiRNNCell.\n",
    "        lstm_cells = [single_cell() for _ in range(num_layers)]\n",
    "        if is_training and apply_dropout and dropout < 1:\n",
    "            lstm_cells = [tf.contrib.rnn.DropoutWrapper(\n",
    "                lstm, input_keep_prob=1.0, output_keep_prob=1.0 - dropout, state_keep_prob=1.0 - dropout\n",
    "            ) for lstm in lstm_cells]\n",
    "        multi_cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells, state_is_tuple=True)\n",
    "\n",
    "        self.state_in = tf.placeholder(tf.float32, [num_layers, 2, None, h_size], name='state_in')\n",
    "        state_per_layer_list = tf.unstack(self.state_in, axis=0)\n",
    "        rnn_tuple_state = tuple(\n",
    "            [tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "             for idx in range(num_layers)]\n",
    "        )\n",
    "        \n",
    "        # calculate the real length of each episode (since remaining states are filled with 0s after selling)\n",
    "        # This is required by RNN \n",
    "        self.seq_len = length(self.convFlat)\n",
    "        \n",
    "        self.rnn,self.rnn_state = tf.nn.dynamic_rnn(\\\n",
    "                cell=multi_cell,\n",
    "                inputs=self.convFlat,                                    \n",
    "                dtype=tf.float32,\n",
    "                initial_state=rnn_tuple_state, \n",
    "                sequence_length=self.seq_len,\n",
    "                scope=myScope+'_lstm')\n",
    "        \n",
    "\n",
    "        self.rnn = tf.reshape(self.rnn,shape=[-1,h_size])\n",
    "        ############################### IQN code\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32, name='actions')\n",
    "        self.actions_onehot = tf.one_hot(self.actions,2,dtype=tf.float32)\n",
    "        self.target_quantile_values = tf.placeholder(shape=[None, num_tau_prime_samples, 1],dtype=tf.float32, name='target_quantile_values')\n",
    "        \n",
    "        weights_initializer = slim.variance_scaling_initializer(factor=1.0 / np.sqrt(3.0), mode='FAN_IN', uniform=True)\n",
    "        \n",
    "        self.num_quantiles = tf.placeholder(dtype=tf.int32, name='num_quantiles')\n",
    "        \n",
    "        self.state_net_size = self.rnn.get_shape().as_list()[-1]\n",
    "        state_net_tiled = tf.tile(self.rnn, [self.num_quantiles, 1])\n",
    "\n",
    "        self.quantiles_shape = tf.placeholder(dtype=tf.int32, name='quantiles_shape')\n",
    "\n",
    "        self.quantiles = tf.random_uniform([self.quantiles_shape, 1], minval=0, maxval=1, dtype=tf.float32)\n",
    "\n",
    "        quantile_net = tf.tile(self.quantiles, [1, quantile_embedding_dim])\n",
    "        pi = tf.constant(math.pi)\n",
    "        quantile_net = tf.cast(tf.range(1, quantile_embedding_dim + 1, 1), tf.float32) * pi * quantile_net\n",
    "        quantile_net = tf.cos(quantile_net)\n",
    "        quantile_net = slim.fully_connected(quantile_net, self.state_net_size,\n",
    "                                              weights_initializer=weights_initializer)\n",
    "        # Hadamard product.\n",
    "        net = tf.multiply(state_net_tiled, quantile_net)\n",
    "\n",
    "        net = slim.fully_connected(net, 512, weights_initializer=weights_initializer)\n",
    "        self.quantile_values = slim.fully_connected(\n",
    "              net,\n",
    "              num_actions,\n",
    "              activation_fn=None,\n",
    "              weights_initializer=weights_initializer)\n",
    "        \n",
    "        self._q_values = tf.reduce_mean(self.quantile_values, axis=0)\n",
    "        self.predict = tf.argmax(self._q_values, axis=0)\n",
    "\n",
    "        # Shape of indices: (num_tau_samples x batch_size) x 1.\n",
    "        # Expand dimension by one so that it can be used to index into all the\n",
    "        # quantiles when using the tf.gather_nd function (see below).\n",
    "        indices = tf.range(num_tau_samples * num_samples)[:, None]\n",
    "\n",
    "        # Expand the dimension by one so that it can be used to index into all the\n",
    "        # quantiles when using the tf.gather_nd function (see below).\n",
    "        reshaped_actions = self.actions[:, None]\n",
    "        reshaped_actions = tf.tile(reshaped_actions, [num_tau_samples, 1])\n",
    "        # Shape of reshaped_actions: (num_tau_samples x batch_size) x 2.\n",
    "        reshaped_actions = tf.concat([indices, reshaped_actions], axis=1)\n",
    "\n",
    "        chosen_action_quantile_values = tf.gather_nd(\n",
    "            self.quantile_values, reshaped_actions)\n",
    "        # Reshape to self.num_tau_samples x batch_size x 1 since this is the manner\n",
    "        # in which the quantile values are tiled.\n",
    "        chosen_action_quantile_values = tf.reshape(chosen_action_quantile_values,\\\n",
    "                                                   [num_tau_samples,num_samples, 1])\n",
    "        # Transpose dimensions so that the dimensionality is batch_size x\n",
    "        # self.num_tau_samples x 1 to prepare for computation of\n",
    "        # Bellman errors.\n",
    "        # Final shape of chosen_action_quantile_values:\n",
    "        # batch_size x num_tau_samples x 1.\n",
    "        chosen_action_quantile_values = tf.transpose(chosen_action_quantile_values, [1, 0, 2])\n",
    "\n",
    "        # Shape of bellman_erors and huber_loss:\n",
    "        # batch_size x num_tau_prime_samples x num_tau_samples x 1.\n",
    "        bellman_errors = self.target_quantile_values[\n",
    "            :, :, None, :] - chosen_action_quantile_values[:, None, :, :]\n",
    "        # The huber loss (see Section 2.3 of the paper) is defined via two cases:\n",
    "        # case_one: |bellman_errors| <= kappa\n",
    "        # case_two: |bellman_errors| > kappa\n",
    "        huber_loss_case_one = tf.to_float(\n",
    "            tf.abs(bellman_errors) <= kappa) * 0.5 * bellman_errors ** 2\n",
    "        huber_loss_case_two = tf.to_float(\n",
    "            tf.abs(bellman_errors) > kappa) * kappa * (\n",
    "                tf.abs(bellman_errors) - 0.5 * kappa)\n",
    "        huber_loss = huber_loss_case_one + huber_loss_case_two\n",
    "\n",
    "        # Reshape replay_quantiles to batch_size x num_tau_samples x 1\n",
    "        replay_quantiles = tf.reshape(self.quantiles, [num_tau_samples, num_samples, 1])\n",
    "        replay_quantiles = tf.transpose(replay_quantiles, [1, 0, 2])\n",
    "\n",
    "        # Tile by num_tau_prime_samples along a new dimension. Shape is now\n",
    "        # batch_size x num_tau_prime_samples x num_tau_samples x 1.\n",
    "        # These quantiles will be used for computation of the quantile huber loss\n",
    "        # below (see section 2.3 of the paper).\n",
    "        replay_quantiles = tf.to_float(tf.tile(replay_quantiles[:, None, :, :], [1, num_tau_prime_samples, 1, 1]))\n",
    "        # Shape: batch_size x num_tau_prime_samples x num_tau_samples x 1.\n",
    "        quantile_huber_loss = (tf.abs(replay_quantiles - tf.stop_gradient(tf.to_float(bellman_errors < 0))) * huber_loss) / kappa\n",
    "        # Sum over current quantile value (num_tau_samples) dimension,\n",
    "        # average over target quantile value (num_tau_prime_samples) dimension.\n",
    "        # Shape: batch_size x num_tau_prime_samples x 1.\n",
    "        loss = tf.reduce_sum(quantile_huber_loss, axis=2)\n",
    "        # Shape: batch_size x 1.\n",
    "        loss = tf.reduce_mean(loss, axis=1)\n",
    "\n",
    "        # divide by the real length of episodes instead of averaging which is incorrect\n",
    "        self.loss = tf.cast(tf.reduce_sum(loss), tf.float64) / tf.cast(tf.reduce_sum(self.seq_len), tf.float64)\n",
    "        \n",
    "        #self.check_ops = tf.debugging.check_numerics(self.loss, \"self.loss contain Nan or Inf\", name=\"self.check_ops\")\n",
    "        \n",
    "        \n",
    "        if optimizer_type == 'Adam':\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        elif optimizer_type == 'GradientDescent':\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        elif optimizer_type == 'RMSProp':\n",
    "            optimizer = tf.train.RMSPropOptimizer(learning_rate)\n",
    "        \n",
    "        if apply_grad_clipping:\n",
    "            # calculate gradients and clip them to handle outliers\n",
    "            tvars = tf.trainable_variables()\n",
    "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), grad_clipping)\n",
    "            self.updateModel = optimizer.apply_gradients(\n",
    "                    zip(grads, tvars),\n",
    "                    # global_step=tf.contrib.framework.get_or_create_global_step(),\n",
    "                    name=\"updateModel\")\n",
    "        else:\n",
    "            self.updateModel = optimizer.minimize(self.loss, name=\"updateModel\")\n",
    "            \n",
    "    def _build_train_op(self):\n",
    "        \"\"\"Builds a training op.\n",
    "        Returns:\n",
    "          train_op: An op performing one step of training from replay data.\n",
    "        \"\"\"\n",
    "        # Reshape to self.num_tau_prime_samples x batch_size x 1 since this is\n",
    "        # the manner in which the target_quantile_values are tiled.\n",
    "        self.target_quantile_values2 = tf.reshape(self.target_quantile_values,\n",
    "                                            [num_tau_prime_samples,\n",
    "                                             num_samples, 1])\n",
    "        # Transpose dimensions so that the dimensionality is batch_size x\n",
    "        # self.num_tau_prime_samples x 1 to prepare for computation of\n",
    "        # Bellman errors.\n",
    "        # Final shape of target_quantile_values:\n",
    "        # batch_size x num_tau_prime_samples x 1.\n",
    "        self.target_quantile_values = tf.transpose(self.target_quantile_values2, [1, 0, 2])\n",
    "\n",
    "        # Shape of indices: (num_tau_samples x batch_size) x 1.\n",
    "        # Expand dimension by one so that it can be used to index into all the\n",
    "        # quantiles when using the tf.gather_nd function (see below).\n",
    "        indices = tf.range(num_tau_samples * num_samples)[:, None]\n",
    "\n",
    "        # Expand the dimension by one so that it can be used to index into all the\n",
    "        # quantiles when using the tf.gather_nd function (see below).\n",
    "        reshaped_actions = self.actions[:, None]\n",
    "        reshaped_actions = tf.tile(reshaped_actions, [num_tau_samples, 1])\n",
    "        # Shape of reshaped_actions: (num_tau_samples x batch_size) x 2.\n",
    "        reshaped_actions = tf.concat([indices, reshaped_actions], axis=1)\n",
    "\n",
    "        chosen_action_quantile_values = tf.gather_nd(\n",
    "            self.quantile_values, reshaped_actions)\n",
    "        # Reshape to self.num_tau_samples x batch_size x 1 since this is the manner\n",
    "        # in which the quantile values are tiled.\n",
    "        chosen_action_quantile_values = tf.reshape(chosen_action_quantile_values,\n",
    "                                                   [num_tau_samples,\n",
    "                                                    num_samples, 1])\n",
    "        # Transpose dimensions so that the dimensionality is batch_size x\n",
    "        # self.num_tau_samples x 1 to prepare for computation of\n",
    "        # Bellman errors.\n",
    "        # Final shape of chosen_action_quantile_values:\n",
    "        # batch_size x num_tau_samples x 1.\n",
    "        chosen_action_quantile_values = tf.transpose(\n",
    "            chosen_action_quantile_values, [1, 0, 2])\n",
    "\n",
    "        # Shape of bellman_erors and huber_loss:\n",
    "        # batch_size x num_tau_prime_samples x num_tau_samples x 1.\n",
    "        bellman_errors = self.target_quantile_values[\n",
    "            :, :, None, :] - chosen_action_quantile_values[:, None, :, :]\n",
    "        # The huber loss (see Section 2.3 of the paper) is defined via two cases:\n",
    "        # case_one: |bellman_errors| <= kappa\n",
    "        # case_two: |bellman_errors| > kappa\n",
    "        huber_loss_case_one = tf.to_float(\n",
    "            tf.abs(bellman_errors) <= kappa) * 0.5 * bellman_errors ** 2\n",
    "        huber_loss_case_two = tf.to_float(\n",
    "            tf.abs(bellman_errors) > kappa) * kappa * (\n",
    "                tf.abs(bellman_errors) - 0.5 * kappa)\n",
    "        huber_loss = huber_loss_case_one + huber_loss_case_two\n",
    "\n",
    "        # Reshape replay_quantiles to batch_size x num_tau_samples x 1\n",
    "        replay_quantiles = tf.reshape(\n",
    "            self.quantiles, [num_tau_samples, num_samples, 1])\n",
    "        replay_quantiles = tf.transpose(replay_quantiles, [1, 0, 2])\n",
    "\n",
    "        # Tile by num_tau_prime_samples along a new dimension. Shape is now\n",
    "        # batch_size x num_tau_prime_samples x num_tau_samples x 1.\n",
    "        # These quantiles will be used for computation of the quantile huber loss\n",
    "        # below (see section 2.3 of the paper).\n",
    "        replay_quantiles = tf.to_float(tf.tile(\n",
    "            replay_quantiles[:, None, :, :], [1, num_tau_prime_samples, 1, 1]))\n",
    "        # Shape: batch_size x num_tau_prime_samples x num_tau_samples x 1.\n",
    "        quantile_huber_loss = (tf.abs(replay_quantiles - tf.stop_gradient(\n",
    "            tf.to_float(bellman_errors < 0))) * huber_loss) / kappa\n",
    "        # Sum over current quantile value (num_tau_samples) dimension,\n",
    "        # average over target quantile value (num_tau_prime_samples) dimension.\n",
    "        # Shape: batch_size x num_tau_prime_samples x 1.\n",
    "        loss = tf.reduce_sum(quantile_huber_loss, axis=2)\n",
    "        # Shape: batch_size x 1.\n",
    "        loss = tf.reduce_mean(loss, axis=1)\n",
    "\n",
    "        # divide by the real length of episodes instead of averaging which is incorrect\n",
    "        loss = tf.cast(tf.reduce_sum(loss), tf.float64) / tf.cast(tf.reduce_sum(self.seq_len), tf.float64)\n",
    "\n",
    "\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_target_quantile_values_op(_replay_next_qt_argmax, _replay_net_target_quantile_values, \n",
    "                                     terminals, rewards):\n",
    "    \"\"\"Build an op used as a target for return values at given quantiles.\n",
    "    Returns:\n",
    "      An op calculating the target quantile return.\n",
    "    \"\"\"\n",
    "    num_samples = batch_size*trace_length\n",
    "    # Shape of rewards: (num_tau_prime_samples x batch_size) x 1.\n",
    "    rewards = rewards[:, None]\n",
    "    rewards = np.tile(rewards, [num_tau_prime_samples, 1])\n",
    "\n",
    "    is_terminal_multiplier = 1. - terminals.astype(np.float32) #tf.to_float(terminals)\n",
    "    # Incorporate terminal state to discount factor.\n",
    "    # size of gamma_with_terminal: (num_tau_prime_samples x batch_size) x 1.\n",
    "    gamma_with_terminal = gamma * is_terminal_multiplier\n",
    "    gamma_with_terminal = np.tile(gamma_with_terminal[:, None],\n",
    "                                  [num_tau_prime_samples, 1])\n",
    "\n",
    "    # Get the indices of the maximium Q-value across the action dimension.\n",
    "    # Shape of replay_next_qt_argmax: (num_tau_prime_samples x batch_size) x 1.\n",
    "\n",
    "    replay_next_qt_argmax = np.tile(\n",
    "        _replay_next_qt_argmax[:, None], [num_tau_prime_samples, 1])\n",
    "\n",
    "    batch_indices = np.arange(num_tau_prime_samples * num_samples)[:, None].astype(np.int64)\n",
    "    batch_indices = batch_indices * 2\n",
    "    batch_indexed_target_values = batch_indices + replay_next_qt_argmax\n",
    "\n",
    "    target_quantile_values = np.squeeze(np.take(_replay_net_target_quantile_values, \n",
    "                                                batch_indexed_target_values))[:, None]\n",
    "\n",
    "    result = rewards + gamma_with_terminal * target_quantile_values\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EgqereejMEY"
   },
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gasxLf2jMEa"
   },
   "source": [
    "These classes allow us to store experies and sample then randomly to train the network.\n",
    "Episode buffer stores experiences for each individal episode.\n",
    "Experience buffer stores entire episodes of experience, and sample() allows us to get training batches needed from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNdGenWWjMEc"
   },
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = memory_capacity, build_warm_up_state_t=build_warm_up_state_t):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + 1 >= self.buffer_size:\n",
    "            self.buffer[0:(1+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.append(experience)\n",
    "    \n",
    "    def sample(self,batch_size):\n",
    "        sampled_episodes = random.sample(self.buffer,batch_size)\n",
    "        #sampled_episodes = np.array(sampled_episodes)\n",
    "        sampled_episodes = self.processEpisodes(sampled_episodes)\n",
    "        return np.reshape(sampled_episodes,[-1,5])\n",
    "    \n",
    "    def processEpisodes(self,sampled_episodes):\n",
    "        sampledTraces = []\n",
    "        for episode in sampled_episodes:\n",
    "            sampledTraces.append(episode[build_warm_up_state_t:])\n",
    "        sampledTraces = np.array(sampledTraces)\n",
    "        return sampledTraces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZiTkGH9jMEi"
   },
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IMkyUaujMEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#num_episodes: 678000\n",
      "#trace_length: 38\n",
      "#gamma: 0.9998016069840849\n"
     ]
    }
   ],
   "source": [
    "#Setting the training parameters\n",
    "num_layers = 3 # Number of layer of LSTM\n",
    "h_size = 512 #256 #512 #128 #512 #256 #512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "keep_prob = 0.8\n",
    "dropout = 1 - keep_prob  # dropout amount\n",
    "update_freq = 5 #30 #10 #5 #How often to perform a training step.\n",
    "update_online_freq = 5 #10 #5 #3 #5\n",
    "update_target_freq = 1000 #100 #300 #30\n",
    "#gamma = discount_factor #.99 #.95 #1 #Discount factor on the target Q-values\n",
    "gamma = env.get_discount_factor(1) # discount for 1 day\n",
    "startE = 1 #0.1 #1 #Starting chance of random action\n",
    "endE = 0.1 #0.01 #0.1 #Final chance of random action\n",
    "num_epochs = 5\n",
    "num_episodes = env.get_total_num_episodes_per_epoch()*num_epochs #30 #50000 #20000 #100000 #20000 #3000 #20000 #30000 #10000 #4000 #100000 #40000\n",
    "pre_train_episodes = int(memory_capacity * 0.1) # 0.25 300 #300 #200 #600 #200\n",
    "annealing_episodes = int(num_episodes * 0.3) #4*memory_capacity #0.7*memory_capacity #400 #memory_capacity #400\n",
    "pre_exploitation_episodes = int(num_episodes * 0.6)\n",
    "annealing_exploitation_episodes = int(num_episodes * 0.25)\n",
    "exploitationE =  0.01 #0.008 #0.02\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = os.path.join(scriptDirectory, 'savedModel') #The path to save our model to.\n",
    "max_epLength = option_T #env.get_max_episode_time() #option_T + build_warm_up_state_t\n",
    "summaryLength = 100 #Number of epidoes to periodically save for analysis\n",
    "summaryAverageReward = 5000\n",
    "summaryEpoch = env.get_total_num_episodes_per_epoch()\n",
    "tau = 0.001 # learning rate (also referred to as step size) for target network\n",
    "softUpdate = False # use soft or hard updates\n",
    "#trained_model_name = os.path.join(path, 'architecture' + str(architecture) + '-option_T' + str(option_T) + '-history_t' + str(history_t) + '-num_episodes' + str(num_episodes) + '-tau' + str(tau) + '-softUpdate' + str(softUpdate) + '-dropout' + str(dropout) + '-mask' + str(mask_type) + '-dueling_type' + str(dueling_type) + '-So' + str(So) + '-strike_price' + str(strike_price) + '-mu' + str(mu) + '-sigma' + str(sigma) + '-num_seeds' + str(num_seeds))\n",
    "trained_model_name = os.path.join(path, 'IQN_200noSoft_00005_1000freq_128batch_dropout_arch' + str(architecture)\\\n",
    "                    + '-option_T' + str(option_T) + '-history_t' + str(history_t)\\\n",
    "                    #+ '-num_episodes' + str(num_episodes)\\\n",
    "                    + '-softUpdate' + str(softUpdate)  + '-tau' + str(tau)\\\n",
    "                    #+ '-dropout' + str(dropout) + str(apply_dropout)\\\n",
    "                    #+ '-num_layers' + str(num_layers) + '-double_dqn' + str(double_dqn)\\\n",
    "                    + '-huber_loss' + str(huber_loss) #+ '-apply_dropout' + str(apply_dropout)\\\n",
    "                    + '-freq' + str(update_target_freq) + '-batch' + str(batch_size)\\\n",
    "                    + '-capacity' + str(memory_capacity) + '-lambda' + str(learning_rate))\n",
    "final_trained_model_name = trained_model_name + '-final'\n",
    "exploration_type = 'Random'\n",
    "print('#num_episodes: ' + str(num_episodes))\n",
    "print('#trace_length: ' + str(trace_length))\n",
    "#print('#discount_factor: ' + str(discount_factor))\n",
    "print('#gamma: ' + str(gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1499
    },
    "colab_type": "code",
    "id": "qBz1AqJ0jMEp",
    "outputId": "4c1462b9-71c3-4076-fd5e-6a77e91b45c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-4e59edcdea37>:97: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-4e59edcdea37>:116: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6a64076f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6a64076f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6a64076f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6a64076f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51ff3790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51ff3790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51ff3790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51ff3790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a640ed0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a640ed0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a640ed0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a640ed0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a6c261290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a6c261290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a6c261290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a6c261290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51df4210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51df4210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51df4210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51df4210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51bf8790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51bf8790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51bf8790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51bf8790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51bf34d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51bf34d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51bf34d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a51bf34d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-9-4e59edcdea37>:219: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6a51d21810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6a51d21810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6a51d21810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6a51d21810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a640d51d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a640d51d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a640d51d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a640d51d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51fcd790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51fcd790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51fcd790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51fcd790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51af5190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51af5190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51af5190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMBlockCell.call of <tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnCompatibleLSTMCell object at 0x7f6a51af5190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6a511cb4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /misc/scratch05/patx/fathanab/Experiments_RL/normalizeFirstDay_seed_corrected_2019_11_21_shuffled_GBM_version/helper.py:92: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "episode 100: \t0.02668738082612865\t15.46\t1\n",
      "episode 200: \t0.019523625061062578\t14.24\t1\n",
      "episode 300: \t0.02729934260404865\t15.15\t1\n",
      "episode 400: \t0.017618255713650898\t10.15\t1\n",
      "episode 500: \t0.01942349604764346\t13.16\t1\n",
      "episode 600: \t0.02419122273960139\t14.24\t1\n",
      "episode 700: \t0.022833153397962394\t13.89\t1\n",
      "episode 800: \t0.024114046247564646\t14.79\t1\n",
      "episode 900: \t0.025077636665282125\t13.82\t1\n",
      "episode 1000: \t0.022596306462873205\t13.36\t1\n",
      "episode 1100: \t0.02340898102685824\t14.12\t0.9995663716814163\n",
      "episode 1200: \t0.02321209154472305\t12.7\t0.9991238938053104\n",
      "episode 1300: \t0.024537849673210838\t15.5\t0.9986814159292046\n",
      "episode 1400: \t0.014403045376193285\t10.77\t0.9982389380530987\n",
      "episode 1500: \t0.02358231635856408\t11.57\t0.9977964601769929\n",
      "episode 1600: \t0.025892523792981362\t13.57\t0.997353982300887\n",
      "episode 1700: \t0.021892906656756837\t16.27\t0.9969115044247812\n",
      "episode 1800: \t0.01996222794565851\t12.91\t0.9964690265486753\n",
      "episode 1900: \t0.025288536243678474\t14.83\t0.9960265486725695\n",
      "episode 2000: \t0.02059456262238339\t10.79\t0.9955840707964636\n",
      "episode 2100: \t0.0234087725840315\t14.64\t0.9951415929203578\n",
      "episode 2200: \t0.02818252291501453\t15.76\t0.9946991150442519\n",
      "episode 2300: \t0.0231703527238981\t11.57\t0.994256637168146\n",
      "episode 2400: \t0.024820390649902234\t15.53\t0.9938141592920402\n",
      "episode 2500: \t0.02420095844946566\t13.81\t0.9933716814159343\n",
      "episode 2600: \t0.025532917064138818\t14.62\t0.9929292035398285\n",
      "episode 2700: \t0.022263597985015014\t16.53\t0.9924867256637226\n",
      "episode 2800: \t0.024271209655069296\t17.21\t0.9920442477876168\n",
      "episode 2900: \t0.020357964930453755\t13.98\t0.9916017699115109\n",
      "episode 3000: \t0.022885317732774725\t13.93\t0.9911592920354051\n",
      "episode 3100: \t0.018802539448683937\t12.31\t0.9907168141592992\n",
      "episode 3200: \t0.020089693308455073\t14.9\t0.9902743362831934\n",
      "episode 3300: \t0.02582208866077553\t14.68\t0.9898318584070875\n",
      "episode 3400: \t0.024443733099233044\t16.56\t0.9893893805309817\n",
      "episode 3500: \t0.018691268400731032\t13.7\t0.9889469026548758\n",
      "episode 3600: \t0.018867477056436953\t13.59\t0.98850442477877\n",
      "episode 3700: \t0.027452581436957724\t15.58\t0.9880619469026641\n",
      "episode 3800: \t0.018467291177183418\t10.3\t0.9876194690265583\n",
      "episode 3900: \t0.020385997992938228\t15.07\t0.9871769911504524\n",
      "episode 4000: \t0.01814319731644837\t16.4\t0.9867345132743466\n",
      "episode 4100: \t0.016784057168993314\t12.95\t0.9862920353982407\n",
      "episode 4200: \t0.02229723268651393\t13.46\t0.9858495575221349\n",
      "episode 4300: \t0.01767542301641074\t14.35\t0.985407079646029\n",
      "episode 4400: \t0.017557131665998222\t10.62\t0.9849646017699232\n",
      "episode 4500: \t0.024336767401856804\t14.51\t0.9845221238938173\n",
      "episode 4600: \t0.025743221082351685\t15.69\t0.9840796460177115\n",
      "episode 4700: \t0.022648434282840076\t15.66\t0.9836371681416056\n",
      "episode 4800: \t0.022444403107849425\t14.49\t0.9831946902654998\n",
      "episode 4900: \t0.024741169654779793\t15.14\t0.9827522123893939\n",
      "episode 5000: \t0.020161348088325183\t12.58\t0.9823097345132881\n",
      "#Average reward per episode 5000: 0.022335771355007042\n",
      "episode 5100: \t0.020803966714213272\t14.69\t0.9818672566371822\n",
      "episode 5200: \t0.01847605737878107\t12.72\t0.9814247787610764\n",
      "episode 5300: \t0.022012405367492924\t14.58\t0.9809823008849705\n",
      "episode 5400: \t0.02589929993513533\t14.49\t0.9805398230088647\n",
      "episode 5500: \t0.024773651303208202\t15.74\t0.9800973451327588\n",
      "episode 5600: \t0.01964162786463797\t13.01\t0.979654867256653\n",
      "episode 5700: \t0.021344489011618926\t14.24\t0.9792123893805471\n",
      "episode 5800: \t0.02318497852710798\t14.67\t0.9787699115044413\n",
      "episode 5900: \t0.0243486961496074\t13.66\t0.9783274336283354\n",
      "episode 6000: \t0.02256670348105207\t16.55\t0.9778849557522296\n",
      "episode 6100: \t0.023331336265222446\t14.8\t0.9774424778761237\n",
      "episode 6200: \t0.02472004991130876\t16.88\t0.9770000000000179\n",
      "episode 6300: \t0.02298742428562989\t14.01\t0.976557522123912\n",
      "episode 6400: \t0.024360374784402318\t14.58\t0.9761150442478062\n",
      "episode 6500: \t0.02887223142016726\t14.47\t0.9756725663717003\n",
      "episode 6600: \t0.027525371140576446\t14.28\t0.9752300884955944\n",
      "episode 6700: \t0.026254966264172914\t13.0\t0.9747876106194886\n",
      "episode 6800: \t0.01997707597865224\t12.6\t0.9743451327433827\n",
      "episode 6900: \t0.01641975572901036\t10.76\t0.9739026548672769\n",
      "episode 7000: \t0.025812184600819858\t13.75\t0.973460176991171\n",
      "episode 7100: \t0.02392880807779142\t14.71\t0.9730176991150652\n",
      "episode 7200: \t0.023697504209692917\t14.94\t0.9725752212389593\n",
      "episode 7300: \t0.021217194439182113\t13.82\t0.9721327433628535\n",
      "episode 7400: \t0.01947735156333938\t13.26\t0.9716902654867476\n",
      "episode 7500: \t0.019890934144802398\t11.53\t0.9712477876106418\n",
      "episode 7600: \t0.017958997270587317\t11.51\t0.9708053097345359\n",
      "episode 7700: \t0.02022456375939129\t13.56\t0.9703628318584301\n",
      "episode 7800: \t0.022042079207810136\t15.97\t0.9699203539823242\n",
      "episode 7900: \t0.023570450623778823\t16.09\t0.9694778761062184\n",
      "episode 8000: \t0.015559039637431651\t12.67\t0.9690353982301125\n",
      "episode 8100: \t0.022066172093965174\t12.16\t0.9685929203540067\n",
      "episode 8200: \t0.023228473358996752\t15.67\t0.9681504424779008\n",
      "episode 8300: \t0.025304306918389877\t14.9\t0.967707964601795\n",
      "episode 8400: \t0.02355245073735866\t14.01\t0.9672654867256891\n",
      "episode 8500: \t0.022306791585582714\t12.32\t0.9668230088495833\n",
      "episode 8600: \t0.022951502135869543\t14.22\t0.9663805309734774\n",
      "episode 8700: \t0.021343604980057697\t11.49\t0.9659380530973716\n",
      "episode 8800: \t0.024374685071640947\t14.1\t0.9654955752212657\n",
      "episode 8900: \t0.019406840709689403\t13.27\t0.9650530973451599\n",
      "episode 9000: \t0.02324728340589263\t14.7\t0.964610619469054\n",
      "episode 9100: \t0.024664767055149528\t17.77\t0.9641681415929482\n",
      "episode 9200: \t0.02396172917578576\t14.75\t0.9637256637168423\n",
      "episode 9300: \t0.02268544128961333\t13.34\t0.9632831858407365\n",
      "episode 9400: \t0.027551815057882866\t16.62\t0.9628407079646306\n",
      "episode 9500: \t0.018537381014061487\t12.03\t0.9623982300885248\n",
      "episode 9600: \t0.02627981162481039\t15.4\t0.9619557522124189\n",
      "episode 9700: \t0.0201179769099884\t11.31\t0.9615132743363131\n",
      "episode 9800: \t0.02008968007141792\t12.24\t0.9610707964602072\n",
      "episode 9900: \t0.024781923662992696\t15.74\t0.9606283185841014\n",
      "episode 10000: \t0.017878077974136618\t13.31\t0.9601858407079955\n",
      "#Average reward per episode 10000: 0.022419988516302614\n",
      "Saved Model\n",
      "#Intermediate time to execute: 90.57276029189428min\n",
      "episode 10100: \t0.021611589784284325\t13.62\t0.9597433628318897\n",
      "episode 10200: \t0.027610381014467646\t17.22\t0.9593008849557838\n",
      "episode 10300: \t0.021726933366670448\t14.31\t0.958858407079678\n",
      "episode 10400: \t0.021763479355134768\t12.67\t0.9584159292035721\n",
      "episode 10500: \t0.022017629954637245\t13.37\t0.9579734513274663\n",
      "episode 10600: \t0.025836094002592843\t15.46\t0.9575309734513604\n",
      "episode 10700: \t0.02092288786416696\t13.15\t0.9570884955752545\n",
      "episode 10800: \t0.024881168507646198\t13.29\t0.9566460176991487\n",
      "episode 10900: \t0.023204035242467284\t14.09\t0.9562035398230428\n",
      "episode 11000: \t0.025472403327339133\t12.68\t0.955761061946937\n",
      "episode 11100: \t0.02008511520870477\t12.03\t0.9553185840708311\n",
      "episode 11200: \t0.027837002778282858\t15.69\t0.9548761061947253\n",
      "episode 11300: \t0.024017622869426526\t13.12\t0.9544336283186194\n",
      "episode 11400: \t0.025303267043688835\t16.4\t0.9539911504425136\n",
      "episode 11500: \t0.033151028468760876\t15.56\t0.9535486725664077\n",
      "episode 11600: \t0.01659649878917486\t12.83\t0.9531061946903019\n",
      "episode 11700: \t0.02839719659944313\t15.68\t0.952663716814196\n",
      "episode 11800: \t0.027507256652182902\t15.35\t0.9522212389380902\n",
      "episode 11900: \t0.0251529857074457\t13.28\t0.9517787610619843\n",
      "episode 12000: \t0.018710496398802175\t12.43\t0.9513362831858785\n",
      "episode 12100: \t0.023227208271192668\t15.57\t0.9508938053097726\n",
      "episode 12200: \t0.017386208197702556\t12.3\t0.9504513274336668\n",
      "episode 12300: \t0.027952693546650767\t15.37\t0.9500088495575609\n",
      "episode 12400: \t0.02030039541658111\t13.47\t0.9495663716814551\n",
      "episode 12500: \t0.028013314259067394\t16.58\t0.9491238938053492\n",
      "episode 12600: \t0.0295951578629431\t15.05\t0.9486814159292434\n",
      "episode 12700: \t0.02944882195113912\t15.51\t0.9482389380531375\n",
      "episode 12800: \t0.02618751702667818\t14.2\t0.9477964601770317\n",
      "episode 12900: \t0.02526233645796809\t12.34\t0.9473539823009258\n",
      "episode 13000: \t0.021976362120267975\t14.08\t0.94691150442482\n",
      "episode 13100: \t0.024618599104929514\t13.74\t0.9464690265487141\n",
      "episode 13200: \t0.023536272233782476\t12.06\t0.9460265486726083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13300: \t0.02781998116855742\t17.39\t0.9455840707965024\n",
      "episode 13400: \t0.026145757517327627\t16.46\t0.9451415929203966\n",
      "episode 13500: \t0.02465797505993133\t15.3\t0.9446991150442907\n",
      "episode 13600: \t0.022656935383443412\t14.18\t0.9442566371681849\n",
      "episode 13700: \t0.016060625538060206\t12.02\t0.943814159292079\n",
      "episode 13800: \t0.027508844212731202\t14.28\t0.9433716814159732\n",
      "episode 13900: \t0.021526739689695394\t14.3\t0.9429292035398673\n",
      "episode 14000: \t0.02122854854146171\t14.22\t0.9424867256637615\n",
      "episode 14100: \t0.020089310559900913\t12.81\t0.9420442477876556\n",
      "episode 14200: \t0.020565027610306697\t13.49\t0.9416017699115498\n",
      "episode 14300: \t0.025875782111007103\t13.08\t0.9411592920354439\n",
      "episode 14400: \t0.020014435593468473\t15.25\t0.940716814159338\n",
      "episode 14500: \t0.02261916565300188\t14.04\t0.9402743362832322\n",
      "episode 14600: \t0.028531071007459486\t14.36\t0.9398318584071264\n",
      "episode 14700: \t0.025779573380654366\t13.75\t0.9393893805310205\n",
      "episode 14800: \t0.023351653250257776\t14.23\t0.9389469026549147\n",
      "episode 14900: \t0.023705775538407962\t14.74\t0.9385044247788088\n",
      "episode 15000: \t0.02300048842159417\t13.4\t0.938061946902703\n",
      "#Average reward per episode 15000: 0.02294964334167833\n",
      "episode 15100: \t0.018999425671837523\t12.76\t0.9376194690265971\n",
      "episode 15200: \t0.025879551104765336\t13.41\t0.9371769911504912\n",
      "episode 15300: \t0.026360293821628553\t15.59\t0.9367345132743854\n",
      "episode 15400: \t0.018628014831935\t14.53\t0.9362920353982795\n",
      "episode 15500: \t0.024526493722376266\t14.54\t0.9358495575221737\n",
      "episode 15600: \t0.025070716199710685\t15.79\t0.9354070796460678\n",
      "episode 15700: \t0.022541840198276382\t15.53\t0.934964601769962\n",
      "episode 15800: \t0.02861054244973601\t15.0\t0.9345221238938561\n",
      "episode 15900: \t0.03088475802667436\t16.4\t0.9340796460177503\n",
      "episode 16000: \t0.02149059830469859\t12.34\t0.9336371681416444\n",
      "episode 16100: \t0.022003090185724897\t14.14\t0.9331946902655386\n",
      "episode 16200: \t0.025953530029030294\t15.67\t0.9327522123894327\n",
      "episode 16300: \t0.022505483271986225\t15.77\t0.9323097345133269\n",
      "episode 16400: \t0.0243765075536975\t15.69\t0.931867256637221\n",
      "episode 16500: \t0.02014701418939671\t14.0\t0.9314247787611152\n",
      "episode 16600: \t0.022946286692430384\t14.79\t0.9309823008850093\n",
      "episode 16700: \t0.02071851871351699\t13.95\t0.9305398230089035\n",
      "episode 16800: \t0.018601581437067617\t13.27\t0.9300973451327976\n",
      "episode 16900: \t0.024397121764161936\t14.11\t0.9296548672566918\n",
      "episode 17000: \t0.023134994839305114\t14.8\t0.9292123893805859\n",
      "episode 17100: \t0.02161862394490236\t15.76\t0.9287699115044801\n",
      "episode 17200: \t0.02161969237880113\t14.31\t0.9283274336283742\n",
      "episode 17300: \t0.017780817361736603\t12.08\t0.9278849557522684\n",
      "episode 17400: \t0.022750029068918706\t13.13\t0.9274424778761625\n",
      "episode 17500: \t0.025697455933313046\t12.97\t0.9270000000000567\n",
      "episode 17600: \t0.02458122275915344\t13.09\t0.9265575221239508\n",
      "episode 17700: \t0.02185162687896522\t13.57\t0.926115044247845\n",
      "episode 17800: \t0.025504626002691023\t14.72\t0.9256725663717391\n",
      "episode 17900: \t0.026014238852355192\t14.79\t0.9252300884956333\n",
      "episode 18000: \t0.025728994172721575\t15.49\t0.9247876106195274\n",
      "episode 18100: \t0.025750866283624444\t12.94\t0.9243451327434216\n",
      "episode 18200: \t0.025544148341824308\t13.49\t0.9239026548673157\n",
      "episode 18300: \t0.026836103961998124\t15.23\t0.9234601769912099\n",
      "episode 18400: \t0.025128688033311353\t13.13\t0.923017699115104\n",
      "episode 18500: \t0.027375049981020024\t15.16\t0.9225752212389982\n",
      "episode 18600: \t0.025187027274396874\t14.71\t0.9221327433628923\n",
      "episode 18700: \t0.0204758934226144\t13.32\t0.9216902654867865\n",
      "episode 18800: \t0.021733051179943116\t13.48\t0.9212477876106806\n",
      "episode 18900: \t0.027064711976645967\t13.99\t0.9208053097345748\n",
      "episode 19000: \t0.023126642295899353\t13.38\t0.9203628318584689\n",
      "episode 19100: \t0.02070434506033834\t12.46\t0.919920353982363\n",
      "episode 19200: \t0.02587351712220947\t14.11\t0.9194778761062572\n",
      "episode 19300: \t0.023836949846550947\t15.02\t0.9190353982301513\n",
      "episode 19400: \t0.023855134549706575\t14.28\t0.9185929203540455\n",
      "episode 19500: \t0.025756731601070414\t13.74\t0.9181504424779396\n",
      "episode 19600: \t0.02234967169230102\t13.98\t0.9177079646018338\n",
      "episode 19700: \t0.02441511948184221\t13.65\t0.9172654867257279\n",
      "episode 19800: \t0.024520684581415965\t17.28\t0.9168230088496221\n",
      "episode 19900: \t0.02221974119353264\t13.33\t0.9163805309735162\n",
      "episode 20000: \t0.022864038945291033\t14.78\t0.9159380530974104\n",
      "#Average reward per episode 20000: 0.023139941542193957\n",
      "Saved Model\n",
      "#Intermediate time to execute: 198.16395167509714min\n",
      "episode 20100: \t0.019150293794219172\t14.26\t0.9154955752213045\n",
      "episode 20200: \t0.024372947447335123\t13.46\t0.9150530973451987\n",
      "episode 20300: \t0.0225632724074754\t11.71\t0.9146106194690928\n",
      "episode 20400: \t0.02104225875492208\t14.69\t0.914168141592987\n",
      "episode 20500: \t0.018758767368467863\t12.49\t0.9137256637168811\n",
      "episode 20600: \t0.02223170581639152\t13.48\t0.9132831858407753\n",
      "episode 20700: \t0.020974565627201788\t13.61\t0.9128407079646694\n",
      "episode 20800: \t0.02349303751921472\t13.88\t0.9123982300885636\n",
      "episode 20900: \t0.030412333527212246\t16.53\t0.9119557522124577\n",
      "episode 21000: \t0.025494298510580292\t14.45\t0.9115132743363519\n",
      "episode 21100: \t0.02281447452529825\t11.57\t0.911070796460246\n",
      "episode 21200: \t0.02715542928532484\t16.11\t0.9106283185841402\n",
      "episode 21300: \t0.018975529648787223\t14.16\t0.9101858407080343\n",
      "episode 21400: \t0.02428802147514932\t15.82\t0.9097433628319285\n",
      "episode 21500: \t0.021318745155328313\t15.29\t0.9093008849558226\n",
      "episode 21600: \t0.019531411209422502\t11.7\t0.9088584070797168\n",
      "episode 21700: \t0.025364627876879133\t14.92\t0.9084159292036109\n",
      "episode 21800: \t0.02283092383923441\t14.68\t0.9079734513275051\n",
      "episode 21900: \t0.020551634624562633\t15.11\t0.9075309734513992\n",
      "episode 22000: \t0.02404543209059208\t13.56\t0.9070884955752934\n",
      "episode 22100: \t0.02470772041013214\t14.4\t0.9066460176991875\n",
      "episode 22200: \t0.020724791751654995\t13.59\t0.9062035398230817\n",
      "episode 22300: \t0.02059013380532937\t15.45\t0.9057610619469758\n",
      "episode 22400: \t0.022850893807514244\t12.94\t0.90531858407087\n",
      "episode 22500: \t0.020170095812902623\t13.18\t0.9048761061947641\n",
      "episode 22600: \t0.015984064952240463\t12.94\t0.9044336283186583\n",
      "episode 22700: \t0.02436885221670826\t14.18\t0.9039911504425524\n",
      "episode 22800: \t0.02193529356854283\t14.21\t0.9035486725664466\n",
      "episode 22900: \t0.023732786677561856\t14.86\t0.9031061946903407\n",
      "episode 23000: \t0.021767183748036753\t14.93\t0.9026637168142349\n",
      "episode 23100: \t0.026914261145553356\t16.03\t0.902221238938129\n",
      "episode 23200: \t0.02532457491927666\t16.9\t0.9017787610620231\n",
      "episode 23300: \t0.020143170814529814\t12.36\t0.9013362831859173\n",
      "episode 23400: \t0.03091003896539739\t16.65\t0.9008938053098114\n",
      "episode 23500: \t0.020957972466332006\t12.93\t0.9004513274337056\n",
      "episode 23600: \t0.019516635367971352\t14.48\t0.9000088495575997\n",
      "episode 23700: \t0.02706703069739682\t16.88\t0.8995663716814939\n",
      "episode 23800: \t0.022495796104006854\t14.42\t0.899123893805388\n",
      "episode 23900: \t0.026988673152173376\t15.85\t0.8986814159292822\n",
      "episode 24000: \t0.017079594016523165\t12.85\t0.8982389380531763\n",
      "episode 24100: \t0.02603009841080335\t15.96\t0.8977964601770705\n",
      "episode 24200: \t0.02013613238665535\t12.85\t0.8973539823009646\n",
      "episode 24300: \t0.02301994236390062\t15.58\t0.8969115044248588\n",
      "episode 24400: \t0.023958450528064387\t16.98\t0.8964690265487529\n",
      "episode 24500: \t0.023910274274717085\t13.99\t0.8960265486726471\n",
      "episode 24600: \t0.026092912284337157\t17.04\t0.8955840707965412\n",
      "episode 24700: \t0.028217375576936377\t14.38\t0.8951415929204354\n",
      "episode 24800: \t0.02057647347817841\t14.73\t0.8946991150443295\n",
      "episode 24900: \t0.024396658152933723\t15.94\t0.8942566371682237\n",
      "episode 25000: \t0.021980762629690922\t15.26\t0.8938141592921178\n",
      "#Average reward per episode 25000: 0.023103626653713585\n",
      "episode 25100: \t0.014464233803883864\t12.28\t0.893371681416012\n",
      "episode 25200: \t0.022589442477432442\t14.17\t0.8929292035399061\n",
      "episode 25300: \t0.024133522995542424\t14.14\t0.8924867256638003\n",
      "episode 25400: \t0.028922064867033387\t16.63\t0.8920442477876944\n",
      "episode 25500: \t0.02264061511131232\t14.02\t0.8916017699115886\n",
      "episode 25600: \t0.022282343897141173\t13.29\t0.8911592920354827\n",
      "episode 25700: \t0.02378566822846807\t15.08\t0.8907168141593769\n",
      "episode 25800: \t0.018480467293291544\t12.28\t0.890274336283271\n",
      "episode 25900: \t0.021892770360997734\t13.29\t0.8898318584071652\n",
      "episode 26000: \t0.021619382352827673\t15.14\t0.8893893805310593\n",
      "episode 26100: \t0.021610999772382497\t14.38\t0.8889469026549535\n",
      "episode 26200: \t0.01888593661506547\t13.5\t0.8885044247788476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 26300: \t0.02182741969395523\t13.19\t0.8880619469027418\n",
      "episode 26400: \t0.0234714077007689\t14.07\t0.8876194690266359\n",
      "episode 26500: \t0.025725775043221974\t14.89\t0.8871769911505301\n",
      "episode 26600: \t0.027692820500315705\t16.24\t0.8867345132744242\n",
      "episode 26700: \t0.024173636360212195\t13.03\t0.8862920353983184\n",
      "episode 26800: \t0.030052616646590983\t18.81\t0.8858495575222125\n",
      "episode 26900: \t0.022082808278905203\t11.78\t0.8854070796461067\n",
      "episode 27000: \t0.020537328781682698\t14.08\t0.8849646017700008\n",
      "episode 27100: \t0.01839293255556542\t14.27\t0.884522123893895\n",
      "episode 27200: \t0.024931136352096414\t14.47\t0.8840796460177891\n",
      "episode 27300: \t0.019890775477141045\t12.9\t0.8836371681416832\n",
      "episode 27400: \t0.02295492295678598\t14.43\t0.8831946902655774\n",
      "episode 27500: \t0.02560931387739799\t15.7\t0.8827522123894715\n",
      "episode 27600: \t0.026871642494974868\t15.16\t0.8823097345133657\n",
      "episode 27700: \t0.023489088660246585\t14.54\t0.8818672566372598\n",
      "episode 27800: \t0.026138122334697467\t15.22\t0.881424778761154\n",
      "episode 27900: \t0.02365383285900957\t14.31\t0.8809823008850481\n",
      "episode 28000: \t0.0289281981237539\t15.54\t0.8805398230089423\n",
      "episode 28100: \t0.022869944207557887\t15.09\t0.8800973451328364\n",
      "episode 28200: \t0.022785459533445396\t14.45\t0.8796548672567306\n",
      "episode 28300: \t0.023352569430597835\t14.27\t0.8792123893806247\n",
      "episode 28400: \t0.018985354399391304\t13.11\t0.8787699115045189\n",
      "episode 28500: \t0.02689355442862645\t15.9\t0.878327433628413\n",
      "episode 28600: \t0.02493698246789654\t15.52\t0.8778849557523072\n",
      "episode 28700: \t0.019791673936355624\t13.69\t0.8774424778762013\n",
      "episode 28800: \t0.017773994290070018\t11.63\t0.8770000000000955\n",
      "episode 28900: \t0.02334034052794095\t13.71\t0.8765575221239896\n",
      "episode 29000: \t0.01789123197643331\t12.37\t0.8761150442478838\n",
      "episode 29100: \t0.02055183103745302\t15.62\t0.8756725663717779\n",
      "episode 29200: \t0.029243809515861953\t16.27\t0.8752300884956721\n",
      "episode 29300: \t0.02140184805035168\t13.68\t0.8747876106195662\n",
      "episode 29400: \t0.02380612357521543\t15.82\t0.8743451327434604\n",
      "episode 29500: \t0.02313281759278873\t15.38\t0.8739026548673545\n",
      "episode 29600: \t0.021228641739807354\t10.85\t0.8734601769912487\n",
      "episode 29700: \t0.02581661483061991\t16.51\t0.8730176991151428\n",
      "episode 29800: \t0.021892887397056925\t13.41\t0.872575221239037\n",
      "episode 29900: \t0.02442249653509455\t15.58\t0.8721327433629311\n",
      "episode 30000: \t0.02159083874529333\t12.21\t0.8716902654868253\n",
      "#Average reward per episode 30000: 0.023084489680396593\n",
      "Saved Model\n",
      "#Intermediate time to execute: 302.05423503716787min\n",
      "episode 30100: \t0.028225771087506468\t14.11\t0.8712477876107194\n",
      "episode 30200: \t0.023627678617224323\t14.45\t0.8708053097346136\n",
      "episode 30300: \t0.025737545461146878\t14.81\t0.8703628318585077\n",
      "episode 30400: \t0.02456692569527099\t13.28\t0.8699203539824019\n",
      "episode 30500: \t0.026623530162689514\t15.34\t0.869477876106296\n",
      "episode 30600: \t0.017156145198754514\t12.98\t0.8690353982301902\n",
      "episode 30700: \t0.02618938401613397\t16.42\t0.8685929203540843\n",
      "episode 30800: \t0.021161811874302657\t12.09\t0.8681504424779785\n",
      "episode 30900: \t0.02562918334142087\t14.94\t0.8677079646018726\n",
      "episode 31000: \t0.020834324140719666\t15.24\t0.8672654867257668\n",
      "episode 31100: \t0.024502898544165125\t16.34\t0.8668230088496609\n",
      "episode 31200: \t0.01935907678290407\t11.46\t0.866380530973555\n",
      "episode 31300: \t0.026587274952741314\t16.83\t0.8659380530974492\n",
      "episode 31400: \t0.021535959144442365\t11.55\t0.8654955752213433\n",
      "episode 31500: \t0.022884227950154837\t13.16\t0.8650530973452375\n",
      "episode 31600: \t0.024661994415100783\t14.16\t0.8646106194691316\n",
      "episode 31700: \t0.01855795774293777\t12.2\t0.8641681415930258\n",
      "episode 31800: \t0.023488288370784344\t13.09\t0.86372566371692\n",
      "episode 31900: \t0.021469210821363997\t14.16\t0.8632831858408141\n",
      "episode 32000: \t0.023389655002938034\t15.64\t0.8628407079647082\n",
      "episode 32100: \t0.02508979846766669\t14.27\t0.8623982300886024\n",
      "episode 32200: \t0.02416158437716186\t15.78\t0.8619557522124965\n",
      "episode 32300: \t0.019566648561442496\t13.3\t0.8615132743363907\n",
      "episode 32400: \t0.02871297385925732\t16.82\t0.8610707964602848\n",
      "episode 32500: \t0.024497299817530915\t15.45\t0.860628318584179\n",
      "episode 32600: \t0.02614944700148152\t15.28\t0.8601858407080731\n",
      "episode 32700: \t0.027181867728049768\t15.07\t0.8597433628319673\n",
      "episode 32800: \t0.019373359024769114\t12.71\t0.8593008849558614\n",
      "episode 32900: \t0.021896467559176694\t15.38\t0.8588584070797556\n",
      "episode 33000: \t0.022908789870684537\t14.47\t0.8584159292036497\n",
      "episode 33100: \t0.02337404611549677\t14.69\t0.8579734513275439\n",
      "episode 33200: \t0.022248477594206836\t13.92\t0.857530973451438\n",
      "episode 33300: \t0.0198532798093896\t13.45\t0.8570884955753322\n",
      "episode 33400: \t0.025946395564246702\t14.02\t0.8566460176992263\n",
      "episode 33500: \t0.02590051340645789\t15.46\t0.8562035398231205\n",
      "episode 33600: \t0.021892932629283553\t14.1\t0.8557610619470146\n",
      "episode 33700: \t0.019922125391835657\t13.01\t0.8553185840709088\n",
      "episode 33800: \t0.0262943739500732\t15.33\t0.8548761061948029\n",
      "episode 33900: \t0.025212718445750692\t15.0\t0.8544336283186971\n",
      "episode 34000: \t0.02332250787597106\t13.75\t0.8539911504425912\n",
      "episode 34100: \t0.025325024402234376\t13.69\t0.8535486725664854\n",
      "episode 34200: \t0.02171527969801764\t12.79\t0.8531061946903795\n",
      "episode 34300: \t0.026739646410757677\t16.02\t0.8526637168142737\n",
      "episode 34400: \t0.029628221888647138\t13.89\t0.8522212389381678\n",
      "episode 34500: \t0.024183512109893023\t13.74\t0.851778761062062\n",
      "episode 34600: \t0.027939651751384863\t15.89\t0.8513362831859561\n",
      "episode 34700: \t0.019658885541749042\t13.4\t0.8508938053098503\n",
      "episode 34800: \t0.019429689826347286\t14.68\t0.8504513274337444\n",
      "episode 34900: \t0.020404621514240665\t15.47\t0.8500088495576386\n",
      "episode 35000: \t0.029038097245001865\t15.45\t0.8495663716815327\n",
      "#Average reward per episode 35000: 0.023168868528228304\n",
      "episode 35100: \t0.023022818459939406\t12.24\t0.8491238938054269\n",
      "episode 35200: \t0.021441386961257337\t14.7\t0.848681415929321\n",
      "episode 35300: \t0.025320978349621336\t14.01\t0.8482389380532152\n",
      "episode 35400: \t0.024448092117672373\t14.66\t0.8477964601771093\n",
      "episode 35500: \t0.02477670746472111\t15.04\t0.8473539823010034\n",
      "episode 35600: \t0.018704975364923625\t10.0\t0.8469115044248976\n",
      "episode 35700: \t0.025102107276479102\t15.7\t0.8464690265487917\n",
      "episode 35800: \t0.022870889758641662\t13.93\t0.8460265486726859\n",
      "episode 35900: \t0.021832702613568476\t13.59\t0.84558407079658\n",
      "episode 36000: \t0.02007744891186469\t11.73\t0.8451415929204742\n",
      "episode 36100: \t0.022115998956991054\t13.07\t0.8446991150443683\n",
      "episode 36200: \t0.023381426805651098\t13.75\t0.8442566371682625\n",
      "episode 36300: \t0.02126883605804733\t12.48\t0.8438141592921566\n",
      "episode 36400: \t0.029000918575042712\t17.6\t0.8433716814160508\n",
      "episode 36500: \t0.025048945093312694\t16.03\t0.8429292035399449\n",
      "episode 36600: \t0.023313556198558582\t12.77\t0.8424867256638391\n",
      "episode 36700: \t0.02476935165953039\t14.51\t0.8420442477877332\n",
      "episode 36800: \t0.020429876799289252\t15.0\t0.8416017699116274\n",
      "episode 36900: \t0.02485601750144076\t15.48\t0.8411592920355215\n",
      "episode 37000: \t0.025276987328705775\t14.87\t0.8407168141594157\n",
      "episode 37100: \t0.025583860653504396\t14.76\t0.8402743362833098\n",
      "episode 37200: \t0.02140044222171668\t12.31\t0.839831858407204\n",
      "episode 37300: \t0.02521005450901124\t14.56\t0.8393893805310981\n",
      "episode 37400: \t0.018390420768788905\t12.76\t0.8389469026549923\n",
      "episode 37500: \t0.02546215832072255\t15.55\t0.8385044247788864\n",
      "episode 37600: \t0.019326105595318624\t13.98\t0.8380619469027806\n",
      "episode 37700: \t0.020724677332697398\t13.72\t0.8376194690266747\n",
      "episode 37800: \t0.020082133711438962\t12.62\t0.8371769911505689\n",
      "episode 37900: \t0.01627856764050535\t13.17\t0.836734513274463\n",
      "episode 38000: \t0.025580869913169314\t16.16\t0.8362920353983572\n",
      "episode 38100: \t0.0221955635026378\t13.91\t0.8358495575222513\n",
      "episode 38200: \t0.02623829394389599\t13.49\t0.8354070796461455\n",
      "episode 38300: \t0.020308168758032034\t13.73\t0.8349646017700396\n",
      "episode 38400: \t0.021505198199727314\t14.1\t0.8345221238939338\n",
      "episode 38500: \t0.021092491786602018\t12.01\t0.8340796460178279\n",
      "episode 38600: \t0.019686384230774828\t12.27\t0.8336371681417221\n",
      "episode 38700: \t0.025499451638022183\t14.06\t0.8331946902656162\n",
      "episode 38800: \t0.028064633570790837\t14.9\t0.8327522123895104\n",
      "episode 38900: \t0.021970950698605964\t11.93\t0.8323097345134045\n",
      "episode 39000: \t0.02279284982352424\t14.06\t0.8318672566372987\n",
      "episode 39100: \t0.02448918217166797\t15.1\t0.8314247787611928\n",
      "episode 39200: \t0.021973324929654744\t13.8\t0.830982300885087\n",
      "episode 39300: \t0.022739629092487227\t14.37\t0.8305398230089811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 39400: \t0.023723563635277393\t14.71\t0.8300973451328753\n",
      "episode 39500: \t0.022605890908350385\t13.05\t0.8296548672567694\n",
      "episode 39600: \t0.023994055893887648\t14.31\t0.8292123893806636\n",
      "episode 39700: \t0.02285938604903077\t12.04\t0.8287699115045577\n",
      "episode 39800: \t0.025116809421428465\t14.61\t0.8283274336284518\n",
      "episode 39900: \t0.018458905546376417\t12.68\t0.827884955752346\n",
      "episode 40000: \t0.0211188361450162\t12.41\t0.8274424778762401\n",
      "#Average reward per episode 40000: 0.023126592169369617\n",
      "Saved Model\n",
      "#Intermediate time to execute: 407.5554559548696min\n",
      "episode 40100: \t0.023673242967481092\t14.21\t0.8270000000001343\n",
      "episode 40200: \t0.019580487461224226\t14.37\t0.8265575221240284\n",
      "episode 40300: \t0.021571407943263655\t15.52\t0.8261150442479226\n",
      "episode 40400: \t0.020657382394509174\t14.72\t0.8256725663718167\n",
      "episode 40500: \t0.022937961277857067\t13.55\t0.8252300884957109\n",
      "episode 40600: \t0.019946048591260587\t13.5\t0.824787610619605\n",
      "episode 40700: \t0.019890948667389358\t15.02\t0.8243451327434992\n",
      "episode 40800: \t0.025236141920268716\t13.05\t0.8239026548673933\n",
      "episode 40900: \t0.024847540859925524\t16.29\t0.8234601769912875\n",
      "episode 41000: \t0.02185628624506702\t14.53\t0.8230176991151816\n",
      "episode 41100: \t0.02137628980256704\t15.73\t0.8225752212390758\n",
      "episode 41200: \t0.026893008510622728\t13.34\t0.8221327433629699\n",
      "episode 41300: \t0.021131614717026567\t12.85\t0.8216902654868641\n",
      "episode 41400: \t0.027551776943966298\t15.51\t0.8212477876107582\n",
      "episode 41500: \t0.018866926597260733\t12.8\t0.8208053097346524\n",
      "episode 41600: \t0.023231494159620666\t11.91\t0.8203628318585465\n",
      "episode 41700: \t0.020327138589074187\t13.54\t0.8199203539824407\n",
      "episode 41800: \t0.025156491986641098\t15.47\t0.8194778761063348\n",
      "episode 41900: \t0.024044715291617322\t11.32\t0.819035398230229\n",
      "episode 42000: \t0.022494702667103364\t13.15\t0.8185929203541231\n",
      "episode 42100: \t0.02284099102724471\t14.04\t0.8181504424780173\n",
      "episode 42200: \t0.021460957777488385\t11.6\t0.8177079646019114\n",
      "episode 42300: \t0.025638527589581808\t14.23\t0.8172654867258056\n",
      "episode 42400: \t0.027991414043234814\t16.48\t0.8168230088496997\n",
      "episode 42500: \t0.02338409140580434\t12.09\t0.8163805309735939\n",
      "episode 42600: \t0.021545389983586873\t15.33\t0.815938053097488\n",
      "episode 42700: \t0.02343339667396522\t15.81\t0.8154955752213822\n",
      "episode 42800: \t0.02132505541582684\t13.52\t0.8150530973452763\n",
      "episode 42900: \t0.032616958420282546\t17.73\t0.8146106194691705\n",
      "episode 43000: \t0.026234509771425253\t15.0\t0.8141681415930646\n",
      "episode 43100: \t0.02450437661616437\t15.64\t0.8137256637169588\n",
      "episode 43200: \t0.02068653918668772\t12.27\t0.8132831858408529\n",
      "episode 43300: \t0.027664859454515377\t16.42\t0.8128407079647471\n",
      "episode 43400: \t0.022667398384429802\t13.48\t0.8123982300886412\n",
      "episode 43500: \t0.02085354120155277\t12.96\t0.8119557522125354\n",
      "episode 43600: \t0.02659874337609237\t15.35\t0.8115132743364295\n",
      "episode 43700: \t0.02225721539794763\t11.61\t0.8110707964603237\n",
      "episode 43800: \t0.022192774749531154\t14.77\t0.8106283185842178\n",
      "episode 43900: \t0.023778883674254545\t14.19\t0.810185840708112\n",
      "episode 44000: \t0.026033082101710053\t12.33\t0.8097433628320061\n",
      "episode 44100: \t0.024554960110691994\t13.79\t0.8093008849559002\n",
      "episode 44200: \t0.034987069122327845\t16.39\t0.8088584070797944\n",
      "episode 44300: \t0.018996298383844718\t11.59\t0.8084159292036885\n",
      "episode 44400: \t0.026463923631309005\t14.87\t0.8079734513275827\n",
      "episode 44500: \t0.024262426903294124\t14.37\t0.8075309734514768\n",
      "episode 44600: \t0.02829434327082209\t13.74\t0.807088495575371\n",
      "episode 44700: \t0.02841209087128344\t16.38\t0.8066460176992651\n",
      "episode 44800: \t0.01765406669349377\t11.2\t0.8062035398231593\n",
      "episode 44900: \t0.02242311866203621\t15.8\t0.8057610619470534\n",
      "episode 45000: \t0.02391080539496344\t13.62\t0.8053185840709476\n",
      "#Average reward per episode 45000: 0.023190169521415505\n",
      "episode 45100: \t0.026611271571198497\t13.55\t0.8048761061948417\n",
      "episode 45200: \t0.023155805227911132\t14.19\t0.8044336283187359\n",
      "episode 45300: \t0.021118848025096167\t14.66\t0.80399115044263\n",
      "episode 45400: \t0.02538035852108264\t13.67\t0.8035486725665242\n",
      "episode 45500: \t0.021475059906141993\t13.82\t0.8031061946904183\n",
      "episode 45600: \t0.026519546207701285\t13.45\t0.8026637168143125\n",
      "episode 45700: \t0.027965555464908896\t15.19\t0.8022212389382066\n",
      "episode 45800: \t0.022933027263409605\t12.68\t0.8017787610621008\n",
      "episode 45900: \t0.02482387983857163\t16.32\t0.8013362831859949\n",
      "episode 46000: \t0.02164126089085511\t14.72\t0.8008938053098891\n",
      "episode 46100: \t0.023253593358361205\t13.7\t0.8004513274337832\n",
      "episode 46200: \t0.01978956432175481\t13.19\t0.8000088495576774\n",
      "episode 46300: \t0.021643344414356537\t14.92\t0.7995663716815715\n",
      "episode 46400: \t0.028767534185804005\t14.07\t0.7991238938054657\n",
      "episode 46500: \t0.02200590337086133\t14.5\t0.7986814159293598\n",
      "episode 46600: \t0.02105503823188004\t12.84\t0.798238938053254\n",
      "episode 46700: \t0.023090072806472885\t13.82\t0.7977964601771481\n",
      "episode 46800: \t0.0262305329394922\t15.18\t0.7973539823010423\n",
      "episode 46900: \t0.022567135260731418\t14.05\t0.7969115044249364\n",
      "episode 47000: \t0.03336204396359109\t16.6\t0.7964690265488306\n",
      "episode 47100: \t0.022186468894068553\t13.16\t0.7960265486727247\n",
      "episode 47200: \t0.02455990105073984\t13.06\t0.7955840707966189\n",
      "episode 47300: \t0.025764554030018528\t15.82\t0.795141592920513\n",
      "episode 47400: \t0.028537549561361245\t15.18\t0.7946991150444072\n",
      "episode 47500: \t0.02767032970166259\t16.25\t0.7942566371683013\n",
      "episode 47600: \t0.02607808797262824\t14.63\t0.7938141592921955\n",
      "episode 47700: \t0.01986549077718242\t13.43\t0.7933716814160896\n",
      "episode 47800: \t0.02479116830544143\t12.62\t0.7929292035399838\n",
      "episode 47900: \t0.02650064306616867\t16.62\t0.7924867256638779\n",
      "episode 48000: \t0.022436605271559253\t15.02\t0.792044247787772\n",
      "episode 48100: \t0.02155043033096478\t14.87\t0.7916017699116662\n",
      "episode 48200: \t0.02246584889455204\t12.52\t0.7911592920355603\n",
      "episode 48300: \t0.025551227597123104\t15.14\t0.7907168141594545\n",
      "episode 48400: \t0.028459290824846356\t18.5\t0.7902743362833486\n",
      "episode 48500: \t0.020269591178302616\t12.45\t0.7898318584072428\n",
      "episode 48600: \t0.022421341901854346\t12.58\t0.7893893805311369\n",
      "episode 48700: \t0.025757858474687468\t15.03\t0.7889469026550311\n",
      "episode 48800: \t0.023185678677450253\t12.05\t0.7885044247789252\n",
      "episode 48900: \t0.019553966980559806\t13.06\t0.7880619469028194\n",
      "episode 49000: \t0.030867167221209427\t17.36\t0.7876194690267135\n",
      "episode 49100: \t0.02468149291529147\t12.78\t0.7871769911506077\n",
      "episode 49200: \t0.025496351789710884\t14.52\t0.7867345132745018\n",
      "episode 49300: \t0.030376221370282726\t19.87\t0.786292035398396\n",
      "episode 49400: \t0.026187577562258334\t14.69\t0.7858495575222901\n",
      "episode 49500: \t0.02223067831557675\t16.73\t0.7854070796461843\n",
      "episode 49600: \t0.024637780707753233\t14.6\t0.7849646017700784\n",
      "episode 49700: \t0.02342731709089325\t14.04\t0.7845221238939726\n",
      "episode 49800: \t0.02622912960161949\t15.34\t0.7840796460178667\n",
      "episode 49900: \t0.025144216521787496\t14.05\t0.7836371681417609\n",
      "episode 50000: \t0.02620547452447171\t15.97\t0.783194690265655\n",
      "#Average reward per episode 50000: 0.023324110203038408\n",
      "Saved Model\n",
      "#Intermediate time to execute: 514.6170157670974min\n",
      "episode 50100: \t0.024608492885610088\t15.12\t0.7827522123895492\n",
      "episode 50200: \t0.027840215539519795\t18.34\t0.7823097345134433\n",
      "episode 50300: \t0.021567194920089655\t14.97\t0.7818672566373375\n",
      "episode 50400: \t0.02630352770376387\t12.28\t0.7814247787612316\n",
      "episode 50500: \t0.022269143291006134\t14.14\t0.7809823008851258\n",
      "episode 50600: \t0.030322190470264635\t16.0\t0.7805398230090199\n",
      "episode 50700: \t0.023474412276518263\t15.91\t0.7800973451329141\n",
      "episode 50800: \t0.02482509209242118\t14.93\t0.7796548672568082\n",
      "episode 50900: \t0.018436180111388433\t14.46\t0.7792123893807024\n",
      "episode 51000: \t0.02417710959077355\t13.54\t0.7787699115045965\n",
      "episode 51100: \t0.02029325215692991\t13.39\t0.7783274336284907\n",
      "episode 51200: \t0.023930061129825656\t14.48\t0.7778849557523848\n",
      "episode 51300: \t0.020840835480839922\t14.89\t0.777442477876279\n",
      "episode 51400: \t0.02244217630269156\t12.75\t0.7770000000001731\n",
      "episode 51500: \t0.025939255939479856\t13.27\t0.7765575221240673\n",
      "episode 51600: \t0.02322305075821694\t13.57\t0.7761150442479614\n",
      "episode 51700: \t0.02210931484724164\t14.92\t0.7756725663718556\n",
      "episode 51800: \t0.01933401121614643\t14.93\t0.7752300884957497\n",
      "episode 51900: \t0.026318710157502614\t15.87\t0.7747876106196439\n",
      "episode 52000: \t0.031030599600205457\t16.5\t0.774345132743538\n",
      "episode 52100: \t0.02655238925160762\t14.09\t0.7739026548674321\n",
      "episode 52200: \t0.025885883990789667\t13.09\t0.7734601769913263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 52300: \t0.023146177815360783\t14.39\t0.7730176991152204\n",
      "episode 52400: \t0.021686889887858517\t12.14\t0.7725752212391146\n",
      "episode 52500: \t0.02011067684178631\t13.0\t0.7721327433630087\n",
      "episode 52600: \t0.028453028172801927\t15.81\t0.7716902654869029\n",
      "episode 52700: \t0.02235123093272735\t12.91\t0.771247787610797\n",
      "episode 52800: \t0.025726660137935623\t15.49\t0.7708053097346912\n",
      "episode 52900: \t0.025730883047802213\t13.51\t0.7703628318585853\n",
      "episode 53000: \t0.03219707834099887\t16.31\t0.7699203539824795\n",
      "episode 53100: \t0.026432928751210213\t15.56\t0.7694778761063736\n",
      "episode 53200: \t0.022271393516294438\t13.13\t0.7690353982302678\n",
      "episode 53300: \t0.023057458968934477\t13.29\t0.7685929203541619\n",
      "episode 53400: \t0.023163578436563706\t15.53\t0.7681504424780561\n",
      "episode 53500: \t0.027359854975520445\t16.71\t0.7677079646019502\n",
      "episode 53600: \t0.026499654294043898\t17.88\t0.7672654867258444\n",
      "episode 53700: \t0.02040644229638819\t13.72\t0.7668230088497385\n",
      "episode 53800: \t0.01181177344428343\t11.78\t0.7663805309736327\n",
      "episode 53900: \t0.018746434389865774\t11.44\t0.7659380530975268\n",
      "episode 54000: \t0.024433202273116062\t16.92\t0.765495575221421\n",
      "episode 54100: \t0.021862218483301797\t13.43\t0.7650530973453151\n",
      "episode 54200: \t0.02786128505743197\t15.58\t0.7646106194692093\n",
      "episode 54300: \t0.024333442536412443\t14.38\t0.7641681415931034\n",
      "episode 54400: \t0.023713005381401517\t12.28\t0.7637256637169976\n",
      "episode 54500: \t0.02676257473286005\t18.04\t0.7632831858408917\n",
      "episode 54600: \t0.023969207181952893\t12.67\t0.7628407079647859\n",
      "episode 54700: \t0.029407484901632662\t18.27\t0.76239823008868\n",
      "episode 54800: \t0.022732703215700388\t12.03\t0.7619557522125742\n",
      "episode 54900: \t0.025098425744220054\t14.49\t0.7615132743364683\n",
      "episode 55000: \t0.021312574310432625\t14.95\t0.7610707964603625\n",
      "#Average reward per episode 55000: 0.023389848126001516\n",
      "episode 55100: \t0.025412913389559772\t17.36\t0.7606283185842566\n",
      "episode 55200: \t0.02180577705842992\t13.32\t0.7601858407081508\n",
      "episode 55300: \t0.022163896493312803\t13.97\t0.7597433628320449\n",
      "episode 55400: \t0.023650146381414355\t13.61\t0.7593008849559391\n",
      "episode 55500: \t0.020763727917564877\t11.98\t0.7588584070798332\n",
      "episode 55600: \t0.02290050836024594\t15.55\t0.7584159292037274\n",
      "episode 55700: \t0.0192374353109625\t14.31\t0.7579734513276215\n",
      "episode 55800: \t0.024736891237462783\t14.79\t0.7575309734515157\n",
      "episode 55900: \t0.026219682243264063\t14.51\t0.7570884955754098\n",
      "episode 56000: \t0.024549700337221512\t17.1\t0.756646017699304\n",
      "episode 56100: \t0.027506620527305743\t13.5\t0.7562035398231981\n",
      "episode 56200: \t0.02564577362282589\t14.45\t0.7557610619470922\n",
      "episode 56300: \t0.01758671713975605\t12.89\t0.7553185840709864\n",
      "episode 56400: \t0.019688158460528904\t13.58\t0.7548761061948805\n",
      "episode 56500: \t0.026055836008208932\t14.52\t0.7544336283187747\n",
      "episode 56600: \t0.02597335189423538\t15.29\t0.7539911504426688\n",
      "episode 56700: \t0.028432367670324754\t15.39\t0.753548672566563\n",
      "episode 56800: \t0.019539041534617253\t12.15\t0.7531061946904571\n",
      "episode 56900: \t0.021140489797810313\t12.65\t0.7526637168143513\n",
      "episode 57000: \t0.028522883424054582\t16.24\t0.7522212389382454\n",
      "episode 57100: \t0.027955957082045232\t17.51\t0.7517787610621396\n",
      "episode 57200: \t0.022282069158148184\t16.87\t0.7513362831860337\n",
      "episode 57300: \t0.024248669058832793\t15.45\t0.7508938053099279\n",
      "episode 57400: \t0.024112655563791444\t16.24\t0.750451327433822\n",
      "episode 57500: \t0.01876817523328337\t11.48\t0.7500088495577162\n",
      "episode 57600: \t0.02033415170757808\t13.49\t0.7495663716816103\n",
      "episode 57700: \t0.022781248846548575\t15.6\t0.7491238938055045\n",
      "episode 57800: \t0.026760099729194447\t16.55\t0.7486814159293986\n",
      "episode 57900: \t0.02470321654947649\t12.76\t0.7482389380532928\n",
      "episode 58000: \t0.02195738189084477\t14.84\t0.7477964601771869\n",
      "episode 58100: \t0.02014773817138899\t14.2\t0.7473539823010811\n",
      "episode 58200: \t0.022487139952478325\t13.88\t0.7469115044249752\n",
      "episode 58300: \t0.025649833358121356\t15.46\t0.7464690265488694\n",
      "episode 58400: \t0.024246625250464567\t14.43\t0.7460265486727635\n",
      "episode 58500: \t0.02182439443548404\t13.68\t0.7455840707966577\n",
      "episode 58600: \t0.01650646067352216\t12.48\t0.7451415929205518\n",
      "episode 58700: \t0.014399875602701473\t12.81\t0.744699115044446\n",
      "episode 58800: \t0.025886281816766252\t14.52\t0.7442566371683401\n",
      "episode 58900: \t0.022310977452501057\t15.15\t0.7438141592922343\n",
      "episode 59000: \t0.02703618466701661\t18.98\t0.7433716814161284\n",
      "episode 59100: \t0.0187224778221199\t11.25\t0.7429292035400226\n",
      "episode 59200: \t0.022092454296391336\t19.63\t0.7424867256639167\n",
      "episode 59300: \t0.0253537560094574\t14.19\t0.7420442477878109\n",
      "episode 59400: \t0.027026105898493444\t14.26\t0.741601769911705\n",
      "episode 59500: \t0.022863893816473486\t12.92\t0.7411592920355992\n",
      "episode 59600: \t0.02632028732531206\t16.08\t0.7407168141594933\n",
      "episode 59700: \t0.02578630283671799\t17.03\t0.7402743362833875\n",
      "episode 59800: \t0.021065754995591716\t13.56\t0.7398318584072816\n",
      "episode 59900: \t0.022608047706823422\t13.92\t0.7393893805311758\n",
      "episode 60000: \t0.02475717355754682\t15.93\t0.7389469026550699\n",
      "#Average reward per episode 60000: 0.023378239630958433\n",
      "WARNING:tensorflow:From /misc/home/reco/fathanab/anaconda3/envs/tfenv/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "#Intermediate time to execute: 629.2183526039123min\n",
      "episode 60100: \t0.02006172426717003\t13.86\t0.738504424778964\n",
      "episode 60200: \t0.03156963414991784\t16.42\t0.7380619469028582\n",
      "episode 60300: \t0.0244535345213591\t15.49\t0.7376194690267524\n",
      "episode 60400: \t0.023593382987660737\t12.37\t0.7371769911506465\n",
      "episode 60500: \t0.022663296712740828\t12.01\t0.7367345132745406\n",
      "episode 60600: \t0.021674950042852855\t14.2\t0.7362920353984348\n",
      "episode 60700: \t0.03047430485981446\t17.09\t0.735849557522329\n",
      "episode 60800: \t0.024921416606953843\t16.89\t0.7354070796462231\n",
      "episode 60900: \t0.02853723307969008\t16.9\t0.7349646017701172\n",
      "episode 61000: \t0.025668100683064778\t13.72\t0.7345221238940114\n",
      "episode 61100: \t0.02029583728796387\t13.13\t0.7340796460179055\n",
      "episode 61200: \t0.01842283585319064\t13.66\t0.7336371681417997\n",
      "episode 61300: \t0.020041634483461954\t13.89\t0.7331946902656938\n",
      "episode 61400: \t0.028756070805291238\t14.58\t0.732752212389588\n",
      "episode 61500: \t0.026509474560190524\t17.23\t0.7323097345134821\n",
      "episode 61600: \t0.022069044399046042\t13.84\t0.7318672566373763\n",
      "episode 61700: \t0.026481684560138396\t16.67\t0.7314247787612704\n",
      "episode 61800: \t0.02473851784693811\t13.32\t0.7309823008851646\n",
      "episode 61900: \t0.028775679067250114\t16.01\t0.7305398230090587\n",
      "episode 62000: \t0.024910067377520505\t13.35\t0.7300973451329529\n",
      "episode 62100: \t0.022718037199039743\t14.55\t0.729654867256847\n",
      "episode 62200: \t0.022729988661153652\t16.42\t0.7292123893807412\n",
      "episode 62300: \t0.027804769532017364\t17.46\t0.7287699115046353\n",
      "episode 62400: \t0.01937581198112506\t13.81\t0.7283274336285295\n",
      "episode 62500: \t0.01831017435844823\t13.44\t0.7278849557524236\n",
      "episode 62600: \t0.025765898391398912\t17.26\t0.7274424778763178\n",
      "episode 62700: \t0.02424813794442466\t14.82\t0.7270000000002119\n",
      "episode 62800: \t0.027717890705107048\t16.19\t0.7265575221241061\n",
      "episode 62900: \t0.025032041342263743\t16.14\t0.7261150442480002\n",
      "episode 63000: \t0.019566013677422417\t14.56\t0.7256725663718944\n",
      "episode 63100: \t0.03210918115586078\t16.05\t0.7252300884957885\n",
      "episode 63200: \t0.023948316048937296\t16.11\t0.7247876106196827\n",
      "episode 63300: \t0.025722036665724608\t14.32\t0.7243451327435768\n",
      "episode 63400: \t0.02040368016232503\t13.99\t0.723902654867471\n",
      "episode 63500: \t0.023759491217340546\t16.1\t0.7234601769913651\n",
      "episode 63600: \t0.028690889517459257\t17.35\t0.7230176991152593\n",
      "episode 63700: \t0.023627823017262038\t12.93\t0.7225752212391534\n",
      "episode 63800: \t0.02518501308170441\t17.38\t0.7221327433630476\n",
      "episode 63900: \t0.02136826014443175\t13.15\t0.7216902654869417\n",
      "episode 64000: \t0.02427656609055375\t14.12\t0.7212477876108359\n",
      "episode 64100: \t0.024634518183557396\t14.5\t0.72080530973473\n",
      "episode 64200: \t0.021739732173153597\t13.91\t0.7203628318586242\n",
      "episode 64300: \t0.022952922898767953\t14.34\t0.7199203539825183\n",
      "episode 64400: \t0.025412555333690513\t17.01\t0.7194778761064125\n",
      "episode 64500: \t0.021915993418153215\t15.12\t0.7190353982303066\n",
      "episode 64600: \t0.023487104308541017\t14.15\t0.7185929203542007\n",
      "episode 64700: \t0.023240082009262912\t12.82\t0.7181504424780949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 64800: \t0.025455332156609445\t15.89\t0.717707964601989\n",
      "episode 64900: \t0.025595329708022665\t13.96\t0.7172654867258832\n",
      "episode 65000: \t0.028578837776986058\t15.61\t0.7168230088497773\n",
      "#Average reward per episode 65000: 0.023456822510135453\n",
      "episode 65100: \t0.028693792217886052\t15.14\t0.7163805309736715\n",
      "episode 65200: \t0.022796728988744866\t13.82\t0.7159380530975656\n",
      "episode 65300: \t0.02257369708743926\t14.18\t0.7154955752214598\n",
      "episode 65400: \t0.024277447488897617\t15.78\t0.7150530973453539\n",
      "episode 65500: \t0.02209453734294818\t14.62\t0.7146106194692481\n",
      "episode 65600: \t0.024903782992834356\t14.7\t0.7141681415931422\n",
      "episode 65700: \t0.02499350480942253\t15.26\t0.7137256637170364\n",
      "episode 65800: \t0.024868718007315774\t15.05\t0.7132831858409305\n",
      "episode 65900: \t0.021084903235161115\t12.83\t0.7128407079648247\n",
      "episode 66000: \t0.01926469111995653\t13.04\t0.7123982300887188\n",
      "episode 66100: \t0.027005544396819948\t15.99\t0.711955752212613\n",
      "episode 66200: \t0.03001529444278422\t14.05\t0.7115132743365071\n",
      "episode 66300: \t0.028103304048286065\t14.36\t0.7110707964604013\n",
      "episode 66400: \t0.02754335600577535\t15.79\t0.7106283185842954\n",
      "episode 66500: \t0.023489975776217795\t14.61\t0.7101858407081896\n",
      "episode 66600: \t0.022534330558063656\t14.01\t0.7097433628320837\n",
      "episode 66700: \t0.01931583010823075\t14.8\t0.7093008849559779\n",
      "episode 66800: \t0.02480123754447394\t15.89\t0.708858407079872\n",
      "episode 66900: \t0.02557467747095567\t13.41\t0.7084159292037662\n",
      "episode 67000: \t0.026250686685035704\t12.93\t0.7079734513276603\n",
      "episode 67100: \t0.019309810889252634\t15.19\t0.7075309734515545\n",
      "episode 67200: \t0.025438104573552077\t13.81\t0.7070884955754486\n",
      "episode 67300: \t0.026324554692792462\t17.08\t0.7066460176993428\n",
      "episode 67400: \t0.03196157234231709\t18.76\t0.7062035398232369\n",
      "episode 67500: \t0.024867913343421734\t13.46\t0.7057610619471311\n",
      "episode 67600: \t0.022526475542055193\t13.65\t0.7053185840710252\n",
      "episode 67700: \t0.02403676399371652\t14.1\t0.7048761061949194\n",
      "episode 67800: \t0.022257388676284726\t13.86\t0.7044336283188135\n",
      "episode 67900: \t0.022778688012853366\t13.95\t0.7039911504427077\n",
      "episode 68000: \t0.022827200459824278\t14.86\t0.7035486725666018\n",
      "episode 68100: \t0.02811635510227856\t15.48\t0.703106194690496\n",
      "episode 68200: \t0.024713072238208067\t16.13\t0.7026637168143901\n",
      "episode 68300: \t0.022583698839927467\t13.9\t0.7022212389382843\n",
      "episode 68400: \t0.025902201268780158\t16.19\t0.7017787610621784\n",
      "episode 68500: \t0.021751661868296943\t14.08\t0.7013362831860726\n",
      "episode 68600: \t0.02252994162671565\t13.79\t0.7008938053099667\n",
      "episode 68700: \t0.023938817533582006\t14.79\t0.7004513274338608\n",
      "episode 68800: \t0.02059015817940241\t14.91\t0.700008849557755\n",
      "episode 68900: \t0.021422947829971985\t13.83\t0.6995663716816491\n",
      "episode 69000: \t0.02565033244904007\t18.15\t0.6991238938055433\n",
      "episode 69100: \t0.025534446663096903\t16.51\t0.6986814159294374\n",
      "episode 69200: \t0.026396305092439742\t17.43\t0.6982389380533316\n",
      "episode 69300: \t0.02030267207795845\t14.15\t0.6977964601772257\n",
      "episode 69400: \t0.024728157248282253\t15.84\t0.6973539823011199\n",
      "episode 69500: \t0.02560283103219306\t15.85\t0.696911504425014\n",
      "episode 69600: \t0.024920134270945648\t14.2\t0.6964690265489082\n",
      "episode 69700: \t0.02149589948064038\t12.76\t0.6960265486728023\n",
      "episode 69800: \t0.01814941841332482\t12.9\t0.6955840707966965\n",
      "episode 69900: \t0.022220134970682138\t13.73\t0.6951415929205906\n",
      "episode 70000: \t0.021523386702335213\t13.4\t0.6946991150444848\n",
      "#Average reward per episode 70000: 0.023496459596185033\n",
      "Saved Model\n",
      "#Intermediate time to execute: 751.7136908094088min\n",
      "episode 70100: \t0.025678763956309122\t16.06\t0.6942566371683789\n",
      "episode 70200: \t0.026268377100878912\t15.7\t0.6938141592922731\n",
      "episode 70300: \t0.024852298968318653\t15.08\t0.6933716814161672\n",
      "episode 70400: \t0.026374525504806675\t15.56\t0.6929292035400614\n",
      "episode 70500: \t0.03194746710836452\t17.06\t0.6924867256639555\n",
      "episode 70600: \t0.03237297395262372\t16.65\t0.6920442477878497\n",
      "episode 70700: \t0.02417036678152703\t14.94\t0.6916017699117438\n",
      "episode 70800: \t0.017799506206785585\t14.93\t0.691159292035638\n",
      "episode 70900: \t0.023957291184345423\t13.74\t0.6907168141595321\n",
      "episode 71000: \t0.028111651953320257\t16.68\t0.6902743362834263\n",
      "episode 71100: \t0.022270857836384744\t12.36\t0.6898318584073204\n",
      "episode 71200: \t0.01902679592572889\t13.51\t0.6893893805312146\n",
      "episode 71300: \t0.020606615342282378\t13.04\t0.6889469026551087\n",
      "episode 71400: \t0.026604997220026457\t14.3\t0.6885044247790029\n",
      "episode 71500: \t0.02574052760861117\t17.39\t0.688061946902897\n",
      "episode 71600: \t0.026610654220959987\t16.91\t0.6876194690267912\n",
      "episode 71700: \t0.023010198453081287\t13.79\t0.6871769911506853\n",
      "episode 71800: \t0.02467749209270411\t14.43\t0.6867345132745795\n",
      "episode 71900: \t0.02150543952926866\t12.69\t0.6862920353984736\n",
      "episode 72000: \t0.01978234835837065\t12.08\t0.6858495575223678\n",
      "episode 72100: \t0.028354788321229535\t15.13\t0.6854070796462619\n",
      "episode 72200: \t0.02662956074662233\t17.24\t0.6849646017701561\n",
      "episode 72300: \t0.02179548157837628\t14.66\t0.6845221238940502\n",
      "episode 72400: \t0.025084877457461192\t14.86\t0.6840796460179444\n",
      "episode 72500: \t0.026868322521572535\t17.16\t0.6836371681418385\n",
      "episode 72600: \t0.019539505030408272\t12.57\t0.6831946902657327\n",
      "episode 72700: \t0.025128568128969634\t15.33\t0.6827522123896268\n",
      "episode 72800: \t0.026092020410223037\t16.92\t0.682309734513521\n",
      "episode 72900: \t0.024120758794749637\t14.53\t0.6818672566374151\n",
      "episode 73000: \t0.02620921852500495\t13.38\t0.6814247787613092\n",
      "episode 73100: \t0.022652967957058293\t14.57\t0.6809823008852034\n",
      "episode 73200: \t0.029593051311572777\t16.79\t0.6805398230090975\n",
      "episode 73300: \t0.02466582568500794\t13.51\t0.6800973451329917\n",
      "episode 73400: \t0.02509073676173581\t15.37\t0.6796548672568858\n",
      "episode 73500: \t0.022986564750022385\t16.12\t0.67921238938078\n",
      "episode 73600: \t0.026970367280953592\t14.89\t0.6787699115046741\n",
      "episode 73700: \t0.021898366373118146\t12.18\t0.6783274336285683\n",
      "episode 73800: \t0.02877285791293853\t16.89\t0.6778849557524624\n",
      "episode 73900: \t0.027144878567906722\t16.32\t0.6774424778763566\n",
      "episode 74000: \t0.026537668445716527\t14.16\t0.6770000000002507\n",
      "episode 74100: \t0.018358032963268874\t12.45\t0.6765575221241449\n",
      "episode 74200: \t0.025258496473563024\t16.15\t0.676115044248039\n",
      "episode 74300: \t0.02458709792580476\t14.78\t0.6756725663719332\n",
      "episode 74400: \t0.0247291625827837\t16.2\t0.6752300884958273\n",
      "episode 74500: \t0.026117814971680958\t16.43\t0.6747876106197215\n",
      "episode 74600: \t0.018306104580729465\t12.56\t0.6743451327436156\n",
      "episode 74700: \t0.025802955992624957\t14.98\t0.6739026548675098\n",
      "episode 74800: \t0.020475975895731736\t12.33\t0.6734601769914039\n",
      "episode 74900: \t0.023244835193482194\t14.75\t0.6730176991152981\n",
      "episode 75000: \t0.028166068975681212\t18.23\t0.6725752212391922\n",
      "#Average reward per episode 75000: 0.023573431731666962\n",
      "episode 75100: \t0.02955360023122928\t14.54\t0.6721327433630864\n",
      "episode 75200: \t0.01980122826578811\t14.74\t0.6716902654869805\n",
      "episode 75300: \t0.022664979068529937\t15.26\t0.6712477876108747\n",
      "episode 75400: \t0.027195291045424973\t17.02\t0.6708053097347688\n",
      "episode 75500: \t0.023180622103397556\t15.01\t0.670362831858663\n",
      "episode 75600: \t0.02461670180971182\t16.04\t0.6699203539825571\n",
      "episode 75700: \t0.01582385743672697\t13.19\t0.6694778761064513\n",
      "episode 75800: \t0.020090180138401123\t13.88\t0.6690353982303454\n",
      "episode 75900: \t0.02419759241489732\t13.25\t0.6685929203542396\n",
      "episode 76000: \t0.026503021643290194\t15.83\t0.6681504424781337\n",
      "episode 76100: \t0.026974497278600917\t13.89\t0.6677079646020279\n",
      "episode 76200: \t0.02422143787488952\t13.29\t0.667265486725922\n",
      "episode 76300: \t0.02335599235404329\t14.92\t0.6668230088498162\n",
      "episode 76400: \t0.024456405575978547\t15.55\t0.6663805309737103\n",
      "episode 76500: \t0.029421167906035984\t15.57\t0.6659380530976045\n",
      "episode 76600: \t0.02027626447181146\t15.02\t0.6654955752214986\n",
      "episode 76700: \t0.01820518981989625\t14.47\t0.6650530973453928\n",
      "episode 76800: \t0.01840673173222378\t10.97\t0.6646106194692869\n",
      "episode 76900: \t0.01793364059014035\t13.14\t0.664168141593181\n",
      "episode 77000: \t0.03346427969949692\t16.93\t0.6637256637170752\n",
      "episode 77100: \t0.0234052278493044\t14.39\t0.6632831858409693\n",
      "episode 77200: \t0.02516961436612295\t15.59\t0.6628407079648635\n",
      "episode 77300: \t0.026445295041085486\t13.83\t0.6623982300887576\n",
      "episode 77400: \t0.022945910117937948\t14.04\t0.6619557522126518\n",
      "episode 77500: \t0.029815956338400684\t15.24\t0.6615132743365459\n",
      "episode 77600: \t0.021799510327770385\t13.87\t0.6610707964604401\n",
      "episode 77700: \t0.024231473173583606\t14.07\t0.6606283185843342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 77800: \t0.028561824770615453\t17.44\t0.6601858407082284\n",
      "episode 77900: \t0.021428144700930633\t15.27\t0.6597433628321225\n",
      "episode 78000: \t0.025551786968760464\t13.82\t0.6593008849560167\n",
      "episode 78100: \t0.022263796824279303\t13.5\t0.6588584070799108\n",
      "episode 78200: \t0.021161785182309937\t13.86\t0.658415929203805\n",
      "episode 78300: \t0.0226156680289028\t15.54\t0.6579734513276991\n",
      "episode 78400: \t0.026007669572702414\t14.28\t0.6575309734515933\n",
      "episode 78500: \t0.03042729363475471\t17.33\t0.6570884955754874\n",
      "episode 78600: \t0.021998768876662078\t14.35\t0.6566460176993816\n",
      "episode 78700: \t0.03502724687284548\t17.65\t0.6562035398232757\n",
      "episode 78800: \t0.022052742151779502\t13.86\t0.6557610619471699\n",
      "episode 78900: \t0.025602043493458734\t16.28\t0.655318584071064\n",
      "episode 79000: \t0.02848851084771463\t16.62\t0.6548761061949582\n",
      "episode 79100: \t0.0246294530296031\t12.1\t0.6544336283188523\n",
      "episode 79200: \t0.030854978475659114\t15.25\t0.6539911504427465\n",
      "episode 79300: \t0.020794320593335667\t12.81\t0.6535486725666406\n",
      "episode 79400: \t0.022649275776071575\t14.65\t0.6531061946905348\n",
      "episode 79500: \t0.02778617860480954\t14.03\t0.6526637168144289\n",
      "episode 79600: \t0.023283209726743512\t12.85\t0.6522212389383231\n",
      "episode 79700: \t0.02385168012167076\t14.74\t0.6517787610622172\n",
      "episode 79800: \t0.025144652268653825\t16.19\t0.6513362831861114\n",
      "episode 79900: \t0.023610452609647024\t15.65\t0.6508938053100055\n",
      "episode 80000: \t0.023875229985768427\t15.75\t0.6504513274338997\n",
      "#Average reward per episode 80000: 0.023627370225678308\n",
      "Saved Model\n",
      "#Intermediate time to execute: 875.3195944507917min\n",
      "episode 80100: \t0.021233141317418686\t15.66\t0.6500088495577938\n",
      "episode 80200: \t0.026113067711471614\t17.94\t0.649566371681688\n",
      "episode 80300: \t0.024349956797543294\t14.98\t0.6491238938055821\n",
      "episode 80400: \t0.023121744851879553\t15.33\t0.6486814159294763\n",
      "episode 80500: \t0.027656550692539864\t16.29\t0.6482389380533704\n",
      "episode 80600: \t0.030421768812650667\t17.29\t0.6477964601772646\n",
      "episode 80700: \t0.01600287266697981\t11.73\t0.6473539823011587\n",
      "episode 80800: \t0.022808588375221196\t13.47\t0.6469115044250529\n",
      "episode 80900: \t0.025952274483858017\t16.38\t0.646469026548947\n",
      "episode 81000: \t0.021903754796874852\t14.97\t0.6460265486728411\n",
      "episode 81100: \t0.025433824309215626\t16.87\t0.6455840707967353\n",
      "episode 81200: \t0.02496476760411066\t14.36\t0.6451415929206294\n",
      "episode 81300: \t0.02105897444979559\t11.93\t0.6446991150445236\n",
      "episode 81400: \t0.024014469604455125\t14.83\t0.6442566371684177\n",
      "episode 81500: \t0.024747606048635414\t15.19\t0.6438141592923119\n",
      "episode 81600: \t0.021215183696225923\t12.53\t0.643371681416206\n",
      "episode 81700: \t0.02455435184739069\t14.86\t0.6429292035401002\n",
      "episode 81800: \t0.02567047831411757\t16.91\t0.6424867256639943\n",
      "episode 81900: \t0.023518930904986916\t14.83\t0.6420442477878885\n",
      "episode 82000: \t0.01918677164374878\t13.93\t0.6416017699117826\n",
      "episode 82100: \t0.019760474452669718\t12.7\t0.6411592920356768\n",
      "episode 82200: \t0.022123344629816064\t14.23\t0.6407168141595709\n",
      "episode 82300: \t0.021107430691047365\t13.83\t0.6402743362834651\n",
      "episode 82400: \t0.02740593616918756\t17.65\t0.6398318584073592\n",
      "episode 82500: \t0.022660628404323018\t13.49\t0.6393893805312534\n",
      "episode 82600: \t0.026851217730275104\t15.32\t0.6389469026551475\n",
      "episode 82700: \t0.020995345091851893\t12.58\t0.6385044247790417\n",
      "episode 82800: \t0.025614800930199532\t13.69\t0.6380619469029358\n",
      "episode 82900: \t0.02519017536952837\t14.57\t0.63761946902683\n",
      "episode 83000: \t0.024503637350201363\t14.66\t0.6371769911507241\n",
      "episode 83100: \t0.024466679241000606\t14.3\t0.6367345132746183\n",
      "episode 83200: \t0.02058164738824134\t13.71\t0.6362920353985124\n",
      "episode 83300: \t0.016855574113272497\t13.29\t0.6358495575224066\n",
      "episode 83400: \t0.023271125697823986\t14.64\t0.6354070796463007\n",
      "episode 83500: \t0.022109485160691344\t13.18\t0.6349646017701949\n",
      "episode 83600: \t0.025416644780024016\t16.06\t0.634522123894089\n",
      "episode 83700: \t0.025525277707597625\t14.12\t0.6340796460179832\n",
      "episode 83800: \t0.022880575419833918\t15.37\t0.6336371681418773\n",
      "episode 83900: \t0.022972288639646996\t15.09\t0.6331946902657715\n",
      "episode 84000: \t0.023052774936008654\t12.37\t0.6327522123896656\n",
      "episode 84100: \t0.022747523128557406\t13.05\t0.6323097345135598\n",
      "episode 84200: \t0.02484130742098857\t13.15\t0.6318672566374539\n",
      "episode 84300: \t0.021163833659516865\t14.36\t0.6314247787613481\n",
      "episode 84400: \t0.029318930948139768\t14.74\t0.6309823008852422\n",
      "episode 84500: \t0.02640642242773003\t14.16\t0.6305398230091364\n",
      "episode 84600: \t0.031874223582282195\t16.23\t0.6300973451330305\n",
      "episode 84700: \t0.02403696302635412\t14.85\t0.6296548672569247\n",
      "episode 84800: \t0.026837838968935112\t13.09\t0.6292123893808188\n",
      "episode 84900: \t0.02366275162468123\t12.0\t0.628769911504713\n",
      "episode 85000: \t0.022037439749008025\t12.86\t0.6283274336286071\n",
      "#Average reward per episode 85000: 0.023637761832836706\n",
      "episode 85100: \t0.02145731010995112\t13.98\t0.6278849557525013\n",
      "episode 85200: \t0.021922259598327914\t15.24\t0.6274424778763954\n",
      "episode 85300: \t0.027949938978235212\t15.19\t0.6270000000002895\n",
      "episode 85400: \t0.02737220449776311\t14.28\t0.6265575221241837\n",
      "episode 85500: \t0.024517567080841497\t14.45\t0.6261150442480778\n",
      "episode 85600: \t0.01949393232534233\t12.55\t0.625672566371972\n",
      "episode 85700: \t0.02353112456876959\t13.25\t0.6252300884958661\n",
      "episode 85800: \t0.019328848730941588\t12.59\t0.6247876106197603\n",
      "episode 85900: \t0.021164861087005417\t13.81\t0.6243451327436544\n",
      "episode 86000: \t0.025010897712695507\t15.08\t0.6239026548675486\n",
      "episode 86100: \t0.02190976820773804\t15.36\t0.6234601769914427\n",
      "episode 86200: \t0.02190110453724253\t14.75\t0.6230176991153369\n",
      "episode 86300: \t0.021829968820601432\t12.9\t0.622575221239231\n",
      "episode 86400: \t0.027389805867233382\t15.59\t0.6221327433631252\n",
      "episode 86500: \t0.025948035965195362\t16.03\t0.6216902654870193\n",
      "episode 86600: \t0.02166810516141711\t12.59\t0.6212477876109135\n",
      "episode 86700: \t0.029254593992138905\t16.19\t0.6208053097348076\n",
      "episode 86800: \t0.024500447596043737\t15.9\t0.6203628318587018\n",
      "episode 86900: \t0.019941192407464826\t14.26\t0.6199203539825959\n",
      "episode 87000: \t0.023724637235735046\t14.57\t0.6194778761064901\n",
      "episode 87100: \t0.021940734167685768\t14.19\t0.6190353982303842\n",
      "episode 87200: \t0.024177294506360286\t16.68\t0.6185929203542784\n",
      "episode 87300: \t0.022876024283087045\t16.4\t0.6181504424781725\n",
      "episode 87400: \t0.024743759837924616\t17.37\t0.6177079646020667\n",
      "episode 87500: \t0.024195558500369932\t14.91\t0.6172654867259608\n",
      "episode 87600: \t0.027172274564085705\t14.99\t0.616823008849855\n",
      "episode 87700: \t0.026307435748937413\t14.57\t0.6163805309737491\n",
      "episode 87800: \t0.025515982429540656\t14.57\t0.6159380530976433\n",
      "episode 87900: \t0.025476713525600117\t15.35\t0.6154955752215374\n",
      "episode 88000: \t0.018722755443916696\t14.3\t0.6150530973454316\n",
      "episode 88100: \t0.01956538702785032\t11.15\t0.6146106194693257\n",
      "episode 88200: \t0.019867855891061152\t13.65\t0.6141681415932199\n",
      "episode 88300: \t0.02613574720236316\t12.22\t0.613725663717114\n",
      "episode 88400: \t0.024617959433593937\t14.76\t0.6132831858410082\n",
      "episode 88500: \t0.023046207887337772\t13.8\t0.6128407079649023\n",
      "episode 88600: \t0.02101909252618011\t10.63\t0.6123982300887965\n",
      "episode 88700: \t0.026378231600942405\t15.7\t0.6119557522126906\n",
      "episode 88800: \t0.023114717277385254\t14.51\t0.6115132743365848\n",
      "episode 88900: \t0.02720185243356415\t14.98\t0.6110707964604789\n",
      "episode 89000: \t0.0260440947971731\t14.46\t0.610628318584373\n",
      "episode 89100: \t0.026798055883275076\t14.49\t0.6101858407082672\n",
      "episode 89200: \t0.02602605579421797\t16.22\t0.6097433628321614\n",
      "episode 89300: \t0.030822729393286945\t17.2\t0.6093008849560555\n",
      "episode 89400: \t0.022052008353937023\t12.69\t0.6088584070799496\n",
      "episode 89500: \t0.025133238745745093\t14.87\t0.6084159292038438\n",
      "episode 89600: \t0.025907338767050207\t14.35\t0.607973451327738\n",
      "episode 89700: \t0.0316604474794191\t15.37\t0.6075309734516321\n",
      "episode 89800: \t0.023366954392432346\t14.35\t0.6070884955755262\n",
      "episode 89900: \t0.027443239640046496\t15.94\t0.6066460176994204\n",
      "episode 90000: \t0.026066751009592656\t13.1\t0.6062035398233145\n",
      "#Average reward per episode 90000: 0.02367256740103991\n",
      "Saved Model\n",
      "#Intermediate time to execute: 1001.7005733966828min\n",
      "episode 90100: \t0.02503650136418703\t15.72\t0.6057610619472087\n",
      "episode 90200: \t0.021210637483761598\t15.48\t0.6053185840711028\n",
      "episode 90300: \t0.02164928502574566\t12.52\t0.604876106194997\n",
      "episode 90400: \t0.023695485472436113\t14.48\t0.6044336283188911\n",
      "episode 90500: \t0.02505379337749974\t14.01\t0.6039911504427853\n",
      "episode 90600: \t0.021708689851524663\t15.83\t0.6035486725666794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 90700: \t0.02251862191241916\t15.89\t0.6031061946905736\n",
      "episode 90800: \t0.022076874701214638\t14.81\t0.6026637168144677\n",
      "episode 90900: \t0.01822444182735451\t13.01\t0.6022212389383619\n",
      "episode 91000: \t0.01981964977503985\t13.16\t0.601778761062256\n",
      "episode 91100: \t0.023046543901409013\t13.9\t0.6013362831861502\n",
      "episode 91200: \t0.022827740017396833\t13.3\t0.6008938053100443\n",
      "episode 91300: \t0.024726126022390976\t14.1\t0.6004513274339385\n",
      "episode 91400: \t0.019756111259266997\t14.52\t0.6000088495578326\n",
      "episode 91500: \t0.03345903943892239\t18.13\t0.5995663716817268\n",
      "episode 91600: \t0.02665465781107709\t15.4\t0.5991238938056209\n",
      "episode 91700: \t0.020723089016510533\t14.07\t0.5986814159295151\n",
      "episode 91800: \t0.025812668478902494\t13.46\t0.5982389380534092\n",
      "episode 91900: \t0.019176917945227908\t12.75\t0.5977964601773034\n",
      "episode 92000: \t0.02443109736982464\t14.41\t0.5973539823011975\n",
      "episode 92100: \t0.02373705837623877\t14.81\t0.5969115044250917\n",
      "episode 92200: \t0.020773404135768215\t14.55\t0.5964690265489858\n",
      "episode 92300: \t0.02631339806529428\t16.24\t0.59602654867288\n",
      "episode 92400: \t0.022114223153831977\t15.75\t0.5955840707967741\n",
      "episode 92500: \t0.022934065050795455\t13.31\t0.5951415929206683\n",
      "episode 92600: \t0.02331415809072373\t14.86\t0.5946991150445624\n",
      "episode 92700: \t0.02358912362427315\t14.89\t0.5942566371684566\n",
      "episode 92800: \t0.025118192293181983\t15.47\t0.5938141592923507\n",
      "episode 92900: \t0.02807575202623109\t17.02\t0.5933716814162449\n",
      "episode 93000: \t0.028490674288974137\t16.09\t0.592929203540139\n",
      "episode 93100: \t0.02073393274499171\t13.88\t0.5924867256640332\n",
      "episode 93200: \t0.03228617110583287\t17.08\t0.5920442477879273\n",
      "episode 93300: \t0.024117615312474302\t16.5\t0.5916017699118215\n",
      "episode 93400: \t0.02010073586007179\t12.86\t0.5911592920357156\n",
      "episode 93500: \t0.02004012730108315\t13.02\t0.5907168141596097\n",
      "episode 93600: \t0.018112018198789652\t13.24\t0.5902743362835039\n",
      "episode 93700: \t0.02566003616335821\t14.42\t0.589831858407398\n",
      "episode 93800: \t0.03434299992200876\t17.28\t0.5893893805312922\n",
      "episode 93900: \t0.02281799976913374\t14.94\t0.5889469026551863\n",
      "episode 94000: \t0.02480093951266542\t14.72\t0.5885044247790805\n",
      "episode 94100: \t0.021826033476324745\t13.66\t0.5880619469029746\n",
      "episode 94200: \t0.028762470202750596\t15.69\t0.5876194690268688\n",
      "episode 94300: \t0.025460519635821525\t14.52\t0.5871769911507629\n",
      "episode 94400: \t0.02036477379969232\t13.04\t0.5867345132746571\n",
      "episode 94500: \t0.02832830653804513\t15.3\t0.5862920353985512\n",
      "episode 94600: \t0.027565245847614484\t17.37\t0.5858495575224454\n",
      "episode 94700: \t0.022728991645649774\t15.19\t0.5854070796463395\n",
      "episode 94800: \t0.02593257967752302\t13.89\t0.5849646017702337\n",
      "episode 94900: \t0.019601187463169786\t14.36\t0.5845221238941278\n",
      "episode 95000: \t0.023589649485946614\t14.75\t0.584079646018022\n",
      "#Average reward per episode 95000: 0.02368268527974352\n",
      "episode 95100: \t0.021155032621208693\t17.07\t0.5836371681419161\n",
      "episode 95200: \t0.021693502252843867\t13.84\t0.5831946902658103\n",
      "episode 95300: \t0.023794313243054796\t14.47\t0.5827522123897044\n",
      "episode 95400: \t0.02540629483415568\t14.72\t0.5823097345135986\n",
      "episode 95500: \t0.028854578621191108\t16.14\t0.5818672566374927\n",
      "episode 95600: \t0.022724723029558996\t13.26\t0.5814247787613869\n",
      "episode 95700: \t0.017327513880540137\t13.79\t0.580982300885281\n",
      "episode 95800: \t0.022998351667429837\t12.67\t0.5805398230091752\n",
      "episode 95900: \t0.02514669536297482\t16.01\t0.5800973451330693\n",
      "episode 96000: \t0.026052544215141978\t16.52\t0.5796548672569635\n",
      "episode 96100: \t0.023630792461037383\t15.29\t0.5792123893808576\n",
      "episode 96200: \t0.02780866122915429\t18.65\t0.5787699115047518\n",
      "episode 96300: \t0.026505784799929984\t15.21\t0.5783274336286459\n",
      "episode 96400: \t0.022405155922558234\t15.1\t0.5778849557525401\n",
      "episode 96500: \t0.02852509953918244\t15.37\t0.5774424778764342\n",
      "episode 96600: \t0.024640888152015473\t16.02\t0.5770000000003284\n",
      "episode 96700: \t0.019902728610779317\t14.24\t0.5765575221242225\n",
      "episode 96800: \t0.022480040473214547\t13.49\t0.5761150442481167\n",
      "episode 96900: \t0.020135876008908718\t14.52\t0.5756725663720108\n",
      "episode 97000: \t0.02101924399115731\t13.81\t0.575230088495905\n",
      "episode 97100: \t0.029093108397615523\t17.22\t0.5747876106197991\n",
      "episode 97200: \t0.02473867546009164\t15.43\t0.5743451327436933\n",
      "episode 97300: \t0.02734204258107055\t15.88\t0.5739026548675874\n",
      "episode 97400: \t0.024662160539149297\t13.63\t0.5734601769914816\n",
      "episode 97500: \t0.014097290495112704\t13.49\t0.5730176991153757\n",
      "episode 97600: \t0.025360131538818872\t19.48\t0.5725752212392698\n",
      "episode 97700: \t0.022743101882791463\t15.85\t0.572132743363164\n",
      "episode 97800: \t0.027738804122980448\t17.23\t0.5716902654870581\n",
      "episode 97900: \t0.023327382257910458\t14.87\t0.5712477876109523\n",
      "episode 98000: \t0.02911284681825538\t18.23\t0.5708053097348464\n",
      "episode 98100: \t0.03220675998579688\t16.21\t0.5703628318587406\n",
      "episode 98200: \t0.02654826532123404\t15.62\t0.5699203539826347\n",
      "episode 98300: \t0.022056163450603797\t13.36\t0.5694778761065289\n",
      "episode 98400: \t0.024099934086137288\t16.96\t0.569035398230423\n",
      "episode 98500: \t0.02280526444610307\t13.68\t0.5685929203543172\n",
      "episode 98600: \t0.019088338417259237\t14.4\t0.5681504424782113\n",
      "episode 98700: \t0.022043187835897315\t16.26\t0.5677079646021055\n",
      "episode 98800: \t0.023966858588691707\t15.74\t0.5672654867259996\n",
      "episode 98900: \t0.026106274739345472\t17.8\t0.5668230088498938\n",
      "episode 99000: \t0.024097716627646662\t15.29\t0.5663805309737879\n",
      "episode 99100: \t0.02162932398210974\t13.25\t0.5659380530976821\n",
      "episode 99200: \t0.027959219193843178\t17.99\t0.5654955752215762\n",
      "episode 99300: \t0.024942612408680283\t12.76\t0.5650530973454704\n",
      "episode 99400: \t0.02751790724947052\t14.69\t0.5646106194693645\n",
      "episode 99500: \t0.027408775033339747\t15.67\t0.5641681415932587\n",
      "episode 99600: \t0.021885915626332405\t14.72\t0.5637256637171528\n",
      "episode 99700: \t0.021708064991474284\t16.45\t0.563283185841047\n",
      "episode 99800: \t0.017601298423260914\t15.07\t0.5628407079649411\n",
      "episode 99900: \t0.023707501012622898\t16.65\t0.5623982300888353\n",
      "episode 100000: \t0.019157459409269703\t13.55\t0.5619557522127294\n",
      "#Average reward per episode 100000: 0.02369551122159529\n",
      "Saved Model\n",
      "#Intermediate time to execute: 1129.958002702395min\n",
      "episode 100100: \t0.025267720118139117\t15.7\t0.5615132743366236\n",
      "episode 100200: \t0.023949035608198863\t14.91\t0.5610707964605177\n",
      "episode 100300: \t0.02729669226254337\t17.39\t0.5606283185844119\n",
      "episode 100400: \t0.024674808881611266\t16.98\t0.560185840708306\n",
      "episode 100500: \t0.01946527461670277\t13.89\t0.5597433628322002\n",
      "episode 100600: \t0.023151236787545288\t16.82\t0.5593008849560943\n",
      "episode 100700: \t0.026580759505155784\t16.66\t0.5588584070799885\n",
      "episode 100800: \t0.019736445624014453\t14.04\t0.5584159292038826\n",
      "episode 100900: \t0.02331341012625538\t14.42\t0.5579734513277768\n",
      "episode 101000: \t0.026883736506180367\t13.6\t0.5575309734516709\n",
      "episode 101100: \t0.02727293046607109\t17.52\t0.5570884955755651\n",
      "episode 101200: \t0.019838051801238196\t12.77\t0.5566460176994592\n",
      "episode 101300: \t0.020526096750763664\t14.29\t0.5562035398233534\n",
      "episode 101400: \t0.02264948535535446\t14.4\t0.5557610619472475\n",
      "episode 101500: \t0.029464755012810116\t16.52\t0.5553185840711417\n",
      "episode 101600: \t0.022878007351095856\t15.6\t0.5548761061950358\n",
      "episode 101700: \t0.0251400120416065\t14.69\t0.55443362831893\n",
      "episode 101800: \t0.02042240527040857\t15.48\t0.5539911504428241\n",
      "episode 101900: \t0.02621248819361537\t16.04\t0.5535486725667182\n",
      "episode 102000: \t0.024860003061133944\t17.26\t0.5531061946906124\n",
      "episode 102100: \t0.02352647776643912\t16.23\t0.5526637168145065\n",
      "episode 102200: \t0.027975344496316872\t14.72\t0.5522212389384007\n",
      "episode 102300: \t0.02473773239184799\t16.81\t0.5517787610622948\n",
      "episode 102400: \t0.028181583963986588\t16.42\t0.551336283186189\n",
      "episode 102500: \t0.017733158095234184\t12.09\t0.5508938053100831\n",
      "episode 102600: \t0.019651173904531877\t12.97\t0.5504513274339773\n",
      "episode 102700: \t0.02628421306451115\t15.73\t0.5500088495578714\n",
      "episode 102800: \t0.024850820618851202\t15.68\t0.5495663716817656\n",
      "episode 102900: \t0.02479200378050035\t14.95\t0.5491238938056597\n",
      "episode 103000: \t0.030095019703162116\t18.68\t0.5486814159295539\n",
      "episode 103100: \t0.02404796281774743\t17.22\t0.548238938053448\n",
      "episode 103200: \t0.019201102526291917\t13.2\t0.5477964601773422\n",
      "episode 103300: \t0.023214431449565517\t12.77\t0.5473539823012363\n",
      "episode 103400: \t0.02658581161804653\t16.08\t0.5469115044251305\n",
      "episode 103500: \t0.02724846731598818\t17.91\t0.5464690265490246\n",
      "episode 103600: \t0.025415745817519042\t14.42\t0.5460265486729188\n",
      "episode 103700: \t0.027205664541524986\t18.24\t0.5455840707968129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 103800: \t0.02737709820449316\t17.26\t0.5451415929207071\n",
      "episode 103900: \t0.018665657209536158\t12.28\t0.5446991150446012\n",
      "episode 104000: \t0.01915495655312367\t15.01\t0.5442566371684954\n",
      "episode 104100: \t0.024074079010422293\t15.55\t0.5438141592923895\n",
      "episode 104200: \t0.02890253412362953\t15.24\t0.5433716814162837\n",
      "episode 104300: \t0.02056019557480068\t14.27\t0.5429292035401778\n",
      "episode 104400: \t0.0221616300424557\t14.42\t0.542486725664072\n",
      "episode 104500: \t0.03240452137178704\t17.8\t0.5420442477879661\n",
      "episode 104600: \t0.03233765731951011\t19.34\t0.5416017699118603\n",
      "episode 104700: \t0.02770683381364548\t14.51\t0.5411592920357544\n",
      "episode 104800: \t0.023937907841223734\t14.89\t0.5407168141596486\n",
      "episode 104900: \t0.023452175897767647\t14.83\t0.5402743362835427\n",
      "episode 105000: \t0.02638796855852488\t15.23\t0.5398318584074369\n",
      "#Average reward per episode 105000: 0.023736156672694103\n",
      "episode 105100: \t0.02133169097551659\t13.52\t0.539389380531331\n",
      "episode 105200: \t0.02262032037550554\t14.42\t0.5389469026552252\n",
      "episode 105300: \t0.020956865680716478\t14.03\t0.5385044247791193\n",
      "episode 105400: \t0.022738843860379235\t16.25\t0.5380619469030135\n",
      "episode 105500: \t0.015585402674915007\t11.1\t0.5376194690269076\n",
      "episode 105600: \t0.030896100783370368\t16.79\t0.5371769911508018\n",
      "episode 105700: \t0.02313422871361476\t15.42\t0.5367345132746959\n",
      "episode 105800: \t0.022109831678261048\t13.41\t0.53629203539859\n",
      "episode 105900: \t0.020054140354752517\t11.84\t0.5358495575224842\n",
      "episode 106000: \t0.02658748964480577\t16.47\t0.5354070796463783\n",
      "episode 106100: \t0.02277330122713653\t13.93\t0.5349646017702725\n",
      "episode 106200: \t0.028391746637749255\t16.22\t0.5345221238941666\n",
      "episode 106300: \t0.022758525008296754\t14.08\t0.5340796460180608\n",
      "episode 106400: \t0.027304286752871932\t15.24\t0.5336371681419549\n",
      "episode 106500: \t0.030703318671166473\t17.39\t0.5331946902658491\n",
      "episode 106600: \t0.018180244539625218\t13.19\t0.5327522123897432\n",
      "episode 106700: \t0.021791306769953677\t13.26\t0.5323097345136374\n",
      "episode 106800: \t0.020872181950599155\t14.8\t0.5318672566375315\n",
      "episode 106900: \t0.02013792082682244\t13.28\t0.5314247787614257\n",
      "episode 107000: \t0.026121287593500388\t16.6\t0.5309823008853198\n",
      "episode 107100: \t0.03160643013032843\t16.42\t0.530539823009214\n",
      "episode 107200: \t0.026928477089003044\t15.53\t0.5300973451331081\n",
      "episode 107300: \t0.019183576567171866\t14.32\t0.5296548672570023\n",
      "episode 107400: \t0.02931186696565871\t16.25\t0.5292123893808964\n",
      "episode 107500: \t0.023069649080371415\t13.99\t0.5287699115047906\n",
      "episode 107600: \t0.03032062776611831\t19.11\t0.5283274336286847\n",
      "episode 107700: \t0.02160124921115611\t13.3\t0.5278849557525789\n",
      "episode 107800: \t0.0210658115245901\t14.18\t0.527442477876473\n",
      "episode 107900: \t0.026765355187116174\t13.84\t0.5270000000003672\n",
      "episode 108000: \t0.021909673734923318\t14.62\t0.5265575221242613\n",
      "episode 108100: \t0.02841427089106932\t15.88\t0.5261150442481555\n",
      "episode 108200: \t0.02703126347450944\t16.92\t0.5256725663720496\n",
      "episode 108300: \t0.02689696037409433\t14.48\t0.5252300884959438\n",
      "episode 108400: \t0.020834858432602407\t13.89\t0.5247876106198379\n",
      "episode 108500: \t0.0283517454442581\t12.38\t0.5243451327437321\n",
      "episode 108600: \t0.024793327088866418\t14.2\t0.5239026548676262\n",
      "episode 108700: \t0.028731018302112936\t16.3\t0.5234601769915204\n",
      "episode 108800: \t0.027761272606451132\t12.88\t0.5230176991154145\n",
      "episode 108900: \t0.029972089461333798\t15.39\t0.5225752212393087\n",
      "episode 109000: \t0.025107135069402858\t15.15\t0.5221327433632028\n",
      "episode 109100: \t0.028876167459745066\t16.37\t0.521690265487097\n",
      "episode 109200: \t0.026745212291795658\t15.54\t0.5212477876109911\n",
      "episode 109300: \t0.02248199344295018\t15.48\t0.5208053097348853\n",
      "episode 109400: \t0.025756913100960413\t15.43\t0.5203628318587794\n",
      "episode 109500: \t0.02510406454715472\t15.36\t0.5199203539826736\n",
      "episode 109600: \t0.02513057651241809\t13.6\t0.5194778761065677\n",
      "episode 109700: \t0.019878401164662572\t15.47\t0.5190353982304619\n",
      "episode 109800: \t0.021432295325375727\t14.72\t0.518592920354356\n",
      "episode 109900: \t0.025265790015569067\t15.94\t0.5181504424782502\n",
      "episode 110000: \t0.027778487079507645\t14.88\t0.5177079646021443\n",
      "#Average reward per episode 110000: 0.023778291000354133\n",
      "Saved Model\n",
      "#Intermediate time to execute: 1258.036167617639min\n",
      "episode 110100: \t0.02267100233251281\t13.5\t0.5172654867260384\n",
      "episode 110200: \t0.019887047486866923\t14.7\t0.5168230088499326\n",
      "episode 110300: \t0.023793583206624676\t15.0\t0.5163805309738267\n",
      "episode 110400: \t0.02663959880112264\t15.68\t0.5159380530977209\n",
      "episode 110500: \t0.025679859144676975\t13.99\t0.515495575221615\n",
      "episode 110600: \t0.03404216480627618\t16.18\t0.5150530973455092\n",
      "episode 110700: \t0.032090530223981985\t17.09\t0.5146106194694033\n",
      "episode 110800: \t0.024813952015392982\t14.01\t0.5141681415932975\n",
      "episode 110900: \t0.020305776295287566\t13.93\t0.5137256637171916\n",
      "episode 111000: \t0.027285208372622553\t16.28\t0.5132831858410858\n",
      "episode 111100: \t0.03207064773263829\t17.23\t0.5128407079649799\n",
      "episode 111200: \t0.020795043446870408\t14.47\t0.5123982300888741\n",
      "episode 111300: \t0.03290520264786199\t15.82\t0.5119557522127682\n",
      "episode 111400: \t0.02686927493478831\t15.94\t0.5115132743366624\n",
      "episode 111500: \t0.030835195594281713\t14.72\t0.5110707964605565\n",
      "episode 111600: \t0.030094035929920403\t15.8\t0.5106283185844507\n",
      "episode 111700: \t0.025950610016309855\t12.95\t0.5101858407083448\n",
      "episode 111800: \t0.0221085270450746\t14.37\t0.509743362832239\n",
      "episode 111900: \t0.023502246650749115\t14.67\t0.5093008849561331\n",
      "episode 112000: \t0.019984495323915812\t12.42\t0.5088584070800273\n",
      "episode 112100: \t0.020066080832740994\t13.15\t0.5084159292039214\n",
      "episode 112200: \t0.02736646334196247\t15.35\t0.5079734513278156\n",
      "episode 112300: \t0.028688335397689727\t14.53\t0.5075309734517097\n",
      "episode 112400: \t0.026206127031613874\t16.32\t0.5070884955756039\n",
      "episode 112500: \t0.023155442161652093\t12.53\t0.506646017699498\n",
      "episode 112600: \t0.023158514172421794\t14.21\t0.5062035398233922\n",
      "episode 112700: \t0.02261600540820874\t12.85\t0.5057610619472863\n",
      "episode 112800: \t0.02676135836657316\t14.84\t0.5053185840711805\n",
      "episode 112900: \t0.027023080242342724\t14.31\t0.5048761061950746\n",
      "episode 113000: \t0.02784251990260976\t14.83\t0.5044336283189688\n",
      "episode 113100: \t0.027219806508379105\t14.55\t0.5039911504428629\n",
      "episode 113200: \t0.02462839057289176\t14.98\t0.5035486725667571\n",
      "episode 113300: \t0.024098194695292726\t14.3\t0.5031061946906512\n",
      "episode 113400: \t0.026478932974063882\t13.63\t0.5026637168145454\n",
      "episode 113500: \t0.022209217042761843\t15.22\t0.5022212389384395\n",
      "episode 113600: \t0.024631468044551023\t12.73\t0.5017787610623337\n",
      "episode 113700: \t0.024823305488450173\t11.57\t0.5013362831862278\n",
      "episode 113800: \t0.016921242204540124\t11.67\t0.500893805310122\n",
      "episode 113900: \t0.023833662050396637\t14.26\t0.5004513274340161\n",
      "episode 114000: \t0.0330771791889443\t20.31\t0.5000088495579103\n",
      "episode 114100: \t0.0257369657751165\t14.3\t0.4995663716818044\n",
      "episode 114200: \t0.020856805249413655\t12.94\t0.49912389380569855\n",
      "episode 114300: \t0.023863751347113424\t13.97\t0.4986814159295927\n",
      "episode 114400: \t0.022781647604841804\t13.85\t0.49823893805348685\n",
      "episode 114500: \t0.020194875362859042\t13.56\t0.497796460177381\n",
      "episode 114600: \t0.02790534209455352\t13.87\t0.49735398230127514\n",
      "episode 114700: \t0.028078868031536298\t15.53\t0.4969115044251693\n",
      "episode 114800: \t0.02129399166626786\t12.72\t0.49646902654906344\n",
      "episode 114900: \t0.018366916249581196\t13.1\t0.4960265486729576\n",
      "episode 115000: \t0.02736218175652013\t13.97\t0.49558407079685174\n",
      "#Average reward per episode 115000: 0.02383973110709838\n",
      "episode 115100: \t0.02668920762569029\t17.04\t0.4951415929207459\n",
      "episode 115200: \t0.024689494648219276\t14.6\t0.49469911504464004\n",
      "episode 115300: \t0.02439446341701001\t13.81\t0.4942566371685342\n",
      "episode 115400: \t0.021606076638960935\t14.23\t0.49381415929242833\n",
      "episode 115500: \t0.030856700344542173\t15.56\t0.4933716814163225\n",
      "episode 115600: \t0.020287394016390525\t13.32\t0.49292920354021663\n",
      "episode 115700: \t0.02130712893940808\t13.07\t0.4924867256641108\n",
      "episode 115800: \t0.022726392099733338\t14.36\t0.49204424778800493\n",
      "episode 115900: \t0.025924767605273423\t16.2\t0.4916017699118991\n",
      "episode 116000: \t0.023803352048638628\t12.88\t0.4911592920357932\n",
      "episode 116100: \t0.023356198362679822\t13.21\t0.4907168141596874\n",
      "episode 116200: \t0.028083127871568907\t16.03\t0.4902743362835815\n",
      "episode 116300: \t0.024685349539807926\t15.76\t0.4898318584074757\n",
      "episode 116400: \t0.020272980230861545\t12.56\t0.4893893805313698\n",
      "episode 116500: \t0.025061517099334095\t14.02\t0.48894690265526397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 116600: \t0.028675935162865086\t16.51\t0.4885044247791581\n",
      "episode 116700: \t0.02529283747887095\t15.48\t0.48806194690305227\n",
      "episode 116800: \t0.02803989974852085\t15.11\t0.4876194690269464\n",
      "episode 116900: \t0.025242714139134287\t15.44\t0.48717699115084057\n",
      "episode 117000: \t0.024727792060822238\t14.18\t0.4867345132747347\n",
      "episode 117100: \t0.020031813474713753\t14.02\t0.48629203539862886\n",
      "episode 117200: \t0.020061176047140625\t13.09\t0.485849557522523\n",
      "episode 117300: \t0.027707248370895284\t12.45\t0.48540707964641716\n",
      "episode 117400: \t0.023500638998154876\t14.03\t0.4849646017703113\n",
      "episode 117500: \t0.02782301676850134\t16.14\t0.48452212389420546\n",
      "episode 117600: \t0.024166037928307325\t14.49\t0.4840796460180996\n",
      "episode 117700: \t0.020075296396131523\t13.42\t0.48363716814199376\n",
      "episode 117800: \t0.026083803610004647\t16.04\t0.4831946902658879\n",
      "episode 117900: \t0.023143984748351554\t13.96\t0.48275221238978205\n",
      "episode 118000: \t0.02655776259202962\t13.98\t0.4823097345136762\n",
      "episode 118100: \t0.031358226302802945\t12.81\t0.48186725663757035\n",
      "episode 118200: \t0.027323507845783735\t13.49\t0.4814247787614645\n",
      "episode 118300: \t0.02239759862466714\t15.63\t0.48098230088535865\n",
      "episode 118400: \t0.021683244428081516\t13.39\t0.4805398230092528\n",
      "episode 118500: \t0.028250862456033112\t15.04\t0.48009734513314695\n",
      "episode 118600: \t0.024051901312949972\t15.06\t0.4796548672570411\n",
      "episode 118700: \t0.022232160333858858\t13.39\t0.47921238938093524\n",
      "episode 118800: \t0.02208063283603591\t12.35\t0.4787699115048294\n",
      "episode 118900: \t0.023272380828597634\t13.03\t0.47832743362872354\n",
      "episode 119000: \t0.020669828141657746\t12.99\t0.4778849557526177\n",
      "episode 119100: \t0.024825607008619768\t13.76\t0.47744247787651184\n",
      "episode 119200: \t0.02276372144219785\t13.53\t0.477000000000406\n",
      "episode 119300: \t0.029211379262247622\t14.82\t0.47655752212430014\n",
      "episode 119400: \t0.027650324581109255\t16.13\t0.4761150442481943\n",
      "episode 119500: \t0.019257185663207665\t11.21\t0.47567256637208843\n",
      "episode 119600: \t0.027878888295125512\t14.76\t0.4752300884959826\n",
      "episode 119700: \t0.02535317523152988\t13.47\t0.47478761061987673\n",
      "episode 119800: \t0.029511071061229757\t15.63\t0.4743451327437709\n",
      "episode 119900: \t0.01984065626814005\t12.08\t0.47390265486766503\n",
      "episode 120000: \t0.027407523278934698\t14.04\t0.4734601769915592\n",
      "#Average reward per episode 120000: 0.023872987296982107\n",
      "Saved Model\n",
      "#Intermediate time to execute: 1389.2190250237784min\n",
      "episode 120100: \t0.025189820014901172\t15.52\t0.4730176991154533\n",
      "episode 120200: \t0.021347460055239464\t12.03\t0.4725752212393475\n",
      "episode 120300: \t0.0229269043256484\t13.43\t0.4721327433632416\n",
      "episode 120400: \t0.025612864876303664\t15.33\t0.4716902654871358\n",
      "episode 120500: \t0.030279891148454644\t15.4\t0.4712477876110299\n",
      "episode 120600: \t0.02133039549284757\t12.29\t0.47080530973492407\n",
      "episode 120700: \t0.019588154722951685\t12.76\t0.4703628318588182\n",
      "episode 120800: \t0.02275064160493981\t15.41\t0.46992035398271237\n",
      "episode 120900: \t0.022178526758370697\t15.71\t0.4694778761066065\n",
      "episode 121000: \t0.02765618592490251\t14.39\t0.46903539823050067\n",
      "episode 121100: \t0.022886168092634863\t12.05\t0.4685929203543948\n",
      "episode 121200: \t0.021396539975956377\t11.5\t0.46815044247828896\n",
      "episode 121300: \t0.02268588703021471\t12.01\t0.4677079646021831\n",
      "episode 121400: \t0.01821020902350542\t11.18\t0.46726548672607726\n",
      "episode 121500: \t0.021947573967669366\t12.48\t0.4668230088499714\n",
      "episode 121600: \t0.024000981271476554\t14.15\t0.46638053097386556\n",
      "episode 121700: \t0.022713346687843406\t12.86\t0.4659380530977597\n",
      "episode 121800: \t0.025577535238585875\t12.6\t0.46549557522165386\n",
      "episode 121900: \t0.023068883393150923\t13.85\t0.465053097345548\n",
      "episode 122000: \t0.025030500467455283\t13.14\t0.46461061946944215\n",
      "episode 122100: \t0.022451978825712548\t13.45\t0.4641681415933363\n",
      "episode 122200: \t0.026049319237510877\t14.15\t0.46372566371723045\n",
      "episode 122300: \t0.023703578132386514\t13.75\t0.4632831858411246\n",
      "episode 122400: \t0.020390983154930244\t12.11\t0.46284070796501875\n",
      "episode 122500: \t0.02204147534573768\t15.26\t0.4623982300889129\n",
      "episode 122600: \t0.022135904251754317\t12.02\t0.46195575221280705\n",
      "episode 122700: \t0.02692897641340364\t14.8\t0.4615132743367012\n",
      "episode 122800: \t0.02209218885111692\t14.19\t0.46107079646059534\n",
      "episode 122900: \t0.025310125263225212\t14.16\t0.4606283185844895\n",
      "episode 123000: \t0.025617934849065094\t13.85\t0.46018584070838364\n",
      "episode 123100: \t0.020759829822692196\t12.8\t0.4597433628322778\n",
      "episode 123200: \t0.027639811826933203\t14.08\t0.45930088495617194\n",
      "episode 123300: \t0.025567619040001283\t12.26\t0.4588584070800661\n",
      "episode 123400: \t0.029492910103416713\t13.07\t0.45841592920396024\n",
      "episode 123500: \t0.023349709458081437\t12.4\t0.4579734513278544\n",
      "episode 123600: \t0.021660246002751803\t13.21\t0.45753097345174853\n",
      "episode 123700: \t0.022161831689496793\t12.92\t0.4570884955756427\n",
      "episode 123800: \t0.02137136150487768\t15.58\t0.45664601769953683\n",
      "episode 123900: \t0.02810583742055203\t14.19\t0.456203539823431\n",
      "episode 124000: \t0.02934739846693476\t14.78\t0.45576106194732513\n",
      "episode 124100: \t0.026809091250999464\t14.28\t0.4553185840712193\n",
      "episode 124200: \t0.02683854193258244\t12.54\t0.4548761061951134\n",
      "episode 124300: \t0.028351861632574547\t13.93\t0.4544336283190076\n",
      "episode 124400: \t0.021473616692035288\t14.48\t0.4539911504429017\n",
      "episode 124500: \t0.027369719322106474\t12.78\t0.4535486725667959\n",
      "episode 124600: \t0.02405944095774361\t12.42\t0.45310619469069\n",
      "episode 124700: \t0.030892067687174386\t15.14\t0.45266371681458417\n",
      "episode 124800: \t0.022795518497469837\t15.25\t0.4522212389384783\n",
      "episode 124900: \t0.02890656709636644\t15.12\t0.45177876106237247\n",
      "episode 125000: \t0.024382049424563693\t12.57\t0.4513362831862666\n",
      "#Average reward per episode 125000: 0.023889616576484644\n",
      "episode 125100: \t0.024466597083080785\t12.22\t0.45089380531016077\n",
      "episode 125200: \t0.029765939267553655\t16.61\t0.4504513274340549\n",
      "episode 125300: \t0.028574064397141295\t13.23\t0.45000884955794906\n",
      "episode 125400: \t0.02544102004526606\t15.09\t0.4495663716818432\n",
      "episode 125500: \t0.026269407100811177\t14.75\t0.44912389380573736\n",
      "episode 125600: \t0.020225177112720868\t13.33\t0.4486814159296315\n",
      "episode 125700: \t0.0277353824958152\t15.57\t0.44823893805352566\n",
      "episode 125800: \t0.02669076823226124\t13.02\t0.4477964601774198\n",
      "episode 125900: \t0.028443444938959218\t13.66\t0.44735398230131396\n",
      "episode 126000: \t0.02629939617042541\t14.62\t0.4469115044252081\n",
      "episode 126100: \t0.02388579049869602\t13.49\t0.44646902654910225\n",
      "episode 126200: \t0.025404880152281987\t12.63\t0.4460265486729964\n",
      "episode 126300: \t0.021675055289442312\t14.4\t0.44558407079689055\n",
      "episode 126400: \t0.022724513383688118\t13.82\t0.4451415929207847\n",
      "episode 126500: \t0.026005108206447365\t14.6\t0.44469911504467885\n",
      "episode 126600: \t0.030064213978088783\t13.55\t0.444256637168573\n",
      "episode 126700: \t0.024278869934238258\t15.47\t0.44381415929246715\n",
      "episode 126800: \t0.02867741929130927\t15.71\t0.4433716814163613\n",
      "episode 126900: \t0.02871704172480021\t15.47\t0.44292920354025545\n",
      "episode 127000: \t0.02640903845368357\t17.22\t0.4424867256641496\n",
      "episode 127100: \t0.02274576820480905\t14.85\t0.44204424778804374\n",
      "episode 127200: \t0.02237299806251125\t12.37\t0.4416017699119379\n",
      "episode 127300: \t0.02519892900176203\t15.77\t0.44115929203583204\n",
      "episode 127400: \t0.020175289315267797\t14.93\t0.4407168141597262\n",
      "episode 127500: \t0.028729856795605243\t14.84\t0.44027433628362034\n",
      "episode 127600: \t0.025908700710592356\t15.14\t0.4398318584075145\n",
      "episode 127700: \t0.021279119438968402\t12.25\t0.43938938053140864\n",
      "episode 127800: \t0.021377887094415415\t13.42\t0.4389469026553028\n",
      "episode 127900: \t0.029971637780094578\t15.67\t0.43850442477919693\n",
      "episode 128000: \t0.027401480042061742\t14.05\t0.4380619469030911\n",
      "episode 128100: \t0.020070710664449643\t13.33\t0.43761946902698523\n",
      "episode 128200: \t0.020305085636484282\t12.52\t0.4371769911508794\n",
      "episode 128300: \t0.025200846837234055\t15.82\t0.43673451327477353\n",
      "episode 128400: \t0.02693392030514845\t15.94\t0.4362920353986677\n",
      "episode 128500: \t0.020417859241359873\t14.72\t0.4358495575225618\n",
      "episode 128600: \t0.03026936232436327\t15.35\t0.435407079646456\n",
      "episode 128700: \t0.02334898747666387\t15.12\t0.4349646017703501\n",
      "episode 128800: \t0.020452110135493515\t13.24\t0.43452212389424427\n",
      "episode 128900: \t0.023013050899879435\t13.22\t0.4340796460181384\n",
      "episode 129000: \t0.023234040140645226\t15.22\t0.43363716814203257\n",
      "episode 129100: \t0.027561341506106122\t18.19\t0.4331946902659267\n",
      "episode 129200: \t0.02705986368999747\t15.53\t0.43275221238982087\n",
      "episode 129300: \t0.020985029218822667\t12.99\t0.432309734513715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 129400: \t0.021575027906988276\t14.89\t0.43186725663760916\n",
      "episode 129500: \t0.0235018696639392\t15.95\t0.4314247787615033\n",
      "episode 129600: \t0.029770601816295567\t15.03\t0.43098230088539746\n",
      "episode 129700: \t0.026886890545961564\t13.7\t0.4305398230092916\n",
      "episode 129800: \t0.02617725072585256\t14.76\t0.43009734513318576\n",
      "episode 129900: \t0.02412068927229563\t15.2\t0.4296548672570799\n",
      "episode 130000: \t0.026483007543406233\t15.85\t0.42921238938097406\n",
      "#Average reward per episode 130000: 0.023935617738738417\n",
      "Saved Model\n",
      "#Intermediate time to execute: 1522.1863422354063min\n",
      "episode 130100: \t0.03196833245036886\t15.91\t0.4287699115048682\n",
      "episode 130200: \t0.026906493314113815\t15.48\t0.42832743362876236\n",
      "episode 130300: \t0.020368753988436912\t16.12\t0.4278849557526565\n",
      "episode 130400: \t0.02839736088256173\t17.06\t0.42744247787655065\n",
      "episode 130500: \t0.028160429096668715\t18.14\t0.4270000000004448\n",
      "episode 130600: \t0.024529783713445875\t16.16\t0.42655752212433895\n",
      "episode 130700: \t0.02774135136665959\t16.75\t0.4261150442482331\n",
      "episode 130800: \t0.028080035040233025\t15.48\t0.42567256637212725\n",
      "episode 130900: \t0.02849669552540236\t17.7\t0.4252300884960214\n",
      "episode 131000: \t0.02605479562881352\t14.97\t0.42478761061991555\n",
      "episode 131100: \t0.02461808108263733\t15.95\t0.4243451327438097\n",
      "episode 131200: \t0.029848256399204343\t19.02\t0.42390265486770384\n",
      "episode 131300: \t0.024894359533555472\t14.84\t0.423460176991598\n",
      "episode 131400: \t0.026283891919421667\t17.35\t0.42301769911549214\n",
      "episode 131500: \t0.02574610237208581\t15.27\t0.4225752212393863\n",
      "episode 131600: \t0.02367664759527699\t16.59\t0.42213274336328044\n",
      "episode 131700: \t0.020154403876366134\t13.28\t0.4216902654871746\n",
      "episode 131800: \t0.024483171572272946\t18.19\t0.42124778761106874\n",
      "episode 131900: \t0.02187694917021215\t15.65\t0.4208053097349629\n",
      "episode 132000: \t0.027906950444923532\t16.63\t0.42036283185885703\n",
      "episode 132100: \t0.022031301583377943\t14.56\t0.4199203539827512\n",
      "episode 132200: \t0.023114281056674343\t15.58\t0.41947787610664533\n",
      "episode 132300: \t0.028637053759330296\t16.28\t0.4190353982305395\n",
      "episode 132400: \t0.022940067939578358\t13.94\t0.41859292035443363\n",
      "episode 132500: \t0.017857833054462393\t13.63\t0.4181504424783278\n",
      "episode 132600: \t0.024158227264300045\t14.37\t0.4177079646022219\n",
      "episode 132700: \t0.02648316876452772\t14.45\t0.4172654867261161\n",
      "episode 132800: \t0.025161178524846194\t16.42\t0.4168230088500102\n",
      "episode 132900: \t0.031129091731497627\t17.36\t0.4163805309739044\n",
      "episode 133000: \t0.019409737628122693\t14.12\t0.4159380530977985\n",
      "episode 133100: \t0.024729591266269665\t15.2\t0.41549557522169267\n",
      "episode 133200: \t0.029015363814885457\t17.74\t0.4150530973455868\n",
      "episode 133300: \t0.022220133591537343\t16.14\t0.41461061946948097\n",
      "episode 133400: \t0.022968230627253262\t14.21\t0.4141681415933751\n",
      "episode 133500: \t0.02394439050590386\t16.11\t0.41372566371726927\n",
      "episode 133600: \t0.021407907810982743\t16.82\t0.4132831858411634\n",
      "episode 133700: \t0.019779003418011466\t15.47\t0.41284070796505756\n",
      "episode 133800: \t0.027137182826483367\t15.76\t0.4123982300889517\n",
      "episode 133900: \t0.02472470568164858\t16.73\t0.41195575221284586\n",
      "episode 134000: \t0.022567082198315568\t15.26\t0.41151327433674\n",
      "episode 134100: \t0.02251535139182508\t15.89\t0.41107079646063416\n",
      "episode 134200: \t0.02484667076543647\t15.32\t0.4106283185845283\n",
      "episode 134300: \t0.03126282512566058\t17.99\t0.41018584070842246\n",
      "episode 134400: \t0.019990888672820485\t14.06\t0.4097433628323166\n",
      "episode 134500: \t0.024937335432057894\t15.01\t0.40930088495621075\n",
      "episode 134600: \t0.027646039754178783\t16.89\t0.4088584070801049\n",
      "episode 134700: \t0.024650871546520448\t18.52\t0.40841592920399905\n",
      "episode 134800: \t0.02212580195564727\t13.83\t0.4079734513278932\n",
      "episode 134900: \t0.021205062187513682\t14.74\t0.40753097345178735\n",
      "episode 135000: \t0.02359817778611381\t15.79\t0.4070884955756815\n",
      "#Average reward per episode 135000: 0.023969400342961706\n",
      "episode 135100: \t0.02249335289349489\t15.09\t0.40664601769957565\n",
      "episode 135200: \t0.023024547197473436\t13.79\t0.4062035398234698\n",
      "episode 135300: \t0.026532524394428717\t15.42\t0.40576106194736394\n",
      "episode 135400: \t0.023197807499101778\t17.3\t0.4053185840712581\n",
      "episode 135500: \t0.024300477986506582\t14.0\t0.40487610619515224\n",
      "episode 135600: \t0.02140157852236749\t15.1\t0.4044336283190464\n",
      "episode 135700: \t0.025259962670231867\t15.58\t0.40399115044294054\n",
      "episode 135800: \t0.0189959041178597\t16.42\t0.4035486725668347\n",
      "episode 135900: \t0.03238290054573447\t17.7\t0.40310619469072884\n",
      "episode 136000: \t0.0170300734502751\t10.54\t0.402663716814623\n",
      "episode 136100: \t0.021603179625280335\t13.13\t0.40222123893851713\n",
      "episode 136200: \t0.018922822787731636\t13.78\t0.4017787610624113\n",
      "episode 136300: \t0.027882568356480963\t17.56\t0.40133628318630543\n",
      "episode 136400: \t0.023037169642644115\t14.16\t0.4008938053101996\n",
      "episode 136500: \t0.023395372999895792\t14.19\t0.40045132743409373\n",
      "episode 136600: \t0.02328002613354869\t12.97\t0.4000088495579879\n",
      "episode 136700: \t0.02560537687554647\t14.92\t0.399566371681882\n",
      "episode 136800: \t0.02457391088072078\t14.34\t0.3991238938057762\n",
      "episode 136900: \t0.02599997399137157\t17.47\t0.3986814159296703\n",
      "episode 137000: \t0.021541016847865805\t14.64\t0.3982389380535645\n",
      "episode 137100: \t0.02574824084857863\t13.59\t0.3977964601774586\n",
      "episode 137200: \t0.023356136464951417\t12.57\t0.39735398230135277\n",
      "episode 137300: \t0.02252234327307607\t15.1\t0.3969115044252469\n",
      "episode 137400: \t0.021529046389741176\t14.56\t0.39646902654914107\n",
      "episode 137500: \t0.021791270214522113\t15.46\t0.3960265486730352\n",
      "episode 137600: \t0.02312728523313447\t13.64\t0.39558407079692937\n",
      "episode 137700: \t0.027046706415694833\t12.92\t0.3951415929208235\n",
      "episode 137800: \t0.026515357421192633\t14.84\t0.39469911504471766\n",
      "episode 137900: \t0.025522139058387388\t14.25\t0.3942566371686118\n",
      "episode 138000: \t0.02547011644473179\t17.06\t0.39381415929250596\n",
      "episode 138100: \t0.02796750139084029\t16.12\t0.3933716814164001\n",
      "episode 138200: \t0.027541962083474522\t14.68\t0.39292920354029426\n",
      "episode 138300: \t0.021710189304743954\t16.9\t0.3924867256641884\n",
      "episode 138400: \t0.024144766521187973\t16.45\t0.39204424778808256\n",
      "episode 138500: \t0.02266898354461923\t13.78\t0.3916017699119767\n",
      "episode 138600: \t0.020868292156489488\t14.46\t0.39115929203587085\n",
      "episode 138700: \t0.019730656368043567\t13.64\t0.390716814159765\n",
      "episode 138800: \t0.022731736823620473\t15.98\t0.39027433628365915\n",
      "episode 138900: \t0.027796810039469353\t15.17\t0.3898318584075533\n",
      "episode 139000: \t0.024042350961545576\t14.76\t0.38938938053144745\n",
      "episode 139100: \t0.024414236060958133\t14.94\t0.3889469026553416\n",
      "episode 139200: \t0.02395448624925827\t14.56\t0.38850442477923575\n",
      "episode 139300: \t0.0280060548165092\t15.59\t0.3880619469031299\n",
      "episode 139400: \t0.02226189450702896\t12.98\t0.38761946902702404\n",
      "episode 139500: \t0.022531961723017996\t15.97\t0.3871769911509182\n",
      "episode 139600: \t0.02340464502287855\t16.74\t0.38673451327481234\n",
      "episode 139700: \t0.01872383033046924\t12.01\t0.3862920353987065\n",
      "episode 139800: \t0.021202756452447603\t14.14\t0.38584955752260064\n",
      "episode 139900: \t0.01921003853610007\t14.27\t0.3854070796464948\n",
      "episode 140000: \t0.0184059262892319\t10.99\t0.38496460177038894\n",
      "#Average reward per episode 140000: 0.023952213379544878\n",
      "Saved Model\n",
      "#Intermediate time to execute: 1656.702552207311min\n",
      "episode 140100: \t0.027283687235076078\t15.11\t0.3845221238942831\n",
      "episode 140200: \t0.02538311915538608\t15.41\t0.38407964601817723\n",
      "episode 140300: \t0.027102493623089224\t16.69\t0.3836371681420714\n",
      "episode 140400: \t0.02496024034023088\t15.19\t0.38319469026596553\n",
      "episode 140500: \t0.026385476281249622\t14.65\t0.3827522123898597\n",
      "episode 140600: \t0.02559377184608566\t13.89\t0.38230973451375383\n",
      "episode 140700: \t0.021055157383634213\t13.5\t0.381867256637648\n",
      "episode 140800: \t0.018487479496547148\t10.9\t0.3814247787615421\n",
      "episode 140900: \t0.020063415189269542\t14.54\t0.3809823008854363\n",
      "episode 141000: \t0.026913536509501058\t14.96\t0.3805398230093304\n",
      "episode 141100: \t0.02689757903449409\t14.91\t0.3800973451332246\n",
      "episode 141200: \t0.024795912080790853\t14.84\t0.3796548672571187\n",
      "episode 141300: \t0.02250413257762978\t13.0\t0.37921238938101287\n",
      "episode 141400: \t0.024689975297631058\t14.34\t0.378769911504907\n",
      "episode 141500: \t0.02867940352518887\t14.59\t0.37832743362880117\n",
      "episode 141600: \t0.02458663219774577\t15.64\t0.3778849557526953\n",
      "episode 141700: \t0.0213280071387888\t13.83\t0.37744247787658947\n",
      "episode 141800: \t0.02779993675119817\t14.42\t0.3770000000004836\n",
      "episode 141900: \t0.025216189194807778\t15.9\t0.37655752212437776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 142000: \t0.026974951060773703\t13.49\t0.3761150442482719\n",
      "episode 142100: \t0.030658986524988156\t13.59\t0.37567256637216606\n",
      "episode 142200: \t0.02722851087008694\t13.72\t0.3752300884960602\n",
      "episode 142300: \t0.028885638757866462\t14.71\t0.37478761061995436\n",
      "episode 142400: \t0.02089897971306283\t11.12\t0.3743451327438485\n",
      "episode 142500: \t0.02313386351085549\t13.1\t0.37390265486774266\n",
      "episode 142600: \t0.028483634131957217\t13.87\t0.3734601769916368\n",
      "episode 142700: \t0.029059633165337613\t13.81\t0.37301769911553095\n",
      "episode 142800: \t0.026943883330544503\t13.53\t0.3725752212394251\n",
      "episode 142900: \t0.0207354891815908\t12.21\t0.37213274336331925\n",
      "episode 143000: \t0.02352425279807717\t13.16\t0.3716902654872134\n",
      "episode 143100: \t0.018795011621408377\t10.59\t0.37124778761110755\n",
      "episode 143200: \t0.021444331329754648\t13.54\t0.3708053097350017\n",
      "episode 143300: \t0.021797621692151666\t13.63\t0.37036283185889585\n",
      "episode 143400: \t0.022593024402031637\t13.65\t0.36992035398279\n",
      "episode 143500: \t0.02619187205963351\t13.92\t0.36947787610668414\n",
      "episode 143600: \t0.020375064212758257\t10.79\t0.3690353982305783\n",
      "episode 143700: \t0.023699167960872944\t11.28\t0.36859292035447244\n",
      "episode 143800: \t0.028142212386629773\t15.34\t0.3681504424783666\n",
      "episode 143900: \t0.025248431171216397\t12.28\t0.36770796460226074\n",
      "episode 144000: \t0.02838517709629169\t14.51\t0.3672654867261549\n",
      "episode 144100: \t0.02440139107035193\t10.74\t0.36682300885004904\n",
      "episode 144200: \t0.027778586814128786\t12.98\t0.3663805309739432\n",
      "episode 144300: \t0.02280034792561581\t10.97\t0.36593805309783733\n",
      "episode 144400: \t0.026381441407876776\t12.25\t0.3654955752217315\n",
      "episode 144500: \t0.02485114667705273\t13.37\t0.36505309734562563\n",
      "episode 144600: \t0.02740103454042459\t13.45\t0.3646106194695198\n",
      "episode 144700: \t0.026617249707531716\t14.15\t0.36416814159341393\n",
      "episode 144800: \t0.024548826100119533\t12.22\t0.3637256637173081\n",
      "episode 144900: \t0.026893919768502146\t13.26\t0.3632831858412022\n",
      "episode 145000: \t0.02631898363655606\t14.19\t0.3628407079650964\n",
      "#Average reward per episode 145000: 0.023988977614377415\n",
      "episode 145100: \t0.02193973575001345\t13.26\t0.3623982300889905\n",
      "episode 145200: \t0.02903033153181036\t14.13\t0.3619557522128847\n",
      "episode 145300: \t0.02456934204314922\t11.47\t0.3615132743367788\n",
      "episode 145400: \t0.021408301332099464\t10.25\t0.36107079646067297\n",
      "episode 145500: \t0.02980723854423872\t14.6\t0.3606283185845671\n",
      "episode 145600: \t0.024182787052627358\t13.58\t0.36018584070846127\n",
      "episode 145700: \t0.021892850809072197\t12.95\t0.3597433628323554\n",
      "episode 145800: \t0.024007226170795065\t12.73\t0.35930088495624957\n",
      "episode 145900: \t0.0230148369516562\t12.96\t0.3588584070801437\n",
      "episode 146000: \t0.027355229783249512\t14.05\t0.35841592920403786\n",
      "episode 146100: \t0.022916547938353276\t12.15\t0.357973451327932\n",
      "episode 146200: \t0.02980490545603181\t14.71\t0.35753097345182616\n",
      "episode 146300: \t0.022156433680265604\t13.77\t0.3570884955757203\n",
      "episode 146400: \t0.023213669303399426\t12.17\t0.35664601769961446\n",
      "episode 146500: \t0.026312689312968932\t14.58\t0.3562035398235086\n",
      "episode 146600: \t0.024114174359092508\t12.65\t0.35576106194740276\n",
      "episode 146700: \t0.020718494074808\t10.92\t0.3553185840712969\n",
      "episode 146800: \t0.02587104668332155\t14.27\t0.35487610619519105\n",
      "episode 146900: \t0.026709030392160108\t13.17\t0.3544336283190852\n",
      "episode 147000: \t0.03312861787821413\t17.11\t0.35399115044297935\n",
      "episode 147100: \t0.029043299708963292\t12.56\t0.3535486725668735\n",
      "episode 147200: \t0.02639163247785365\t13.48\t0.35310619469076765\n",
      "episode 147300: \t0.02851220985277819\t13.74\t0.3526637168146618\n",
      "episode 147400: \t0.02783801977929385\t13.42\t0.35222123893855595\n",
      "episode 147500: \t0.029805311212858506\t13.39\t0.3517787610624501\n",
      "episode 147600: \t0.020571134687296145\t12.42\t0.35133628318634424\n",
      "episode 147700: \t0.02316018280254466\t13.74\t0.3508938053102384\n",
      "episode 147800: \t0.021556231028013788\t11.33\t0.35045132743413254\n",
      "episode 147900: \t0.027098605389000396\t13.62\t0.3500088495580267\n",
      "episode 148000: \t0.02676544100528396\t12.3\t0.34956637168192084\n",
      "episode 148100: \t0.027844887816009845\t13.94\t0.349123893805815\n",
      "episode 148200: \t0.027012538907408477\t12.61\t0.34868141592970914\n",
      "episode 148300: \t0.02904758600073622\t14.32\t0.3482389380536033\n",
      "episode 148400: \t0.026925445329070548\t13.27\t0.34779646017749744\n",
      "episode 148500: \t0.023665938540969593\t12.31\t0.3473539823013916\n",
      "episode 148600: \t0.019118833825438976\t10.83\t0.34691150442528573\n",
      "episode 148700: \t0.02812852452796228\t12.34\t0.3464690265491799\n",
      "episode 148800: \t0.019975306037570514\t11.33\t0.34602654867307403\n",
      "episode 148900: \t0.02801629638988092\t15.03\t0.3455840707969682\n",
      "episode 149000: \t0.028362762225826555\t15.25\t0.34514159292086233\n",
      "episode 149100: \t0.023344391539363137\t14.56\t0.3446991150447565\n",
      "episode 149200: \t0.02670038627991012\t13.27\t0.3442566371686506\n",
      "episode 149300: \t0.0212912992709018\t11.88\t0.3438141592925448\n",
      "episode 149400: \t0.028600463435315443\t12.36\t0.3433716814164389\n",
      "episode 149500: \t0.024669022191767084\t13.74\t0.34292920354033307\n",
      "episode 149600: \t0.025412751734397165\t12.43\t0.3424867256642272\n",
      "episode 149700: \t0.024628586882016714\t13.4\t0.34204424778812137\n",
      "episode 149800: \t0.023707506126779247\t12.38\t0.3416017699120155\n",
      "episode 149900: \t0.026399616894000725\t12.47\t0.34115929203590967\n",
      "episode 150000: \t0.024929129052951395\t13.54\t0.3407168141598038\n",
      "#Average reward per episode 150000: 0.024036462913897817\n",
      "Saved Model\n",
      "#Intermediate time to execute: 1791.726344883442min\n",
      "episode 150100: \t0.022634551762989494\t13.59\t0.34027433628369796\n",
      "episode 150200: \t0.02910669220903529\t13.84\t0.3398318584075921\n",
      "episode 150300: \t0.030448443701510213\t13.98\t0.33938938053148626\n",
      "episode 150400: \t0.023273311549240026\t12.66\t0.3389469026553804\n",
      "episode 150500: \t0.02429108423280972\t14.11\t0.33850442477927456\n",
      "episode 150600: \t0.02406069008896367\t13.36\t0.3380619469031687\n",
      "episode 150700: \t0.025741742037437492\t11.24\t0.33761946902706286\n",
      "episode 150800: \t0.02872933329157171\t13.0\t0.337176991150957\n",
      "episode 150900: \t0.02608485461641397\t12.76\t0.33673451327485115\n",
      "episode 151000: \t0.02201416197571602\t14.1\t0.3362920353987453\n",
      "episode 151100: \t0.02779314374878391\t15.51\t0.33584955752263945\n",
      "episode 151200: \t0.027413941069494897\t16.1\t0.3354070796465336\n",
      "episode 151300: \t0.027684800269510926\t15.89\t0.33496460177042775\n",
      "episode 151400: \t0.029769566412095\t16.61\t0.3345221238943219\n",
      "episode 151500: \t0.02947964909291119\t15.97\t0.33407964601821605\n",
      "episode 151600: \t0.025557117139540987\t13.29\t0.3336371681421102\n",
      "episode 151700: \t0.02292939892149707\t13.82\t0.33319469026600435\n",
      "episode 151800: \t0.0332718671756142\t17.62\t0.3327522123898985\n",
      "episode 151900: \t0.02772771464337706\t16.38\t0.33230973451379264\n",
      "episode 152000: \t0.023190656862268493\t14.22\t0.3318672566376868\n",
      "episode 152100: \t0.02446566555430241\t15.04\t0.33142477876158094\n",
      "episode 152200: \t0.025347299137496514\t14.64\t0.3309823008854751\n",
      "episode 152300: \t0.023853346411700786\t14.41\t0.33053982300936924\n",
      "episode 152400: \t0.02333908383169875\t13.92\t0.3300973451332634\n",
      "episode 152500: \t0.026366310575206733\t14.66\t0.32965486725715754\n",
      "episode 152600: \t0.022324374993125985\t14.05\t0.3292123893810517\n",
      "episode 152700: \t0.022831708379562516\t14.51\t0.32876991150494583\n",
      "episode 152800: \t0.02247554817543205\t14.47\t0.32832743362884\n",
      "episode 152900: \t0.021449019375392533\t13.22\t0.32788495575273413\n",
      "episode 153000: \t0.026315476547292924\t14.54\t0.3274424778766283\n",
      "episode 153100: \t0.023665559473167553\t12.57\t0.32700000000052243\n",
      "episode 153200: \t0.025771660925787775\t13.51\t0.3265575221244166\n",
      "episode 153300: \t0.027027451647148277\t14.69\t0.3261150442483107\n",
      "episode 153400: \t0.02842132557225987\t15.49\t0.3256725663722049\n",
      "episode 153500: \t0.029588527027141712\t16.81\t0.325230088496099\n",
      "episode 153600: \t0.026509287433534746\t14.67\t0.3247876106199932\n",
      "episode 153700: \t0.027239559915170162\t13.61\t0.3243451327438873\n",
      "episode 153800: \t0.024876844337365162\t13.22\t0.32390265486778147\n",
      "episode 153900: \t0.028469574006248225\t16.27\t0.3234601769916756\n",
      "episode 154000: \t0.029206522186326835\t13.32\t0.32301769911556977\n",
      "episode 154100: \t0.029503543661750547\t16.87\t0.3225752212394639\n",
      "episode 154200: \t0.025722375779131196\t12.97\t0.32213274336335807\n",
      "episode 154300: \t0.023891992178193714\t12.86\t0.3216902654872522\n",
      "episode 154400: \t0.023127427571927647\t12.41\t0.32124778761114636\n",
      "episode 154500: \t0.024989416876182745\t14.07\t0.3208053097350405\n",
      "episode 154600: \t0.022137900103602063\t12.06\t0.32036283185893466\n",
      "episode 154700: \t0.023295454369591115\t14.17\t0.3199203539828288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 154800: \t0.024405132091008187\t14.18\t0.31947787610672296\n",
      "episode 154900: \t0.025563868283916234\t12.98\t0.3190353982306171\n",
      "episode 155000: \t0.025755049630093976\t13.64\t0.31859292035451126\n",
      "#Average reward per episode 155000: 0.024092795740450496\n",
      "episode 155100: \t0.023544100483798153\t12.91\t0.3181504424784054\n",
      "episode 155200: \t0.02447397545066985\t15.16\t0.31770796460229955\n",
      "episode 155300: \t0.024719712474952207\t14.33\t0.3172654867261937\n",
      "episode 155400: \t0.027827822749175658\t16.72\t0.31682300885008785\n",
      "episode 155500: \t0.0237332886869628\t13.06\t0.316380530973982\n",
      "episode 155600: \t0.026296561354673054\t14.38\t0.31593805309787615\n",
      "episode 155700: \t0.023879262164230978\t13.44\t0.3154955752217703\n",
      "episode 155800: \t0.029835113974123372\t15.24\t0.31505309734566445\n",
      "episode 155900: \t0.025517623865910433\t14.15\t0.3146106194695586\n",
      "episode 156000: \t0.022627462583367914\t14.53\t0.31416814159345274\n",
      "episode 156100: \t0.026158030861287766\t15.36\t0.3137256637173469\n",
      "episode 156200: \t0.024811274301836547\t13.16\t0.31328318584124104\n",
      "episode 156300: \t0.02563192701152396\t13.95\t0.3128407079651352\n",
      "episode 156400: \t0.02450061900348782\t13.21\t0.31239823008902934\n",
      "episode 156500: \t0.028334064883945357\t14.28\t0.3119557522129235\n",
      "episode 156600: \t0.02644582279289044\t14.8\t0.31151327433681764\n",
      "episode 156700: \t0.026226773102194297\t10.85\t0.3110707964607118\n",
      "episode 156800: \t0.025485702535432985\t13.47\t0.31062831858460593\n",
      "episode 156900: \t0.01850104889207471\t13.59\t0.3101858407085001\n",
      "episode 157000: \t0.02709135755281972\t14.4\t0.30974336283239423\n",
      "episode 157100: \t0.02290687317728065\t16.27\t0.3093008849562884\n",
      "episode 157200: \t0.022649200587252786\t12.81\t0.30885840708018253\n",
      "episode 157300: \t0.026316351571981138\t14.06\t0.3084159292040767\n",
      "episode 157400: \t0.024142910840480303\t12.49\t0.3079734513279708\n",
      "episode 157500: \t0.02623443916809125\t14.17\t0.307530973451865\n",
      "episode 157600: \t0.025808896982719834\t11.28\t0.3070884955757591\n",
      "episode 157700: \t0.027474748063309767\t13.81\t0.3066460176996533\n",
      "episode 157800: \t0.02728346872862542\t15.22\t0.3062035398235474\n",
      "episode 157900: \t0.022204772526577158\t14.85\t0.30576106194744157\n",
      "episode 158000: \t0.026130221927956034\t11.0\t0.3053185840713357\n",
      "episode 158100: \t0.022555271647587957\t13.13\t0.30487610619522987\n",
      "episode 158200: \t0.02003052317568204\t11.47\t0.304433628319124\n",
      "episode 158300: \t0.02187591833896601\t11.71\t0.30399115044301817\n",
      "episode 158400: \t0.02658789194632792\t14.96\t0.3035486725669123\n",
      "episode 158500: \t0.024901752310953425\t13.96\t0.30310619469080646\n",
      "episode 158600: \t0.022660108856824276\t13.36\t0.3026637168147006\n",
      "episode 158700: \t0.02773752029544376\t15.86\t0.30222123893859476\n",
      "episode 158800: \t0.028663126332231698\t18.29\t0.3017787610624889\n",
      "episode 158900: \t0.02159508073891414\t10.7\t0.30133628318638306\n",
      "episode 159000: \t0.028496700438032426\t16.07\t0.3008938053102772\n",
      "episode 159100: \t0.023459871036132687\t14.32\t0.30045132743417136\n",
      "episode 159200: \t0.02504747319107679\t15.31\t0.3000088495580655\n",
      "episode 159300: \t0.02256203623731861\t14.94\t0.29956637168195965\n",
      "episode 159400: \t0.024378868157280867\t12.72\t0.2991238938058538\n",
      "episode 159500: \t0.025182357861526207\t13.87\t0.29868141592974795\n",
      "episode 159600: \t0.019089736720219973\t13.47\t0.2982389380536421\n",
      "episode 159700: \t0.027103097343162935\t13.98\t0.29779646017753625\n",
      "episode 159800: \t0.022623308685146698\t14.89\t0.2973539823014304\n",
      "episode 159900: \t0.024199968992420575\t14.39\t0.29691150442532455\n",
      "episode 160000: \t0.02688337688863567\t16.78\t0.2964690265492187\n",
      "#Average reward per episode 160000: 0.024116413009494832\n",
      "Saved Model\n",
      "#Intermediate time to execute: 1927.5095262845357min\n",
      "episode 160100: \t0.024221948000834388\t12.24\t0.29602654867311284\n",
      "episode 160200: \t0.02809537137093379\t15.91\t0.295584070797007\n",
      "episode 160300: \t0.02785759857288972\t15.93\t0.29514159292090114\n",
      "episode 160400: \t0.02360852343510829\t14.78\t0.2946991150447953\n",
      "episode 160500: \t0.027777127990135698\t15.69\t0.29425663716868944\n",
      "episode 160600: \t0.026979450823098272\t16.02\t0.2938141592925836\n",
      "episode 160700: \t0.020134230076533633\t14.78\t0.29337168141647774\n",
      "episode 160800: \t0.02354594721922814\t12.96\t0.2929292035403719\n",
      "episode 160900: \t0.025035661942946777\t15.5\t0.29248672566426603\n",
      "episode 161000: \t0.0300221167668502\t16.38\t0.2920442477881602\n",
      "episode 161100: \t0.02249012242128951\t13.2\t0.29160176991205433\n",
      "episode 161200: \t0.027339981402672464\t14.65\t0.2911592920359485\n",
      "episode 161300: \t0.025556681202903317\t15.94\t0.29071681415984263\n",
      "episode 161400: \t0.02334405116861755\t15.33\t0.2902743362837368\n",
      "episode 161500: \t0.024067677521095322\t13.07\t0.2898318584076309\n",
      "episode 161600: \t0.024916095299308716\t16.12\t0.2893893805315251\n",
      "episode 161700: \t0.023648079903439676\t13.23\t0.2889469026554192\n",
      "episode 161800: \t0.024939818611274187\t14.96\t0.2885044247793134\n",
      "episode 161900: \t0.024556980953091608\t15.69\t0.2880619469032075\n",
      "episode 162000: \t0.02478362571187728\t15.17\t0.28761946902710167\n",
      "episode 162100: \t0.02852654674154771\t13.75\t0.2871769911509958\n",
      "episode 162200: \t0.024634423415963065\t15.84\t0.28673451327488997\n",
      "episode 162300: \t0.02364216014028732\t11.48\t0.2862920353987841\n",
      "episode 162400: \t0.034730177859564\t19.34\t0.28584955752267827\n",
      "episode 162500: \t0.021494812174465933\t11.67\t0.2854070796465724\n",
      "episode 162600: \t0.023829683992962373\t14.82\t0.28496460177046656\n",
      "episode 162700: \t0.02362126906179718\t15.27\t0.2845221238943607\n",
      "episode 162800: \t0.022252346328365077\t14.32\t0.28407964601825486\n",
      "episode 162900: \t0.021894564329061787\t13.56\t0.283637168142149\n",
      "episode 163000: \t0.024394379744022313\t14.45\t0.28319469026604316\n",
      "episode 163100: \t0.029782057084232778\t15.39\t0.2827522123899373\n",
      "episode 163200: \t0.02519426515184076\t12.93\t0.28230973451383146\n",
      "episode 163300: \t0.024484850413342012\t14.17\t0.2818672566377256\n",
      "episode 163400: \t0.023330383806206424\t14.09\t0.28142477876161975\n",
      "episode 163500: \t0.026484006700869544\t13.56\t0.2809823008855139\n",
      "episode 163600: \t0.026072404066213233\t14.35\t0.28053982300940805\n",
      "episode 163700: \t0.026053286629039538\t14.73\t0.2800973451333022\n",
      "episode 163800: \t0.024689263366593894\t12.88\t0.27965486725719635\n",
      "episode 163900: \t0.02319079754342348\t12.79\t0.2792123893810905\n",
      "episode 164000: \t0.023939246923917922\t13.05\t0.27876991150498465\n",
      "episode 164100: \t0.02465014082242502\t13.38\t0.2783274336288788\n",
      "episode 164200: \t0.024057797131475267\t16.1\t0.27788495575277294\n",
      "episode 164300: \t0.021619419817907222\t13.94\t0.2774424778766671\n",
      "episode 164400: \t0.02402235203023479\t11.08\t0.27700000000056124\n",
      "episode 164500: \t0.022806487196823988\t13.75\t0.2765575221244554\n",
      "episode 164600: \t0.018826403742988922\t11.53\t0.27611504424834954\n",
      "episode 164700: \t0.02240351224751688\t15.6\t0.2756725663722437\n",
      "episode 164800: \t0.02787888283067945\t15.15\t0.27523008849613784\n",
      "episode 164900: \t0.023548030813492802\t13.86\t0.274787610620032\n",
      "episode 165000: \t0.02560955879863628\t15.93\t0.27434513274392613\n",
      "#Average reward per episode 165000: 0.024137482070601016\n",
      "episode 165100: \t0.021967549136333708\t13.49\t0.2739026548678203\n",
      "episode 165200: \t0.025585757114867148\t13.94\t0.27346017699171443\n",
      "episode 165300: \t0.02416701299733865\t16.75\t0.2730176991156086\n",
      "episode 165400: \t0.02229484565708026\t12.74\t0.27257522123950273\n",
      "episode 165500: \t0.021168190382828297\t12.89\t0.2721327433633969\n",
      "episode 165600: \t0.024538955323130295\t13.26\t0.271690265487291\n",
      "episode 165700: \t0.025614452628587726\t14.42\t0.2712477876111852\n",
      "episode 165800: \t0.025476102079996545\t14.23\t0.2708053097350793\n",
      "episode 165900: \t0.026961313755757797\t15.72\t0.2703628318589735\n",
      "episode 166000: \t0.021466659125051666\t12.28\t0.2699203539828676\n",
      "episode 166100: \t0.023814990192522152\t14.11\t0.26947787610676177\n",
      "episode 166200: \t0.021067441553240362\t14.24\t0.2690353982306559\n",
      "episode 166300: \t0.02530167499363569\t14.47\t0.26859292035455007\n",
      "episode 166400: \t0.02477902435884974\t13.06\t0.2681504424784442\n",
      "episode 166500: \t0.028181755517443733\t14.78\t0.26770796460233837\n",
      "episode 166600: \t0.021152408307510195\t13.11\t0.2672654867262325\n",
      "episode 166700: \t0.026103925126822212\t14.68\t0.26682300885012666\n",
      "episode 166800: \t0.022041835568029414\t11.64\t0.2663805309740208\n",
      "episode 166900: \t0.025884917388678055\t14.47\t0.26593805309791496\n",
      "episode 167000: \t0.023905916907531837\t12.23\t0.2654955752218091\n",
      "episode 167100: \t0.02340157154766744\t12.29\t0.26505309734570326\n",
      "episode 167200: \t0.02026302744673831\t13.24\t0.2646106194695974\n",
      "episode 167300: \t0.01820626134452811\t13.88\t0.26416814159349156\n",
      "episode 167400: \t0.023712028204705752\t13.05\t0.2637256637173857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 167500: \t0.022207372558352284\t13.47\t0.26328318584127985\n",
      "episode 167600: \t0.02287154507113942\t14.48\t0.262840707965174\n",
      "episode 167700: \t0.02663622154979233\t13.46\t0.26239823008906815\n",
      "episode 167800: \t0.025791858449459793\t14.9\t0.2619557522129623\n",
      "episode 167900: \t0.023055888465188336\t13.86\t0.26151327433685645\n",
      "episode 168000: \t0.022738746738041108\t13.37\t0.2610707964607506\n",
      "episode 168100: \t0.0227180054566064\t13.84\t0.26062831858464475\n",
      "episode 168200: \t0.027733113874361913\t14.54\t0.2601858407085389\n",
      "episode 168300: \t0.027886861976102434\t14.1\t0.25974336283243304\n",
      "episode 168400: \t0.019716958582534375\t13.09\t0.2593008849563272\n",
      "episode 168500: \t0.023607909120228567\t12.81\t0.25885840708022134\n",
      "episode 168600: \t0.02345670726858519\t13.37\t0.2584159292041155\n",
      "episode 168700: \t0.02474027984874005\t13.68\t0.25797345132800964\n",
      "episode 168800: \t0.0237175169663769\t14.04\t0.2575309734519038\n",
      "episode 168900: \t0.024534523521890683\t12.15\t0.25708849557579794\n",
      "episode 169000: \t0.024773656196834394\t13.39\t0.2566460176996921\n",
      "episode 169100: \t0.024640797856021943\t13.29\t0.25620353982358623\n",
      "episode 169200: \t0.019297328036491597\t12.7\t0.2557610619474804\n",
      "episode 169300: \t0.023244130171978614\t11.37\t0.25531858407137453\n",
      "episode 169400: \t0.026732338904639413\t11.06\t0.2548761061952687\n",
      "episode 169500: \t0.02487417697011758\t13.47\t0.25443362831916283\n",
      "episode 169600: \t0.02188617497155681\t11.7\t0.253991150443057\n",
      "episode 169700: \t0.0219466980034738\t10.92\t0.2535486725669511\n",
      "episode 169800: \t0.02540361071884483\t12.28\t0.2531061946908453\n",
      "episode 169900: \t0.025647639631256828\t12.0\t0.2526637168147394\n",
      "episode 170000: \t0.023196242637330385\t9.74\t0.2522212389386336\n",
      "#Average reward per episode 170000: 0.0241276231392332\n",
      "Saved Model\n",
      "#Intermediate time to execute: 2050.0900850494704min\n",
      "episode 170100: \t0.023804632045906063\t13.68\t0.2517787610625277\n",
      "episode 170200: \t0.028681945536935868\t13.83\t0.25133628318642187\n",
      "episode 170300: \t0.024144658693932106\t11.14\t0.250893805310316\n",
      "episode 170400: \t0.023859845217085486\t12.65\t0.25045132743421017\n",
      "episode 170500: \t0.017795497872878464\t12.08\t0.2500088495581043\n",
      "episode 170600: \t0.024906624060680033\t12.33\t0.24956637168199847\n",
      "episode 170700: \t0.022097040342074006\t10.69\t0.24912389380589262\n",
      "episode 170800: \t0.023505554225682207\t14.63\t0.24868141592978676\n",
      "episode 170900: \t0.02485703197638483\t13.13\t0.2482389380536809\n",
      "episode 171000: \t0.02206010986705615\t13.2\t0.24779646017757506\n",
      "episode 171100: \t0.02329554696729776\t12.17\t0.2473539823014692\n",
      "episode 171200: \t0.021247843399427504\t10.33\t0.24691150442536336\n",
      "episode 171300: \t0.023610122501089636\t11.7\t0.2464690265492575\n",
      "episode 171400: \t0.021520803552941014\t13.23\t0.24602654867315166\n",
      "episode 171500: \t0.02212582451547309\t10.46\t0.2455840707970458\n",
      "episode 171600: \t0.01870466856560325\t10.9\t0.24514159292093995\n",
      "episode 171700: \t0.02082749061323318\t10.79\t0.2446991150448341\n",
      "episode 171800: \t0.025642769498607335\t13.67\t0.24425663716872825\n",
      "episode 171900: \t0.021832461223166833\t11.61\t0.2438141592926224\n",
      "episode 172000: \t0.02429756764330067\t12.76\t0.24337168141651655\n",
      "episode 172100: \t0.023122159475872213\t14.74\t0.2429292035404107\n",
      "episode 172200: \t0.026139808428391333\t12.9\t0.24248672566430485\n",
      "episode 172300: \t0.022939778132799273\t11.64\t0.242044247788199\n",
      "episode 172400: \t0.022400360095308693\t13.13\t0.24160176991209315\n",
      "episode 172500: \t0.024347716375081534\t13.51\t0.2411592920359873\n",
      "episode 172600: \t0.027058550968340086\t14.28\t0.24071681415988144\n",
      "episode 172700: \t0.022981254314375286\t12.61\t0.2402743362837756\n",
      "episode 172800: \t0.02330091006603281\t11.48\t0.23983185840766974\n",
      "episode 172900: \t0.0255612250891008\t11.53\t0.2393893805315639\n",
      "episode 173000: \t0.02395766988669755\t13.05\t0.23894690265545804\n",
      "episode 173100: \t0.02084607428353612\t11.92\t0.2385044247793522\n",
      "episode 173200: \t0.020695360635861967\t11.63\t0.23806194690324634\n",
      "episode 173300: \t0.02372755962335468\t11.55\t0.23761946902714048\n",
      "episode 173400: \t0.019955983959690785\t11.8\t0.23717699115103463\n",
      "episode 173500: \t0.017997474031086064\t12.02\t0.23673451327492878\n",
      "episode 173600: \t0.02476741516030017\t14.29\t0.23629203539882293\n",
      "episode 173700: \t0.02403624830506498\t13.13\t0.23584955752271708\n",
      "episode 173800: \t0.023197083591254514\t11.94\t0.23540707964661123\n",
      "episode 173900: \t0.020784774892412962\t12.27\t0.23496460177050538\n",
      "episode 174000: \t0.022180685893610753\t12.66\t0.23452212389439953\n",
      "episode 174100: \t0.01961186192120313\t10.59\t0.23407964601829367\n",
      "episode 174200: \t0.02311701342716139\t11.39\t0.23363716814218782\n",
      "episode 174300: \t0.02326953798198461\t13.77\t0.23319469026608197\n",
      "episode 174400: \t0.02459886315871757\t12.77\t0.23275221238997612\n",
      "episode 174500: \t0.025680055996951973\t11.55\t0.23230973451387027\n",
      "episode 174600: \t0.023001665805366403\t12.06\t0.23186725663776442\n",
      "episode 174700: \t0.023951931753937464\t11.79\t0.23142477876165857\n",
      "episode 174800: \t0.021243840855150836\t12.84\t0.23098230088555272\n",
      "episode 174900: \t0.023564900575200158\t12.76\t0.23053982300944686\n",
      "episode 175000: \t0.025476611599476447\t12.48\t0.230097345133341\n",
      "#Average reward per episode 175000: 0.02409673814359908\n",
      "episode 175100: \t0.02487619401951304\t12.13\t0.22965486725723516\n",
      "episode 175200: \t0.022066643659531815\t12.3\t0.2292123893811293\n",
      "episode 175300: \t0.024152410564213685\t10.17\t0.22876991150502346\n",
      "episode 175400: \t0.023302246159642128\t11.67\t0.2283274336289176\n",
      "episode 175500: \t0.01996944871008584\t10.7\t0.22788495575281176\n",
      "episode 175600: \t0.024574671510808544\t11.19\t0.2274424778767059\n",
      "episode 175700: \t0.022983397868347234\t11.59\t0.22700000000060006\n",
      "episode 175800: \t0.021022188733112998\t11.82\t0.2265575221244942\n",
      "episode 175900: \t0.021031485268250282\t14.85\t0.22611504424838835\n",
      "episode 176000: \t0.023318584236420553\t13.23\t0.2256725663722825\n",
      "episode 176100: \t0.026293621289474628\t13.79\t0.22523008849617665\n",
      "episode 176200: \t0.020713968176291155\t12.0\t0.2247876106200708\n",
      "episode 176300: \t0.022152726414493392\t11.62\t0.22434513274396495\n",
      "episode 176400: \t0.02680639317459266\t11.33\t0.2239026548678591\n",
      "episode 176500: \t0.025030886118699493\t11.44\t0.22346017699175325\n",
      "episode 176600: \t0.022537882987091282\t10.88\t0.2230176991156474\n",
      "episode 176700: \t0.02217982926710868\t12.5\t0.22257522123954154\n",
      "episode 176800: \t0.023555288440982102\t11.05\t0.2221327433634357\n",
      "episode 176900: \t0.020303378369361035\t10.95\t0.22169026548732984\n",
      "episode 177000: \t0.025783181615971453\t12.93\t0.221247787611224\n",
      "episode 177100: \t0.0185120257974412\t10.14\t0.22080530973511814\n",
      "episode 177200: \t0.018553402625874807\t8.84\t0.2203628318590123\n",
      "episode 177300: \t0.020965827687260755\t11.73\t0.21992035398290644\n",
      "episode 177400: \t0.024284648733095982\t12.41\t0.21947787610680058\n",
      "episode 177500: \t0.021043737834946414\t9.82\t0.21903539823069473\n",
      "episode 177600: \t0.022953886101436654\t12.23\t0.21859292035458888\n",
      "episode 177700: \t0.02650220898373611\t11.89\t0.21815044247848303\n",
      "episode 177800: \t0.020612222063690015\t10.15\t0.21770796460237718\n",
      "episode 177900: \t0.024217199148959728\t12.74\t0.21726548672627133\n",
      "episode 178000: \t0.02441803830800488\t12.03\t0.21682300885016548\n",
      "episode 178100: \t0.02411421357999629\t11.34\t0.21638053097405963\n",
      "episode 178200: \t0.023999120658767418\t13.87\t0.21593805309795377\n",
      "episode 178300: \t0.023794879097470564\t12.05\t0.21549557522184792\n",
      "episode 178400: \t0.020054750207636265\t11.56\t0.21505309734574207\n",
      "episode 178500: \t0.02368095212907265\t11.57\t0.21461061946963622\n",
      "episode 178600: \t0.023512962606640996\t10.87\t0.21416814159353037\n",
      "episode 178700: \t0.021146320881147474\t12.62\t0.21372566371742452\n",
      "episode 178800: \t0.01958715748996473\t9.2\t0.21328318584131867\n",
      "episode 178900: \t0.023698367587227036\t12.29\t0.21284070796521282\n",
      "episode 179000: \t0.023410364430934267\t9.73\t0.21239823008910697\n",
      "episode 179100: \t0.02036994695802695\t12.04\t0.21195575221300111\n",
      "episode 179200: \t0.02272439283322988\t11.03\t0.21151327433689526\n",
      "episode 179300: \t0.020992514981854334\t9.05\t0.2110707964607894\n",
      "episode 179400: \t0.022489938976188308\t11.46\t0.21062831858468356\n",
      "episode 179500: \t0.019986933157192504\t10.65\t0.2101858407085777\n",
      "episode 179600: \t0.02172022223210592\t9.39\t0.20974336283247186\n",
      "episode 179700: \t0.027910296938945582\t10.17\t0.209300884956366\n",
      "episode 179800: \t0.023656385963868966\t8.44\t0.20885840708026016\n",
      "episode 179900: \t0.019305186395766945\t10.34\t0.2084159292041543\n",
      "episode 180000: \t0.02483059121471499\t10.25\t0.20797345132804845\n",
      "#Average reward per episode 180000: 0.024058330485270972\n",
      "Saved Model\n",
      "#Intermediate time to execute: 2172.7801090240478min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 180100: \t0.025838985362876907\t11.84\t0.2075309734519426\n",
      "episode 180200: \t0.021954059908231655\t9.64\t0.20708849557583675\n",
      "episode 180300: \t0.024111772200549074\t10.92\t0.2066460176997309\n",
      "episode 180400: \t0.018545782343677982\t10.42\t0.20620353982362505\n",
      "episode 180500: \t0.024028684599157257\t12.32\t0.2057610619475192\n",
      "episode 180600: \t0.021874169157021756\t10.76\t0.20531858407141335\n",
      "episode 180700: \t0.02169384744369267\t10.35\t0.2048761061953075\n",
      "episode 180800: \t0.020204122892845157\t10.39\t0.20443362831920164\n",
      "episode 180900: \t0.02192796731810795\t10.21\t0.2039911504430958\n",
      "episode 181000: \t0.023895291793648073\t9.6\t0.20354867256698994\n",
      "episode 181100: \t0.021216552825440802\t10.15\t0.2031061946908841\n",
      "episode 181200: \t0.025060564201584805\t9.84\t0.20266371681477824\n",
      "episode 181300: \t0.027003167503582243\t11.99\t0.2022212389386724\n",
      "episode 181400: \t0.023126904593905807\t11.23\t0.20177876106256654\n",
      "episode 181500: \t0.02736705021967971\t14.07\t0.20133628318646069\n",
      "episode 181600: \t0.024600383611015682\t11.74\t0.20089380531035483\n",
      "episode 181700: \t0.02667501295467627\t12.54\t0.20045132743424898\n",
      "episode 181800: \t0.02395706650735641\t11.45\t0.20000884955814313\n",
      "episode 181900: \t0.020986948220511326\t11.92\t0.19956637168203728\n",
      "episode 182000: \t0.026309599446522648\t10.51\t0.19912389380593143\n",
      "episode 182100: \t0.017812825572594962\t11.85\t0.19868141592982558\n",
      "episode 182200: \t0.021541950916249105\t11.32\t0.19823893805371973\n",
      "episode 182300: \t0.02503621307367635\t11.7\t0.19779646017761388\n",
      "episode 182400: \t0.024346594544623793\t11.58\t0.19735398230150802\n",
      "episode 182500: \t0.024332147610127332\t11.87\t0.19691150442540217\n",
      "episode 182600: \t0.028067479575600435\t14.54\t0.19646902654929632\n",
      "episode 182700: \t0.02085454454653522\t9.95\t0.19602654867319047\n",
      "episode 182800: \t0.02317236429026962\t11.28\t0.19558407079708462\n",
      "episode 182900: \t0.025594233492589904\t12.58\t0.19514159292097877\n",
      "episode 183000: \t0.02826713797289051\t13.4\t0.19469911504487292\n",
      "episode 183100: \t0.024454387663431224\t11.93\t0.19425663716876707\n",
      "episode 183200: \t0.020730727253016442\t12.95\t0.19381415929266121\n",
      "episode 183300: \t0.020065539959551446\t11.96\t0.19337168141655536\n",
      "episode 183400: \t0.02209851345209217\t10.08\t0.1929292035404495\n",
      "episode 183500: \t0.023538070270719292\t14.73\t0.19248672566434366\n",
      "episode 183600: \t0.02562709153578545\t13.78\t0.1920442477882378\n",
      "episode 183700: \t0.026047211570840948\t13.67\t0.19160176991213196\n",
      "episode 183800: \t0.02232925384126859\t10.99\t0.1911592920360261\n",
      "episode 183900: \t0.025430644447945724\t13.29\t0.19071681415992026\n",
      "episode 184000: \t0.030479764346515382\t16.11\t0.1902743362838144\n",
      "episode 184100: \t0.019162431437661692\t10.9\t0.18983185840770855\n",
      "episode 184200: \t0.02332789172478823\t11.64\t0.1893893805316027\n",
      "episode 184300: \t0.02764576548917349\t12.88\t0.18894690265549685\n",
      "episode 184400: \t0.025374712893046155\t10.87\t0.188504424779391\n",
      "episode 184500: \t0.021196390096834525\t11.21\t0.18806194690328515\n",
      "episode 184600: \t0.024629361366199122\t14.17\t0.1876194690271793\n",
      "episode 184700: \t0.023187310474699477\t12.29\t0.18717699115107345\n",
      "episode 184800: \t0.024236122167652557\t12.73\t0.1867345132749676\n",
      "episode 184900: \t0.027552586610966996\t15.72\t0.18629203539886174\n",
      "episode 185000: \t0.02933070934003404\t14.03\t0.1858495575227559\n",
      "#Average reward per episode 185000: 0.024054509613042806\n",
      "episode 185100: \t0.02734884981916765\t15.79\t0.18540707964665004\n",
      "episode 185200: \t0.026781304675494146\t13.88\t0.1849646017705442\n",
      "episode 185300: \t0.023284607875010934\t14.53\t0.18452212389443834\n",
      "episode 185400: \t0.024191262769462533\t15.17\t0.1840796460183325\n",
      "episode 185500: \t0.028698300946162093\t14.61\t0.18363716814222664\n",
      "episode 185600: \t0.025184704642976185\t16.13\t0.18319469026612079\n",
      "episode 185700: \t0.026174828637760023\t13.23\t0.18275221239001493\n",
      "episode 185800: \t0.029621751825386032\t18.27\t0.18230973451390908\n",
      "episode 185900: \t0.02407641466926591\t14.67\t0.18186725663780323\n",
      "episode 186000: \t0.025109494707681278\t13.83\t0.18142477876169738\n",
      "episode 186100: \t0.025395556140322885\t14.29\t0.18098230088559153\n",
      "episode 186200: \t0.027389345944579705\t14.69\t0.18053982300948568\n",
      "episode 186300: \t0.02737893573373064\t16.62\t0.18009734513337983\n",
      "episode 186400: \t0.022649848887995105\t14.28\t0.17965486725727398\n",
      "episode 186500: \t0.017398629543330227\t15.65\t0.17921238938116812\n",
      "episode 186600: \t0.024700563699980083\t13.5\t0.17876991150506227\n",
      "episode 186700: \t0.025114315657225217\t13.45\t0.17832743362895642\n",
      "episode 186800: \t0.020617959792977692\t12.31\t0.17788495575285057\n",
      "episode 186900: \t0.023186908762499202\t15.22\t0.17744247787674472\n",
      "episode 187000: \t0.021183191269601526\t12.97\t0.17700000000063887\n",
      "episode 187100: \t0.025965227252529047\t14.66\t0.17655752212453302\n",
      "episode 187200: \t0.023911600813113144\t14.1\t0.17611504424842717\n",
      "episode 187300: \t0.022934989507422534\t15.72\t0.17567256637232131\n",
      "episode 187400: \t0.021527436551653727\t14.05\t0.17523008849621546\n",
      "episode 187500: \t0.023001341718539785\t14.05\t0.1747876106201096\n",
      "episode 187600: \t0.029540019357248957\t17.22\t0.17434513274400376\n",
      "episode 187700: \t0.029853972237010563\t16.28\t0.1739026548678979\n",
      "episode 187800: \t0.02749822064320554\t15.89\t0.17346017699179206\n",
      "episode 187900: \t0.023233380699966916\t14.41\t0.1730176991156862\n",
      "episode 188000: \t0.028721627476740993\t14.45\t0.17257522123958036\n",
      "episode 188100: \t0.018470465719928653\t10.75\t0.1721327433634745\n",
      "episode 188200: \t0.028999717740467904\t12.59\t0.17169026548736865\n",
      "episode 188300: \t0.023910143711862487\t11.11\t0.1712477876112628\n",
      "episode 188400: \t0.026698570322456518\t14.35\t0.17080530973515695\n",
      "episode 188500: \t0.025776349771414627\t11.36\t0.1703628318590511\n",
      "episode 188600: \t0.03366066426501096\t12.72\t0.16992035398294525\n",
      "episode 188700: \t0.030019890264073278\t15.29\t0.1694778761068394\n",
      "episode 188800: \t0.019468923275176766\t10.26\t0.16903539823073355\n",
      "episode 188900: \t0.02564362934279394\t11.11\t0.1685929203546277\n",
      "episode 189000: \t0.02544358578144048\t13.37\t0.16815044247852184\n",
      "episode 189100: \t0.03216758730248528\t14.28\t0.167707964602416\n",
      "episode 189200: \t0.027367945664936614\t15.1\t0.16726548672631014\n",
      "episode 189300: \t0.024043474778712177\t11.56\t0.1668230088502043\n",
      "episode 189400: \t0.016843501614914432\t12.61\t0.16638053097409844\n",
      "episode 189500: \t0.022577986264175065\t10.35\t0.1659380530979926\n",
      "episode 189600: \t0.02579224657705046\t13.66\t0.16549557522188674\n",
      "episode 189700: \t0.023988130800489126\t11.7\t0.16505309734578089\n",
      "episode 189800: \t0.025951722705880264\t14.18\t0.16461061946967503\n",
      "episode 189900: \t0.027231133433439112\t13.21\t0.16416814159356918\n",
      "episode 190000: \t0.02354851913505295\t11.21\t0.16372566371746333\n",
      "#Average reward per episode 190000: 0.024084274507820504\n",
      "Saved Model\n",
      "#Intermediate time to execute: 2298.2555939515432min\n",
      "episode 190100: \t0.028035737106721116\t16.45\t0.16328318584135748\n",
      "episode 190200: \t0.024648770874629723\t11.25\t0.16284070796525163\n",
      "episode 190300: \t0.027860688982089057\t13.3\t0.16239823008914578\n",
      "episode 190400: \t0.02352617911386524\t10.47\t0.16195575221303993\n",
      "episode 190500: \t0.02460686092149047\t11.29\t0.16151327433693408\n",
      "episode 190600: \t0.023278704604067526\t13.31\t0.16107079646082822\n",
      "episode 190700: \t0.029099588485041617\t14.63\t0.16062831858472237\n",
      "episode 190800: \t0.021112969229913278\t12.41\t0.16018584070861652\n",
      "episode 190900: \t0.021104261603095212\t11.74\t0.15974336283251067\n",
      "episode 191000: \t0.0224252444124748\t11.68\t0.15930088495640482\n",
      "episode 191100: \t0.020852374073874393\t11.84\t0.15885840708029897\n",
      "episode 191200: \t0.022727375320409315\t12.25\t0.15841592920419312\n",
      "episode 191300: \t0.01984992356283668\t11.88\t0.15797345132808727\n",
      "episode 191400: \t0.026920879655765312\t12.98\t0.15753097345198142\n",
      "episode 191500: \t0.026422379681340324\t11.44\t0.15708849557587556\n",
      "episode 191600: \t0.027819125602982275\t14.55\t0.1566460176997697\n",
      "episode 191700: \t0.025737972556222316\t10.96\t0.15620353982366386\n",
      "episode 191800: \t0.027383129053300648\t13.05\t0.155761061947558\n",
      "episode 191900: \t0.02079305882332378\t13.37\t0.15531858407145216\n",
      "episode 192000: \t0.02027041932633968\t10.64\t0.1548761061953463\n",
      "episode 192100: \t0.028047127738292776\t13.33\t0.15443362831924046\n",
      "episode 192200: \t0.02836844244376837\t15.07\t0.1539911504431346\n",
      "episode 192300: \t0.02510014570888399\t12.24\t0.15354867256702875\n",
      "episode 192400: \t0.025314918213185735\t10.88\t0.1531061946909229\n",
      "episode 192500: \t0.020893350746810563\t10.38\t0.15266371681481705\n",
      "episode 192600: \t0.032946953940536955\t14.53\t0.1522212389387112\n",
      "episode 192700: \t0.02957043551119474\t15.01\t0.15177876106260535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 192800: \t0.028176141884433865\t15.16\t0.1513362831864995\n",
      "episode 192900: \t0.02311098641463632\t14.12\t0.15089380531039365\n",
      "episode 193000: \t0.023943124866538587\t13.0\t0.1504513274342878\n",
      "episode 193100: \t0.022651377702230243\t12.41\t0.15000884955818194\n",
      "episode 193200: \t0.021947531412264056\t11.12\t0.1495663716820761\n",
      "episode 193300: \t0.024465790033470713\t14.41\t0.14912389380597024\n",
      "episode 193400: \t0.029788701556698154\t16.24\t0.1486814159298644\n",
      "episode 193500: \t0.027493326580450953\t12.75\t0.14823893805375854\n",
      "episode 193600: \t0.027286313437041895\t14.69\t0.1477964601776527\n",
      "episode 193700: \t0.020354147841132743\t11.86\t0.14735398230154684\n",
      "episode 193800: \t0.026937476947414205\t15.12\t0.146911504425441\n",
      "episode 193900: \t0.0238330613364781\t13.65\t0.14646902654933514\n",
      "episode 194000: \t0.025452132938844563\t13.81\t0.14602654867322928\n",
      "episode 194100: \t0.024618951696836065\t12.67\t0.14558407079712343\n",
      "episode 194200: \t0.019504199724916866\t12.04\t0.14514159292101758\n",
      "episode 194300: \t0.015880937798755303\t11.6\t0.14469911504491173\n",
      "episode 194400: \t0.02912383381106845\t13.98\t0.14425663716880588\n",
      "episode 194500: \t0.026096545119215463\t14.3\t0.14381415929270003\n",
      "episode 194600: \t0.030653228683572616\t16.58\t0.14337168141659418\n",
      "episode 194700: \t0.025096316745900942\t10.41\t0.14292920354048833\n",
      "episode 194800: \t0.025359294408874897\t18.01\t0.14248672566438247\n",
      "episode 194900: \t0.026990128190911004\t13.85\t0.14204424778827662\n",
      "episode 195000: \t0.029717205592491337\t12.46\t0.14160176991217077\n",
      "#Average reward per episode 195000: 0.024109394531731037\n",
      "episode 195100: \t0.025465027038925715\t13.22\t0.14115929203606492\n",
      "episode 195200: \t0.03087209712579481\t13.41\t0.14071681415995907\n",
      "episode 195300: \t0.028062796213656763\t15.16\t0.14027433628385322\n",
      "episode 195400: \t0.02687402438189117\t12.31\t0.13983185840774737\n",
      "episode 195500: \t0.025141222582813868\t13.11\t0.13938938053164152\n",
      "episode 195600: \t0.028137118660662902\t13.59\t0.13894690265553566\n",
      "episode 195700: \t0.026052516505468228\t13.21\t0.1385044247794298\n",
      "episode 195800: \t0.028538683363907705\t13.94\t0.13806194690332396\n",
      "episode 195900: \t0.02714844810674356\t14.25\t0.1376194690272181\n",
      "episode 196000: \t0.025141851925305568\t11.97\t0.13717699115111226\n",
      "episode 196100: \t0.02378158816997116\t11.36\t0.1367345132750064\n",
      "episode 196200: \t0.02217497275750974\t13.77\t0.13629203539890056\n",
      "episode 196300: \t0.029399155854904442\t15.45\t0.1358495575227947\n",
      "episode 196400: \t0.026543627710388155\t15.92\t0.13540707964668885\n",
      "episode 196500: \t0.02753371115592863\t14.45\t0.134964601770583\n",
      "episode 196600: \t0.028384827811427576\t13.7\t0.13452212389447715\n",
      "episode 196700: \t0.02093639111065322\t12.75\t0.1340796460183713\n",
      "episode 196800: \t0.024882439603079315\t13.32\t0.13363716814226545\n",
      "episode 196900: \t0.02311041848297221\t12.48\t0.1331946902661596\n",
      "episode 197000: \t0.025677394030954037\t13.27\t0.13275221239005375\n",
      "episode 197100: \t0.029701946410740535\t14.3\t0.1323097345139479\n",
      "episode 197200: \t0.023291175845409323\t13.86\t0.13186725663784205\n",
      "episode 197300: \t0.029094619862016127\t16.41\t0.1314247787617362\n",
      "episode 197400: \t0.031026383079097754\t14.43\t0.13098230088563034\n",
      "episode 197500: \t0.02744870171887749\t14.38\t0.1305398230095245\n",
      "episode 197600: \t0.02715531716451465\t12.29\t0.13009734513341864\n",
      "episode 197700: \t0.029196363891041823\t12.99\t0.1296548672573128\n",
      "episode 197800: \t0.030193617164909255\t14.78\t0.12921238938120694\n",
      "episode 197900: \t0.027143785759773848\t15.35\t0.1287699115051011\n",
      "episode 198000: \t0.024364570648763073\t13.7\t0.12832743362899524\n",
      "episode 198100: \t0.019837983597570934\t12.87\t0.12788495575288938\n",
      "episode 198200: \t0.03334495309157188\t15.8\t0.12744247787678353\n",
      "episode 198300: \t0.027879986346488788\t14.66\t0.12700000000067768\n",
      "episode 198400: \t0.026418015989293293\t13.62\t0.12655752212457183\n",
      "episode 198500: \t0.024246423718884504\t13.88\t0.12611504424846598\n",
      "episode 198600: \t0.024835824795804467\t13.52\t0.12567256637236013\n",
      "episode 198700: \t0.03086300165320617\t13.05\t0.12523008849625428\n",
      "episode 198800: \t0.025686606655339884\t14.07\t0.12478761062014843\n",
      "episode 198900: \t0.027947728127247898\t11.64\t0.12434513274404257\n",
      "episode 199000: \t0.025885491329984748\t12.64\t0.12390265486793672\n",
      "episode 199100: \t0.028208912581486275\t14.41\t0.12346017699183087\n",
      "episode 199200: \t0.030276951786793106\t12.61\t0.12301769911572502\n",
      "episode 199300: \t0.02535688352817594\t11.88\t0.12257522123961917\n",
      "episode 199400: \t0.02575731799540198\t13.97\t0.12213274336351332\n",
      "episode 199500: \t0.0219492618687414\t10.71\t0.12169026548740747\n",
      "episode 199600: \t0.026301105949305945\t11.88\t0.12124778761130162\n",
      "episode 199700: \t0.0257452815087995\t14.11\t0.12080530973519576\n",
      "episode 199800: \t0.022524130344937433\t12.2\t0.12036283185908991\n",
      "episode 199900: \t0.026195111790432282\t11.28\t0.11992035398298406\n",
      "episode 200000: \t0.028021545232041197\t13.92\t0.11947787610687821\n",
      "#Average reward per episode 200000: 0.024171538324452544\n",
      "Saved Model\n",
      "#Intermediate time to execute: 2426.1925739010176min\n",
      "episode 200100: \t0.02512861645176628\t13.59\t0.11903539823077236\n",
      "episode 200200: \t0.02314970161068605\t11.7\t0.11859292035466651\n",
      "episode 200300: \t0.022925912091689312\t10.79\t0.11815044247856066\n",
      "episode 200400: \t0.025516809546246456\t13.63\t0.1177079646024548\n",
      "episode 200500: \t0.02270064782107576\t12.98\t0.11726548672634896\n",
      "episode 200600: \t0.02865989397757995\t15.65\t0.1168230088502431\n",
      "episode 200700: \t0.02873500589246982\t14.77\t0.11638053097413725\n",
      "episode 200800: \t0.027114429761827884\t12.91\t0.1159380530980314\n",
      "episode 200900: \t0.0244975726502195\t11.38\t0.11549557522192555\n",
      "episode 201000: \t0.02561749458986873\t11.99\t0.1150530973458197\n",
      "episode 201100: \t0.02542360171998576\t11.84\t0.11461061946971385\n",
      "episode 201200: \t0.02770826931352248\t14.11\t0.114168141593608\n",
      "episode 201300: \t0.028336598777951454\t11.7\t0.11372566371750215\n",
      "episode 201400: \t0.02902507646692815\t13.97\t0.1132831858413963\n",
      "episode 201500: \t0.02660166538044712\t13.64\t0.11284070796529044\n",
      "episode 201600: \t0.025058184020486048\t13.34\t0.11239823008918459\n",
      "episode 201700: \t0.02783946824424071\t13.38\t0.11195575221307874\n",
      "episode 201800: \t0.030981780562032078\t12.18\t0.11151327433697289\n",
      "episode 201900: \t0.028113009415498658\t13.7\t0.11107079646086704\n",
      "episode 202000: \t0.026713749843487854\t13.94\t0.11062831858476119\n",
      "episode 202100: \t0.02667734239656697\t12.26\t0.11018584070865534\n",
      "episode 202200: \t0.02740028520524578\t13.26\t0.10974336283254948\n",
      "episode 202300: \t0.023079760279163714\t11.96\t0.10930088495644363\n",
      "episode 202400: \t0.025826681351759643\t13.38\t0.10885840708033778\n",
      "episode 202500: \t0.02692168561944722\t12.22\t0.10841592920423193\n",
      "episode 202600: \t0.023887223173375847\t9.98\t0.10797345132812608\n",
      "episode 202700: \t0.025086688737662143\t14.51\t0.10753097345202023\n",
      "episode 202800: \t0.027811151335579633\t12.57\t0.10708849557591438\n",
      "episode 202900: \t0.026132806589311833\t15.65\t0.10664601769980853\n",
      "episode 203000: \t0.030674923711090155\t15.2\t0.10620353982370268\n",
      "episode 203100: \t0.021604307174527663\t11.46\t0.10576106194759682\n",
      "episode 203200: \t0.02352263206406193\t11.7\t0.10531858407149097\n",
      "episode 203300: \t0.029126474530644132\t11.8\t0.10487610619538512\n",
      "episode 203400: \t0.02708738274156437\t12.15\t0.10443362831927927\n",
      "episode 203500: \t0.022539103991199738\t12.42\t0.10399115044317342\n",
      "episode 203600: \t0.025791168874142248\t10.92\t0.10354867256706757\n",
      "episode 203700: \t0.029018526463991914\t14.82\t0.10310619469096172\n",
      "episode 203800: \t0.025865465092401077\t15.38\t0.10266371681485587\n",
      "episode 203900: \t0.029567569062422763\t11.67\t0.10222123893875001\n",
      "episode 204000: \t0.028447867678239213\t13.89\t0.10177876106264416\n",
      "episode 204100: \t0.024885177303276138\t14.36\t0.10133628318653831\n",
      "episode 204200: \t0.02392204164963255\t13.83\t0.10089380531043246\n",
      "episode 204300: \t0.02607088424818063\t14.27\t0.10045132743432661\n",
      "episode 204400: \t0.025948000114026457\t14.95\t0.10000884955822076\n",
      "episode 204500: \t0.020421704608672372\t13.28\t0.09999557522193758\n",
      "episode 204600: \t0.027172053709342087\t16.61\t0.09999557522193758\n",
      "episode 204700: \t0.0256966085329932\t14.82\t0.09999557522193758\n",
      "episode 204800: \t0.031225905021797597\t17.7\t0.09999557522193758\n",
      "episode 204900: \t0.023165714309380667\t14.93\t0.09999557522193758\n",
      "episode 205000: \t0.02596804819785153\t15.5\t0.09999557522193758\n",
      "#Average reward per episode 205000: 0.02422120454673693\n",
      "episode 205100: \t0.0333136051788106\t14.93\t0.09999557522193758\n",
      "episode 205200: \t0.02991610754237035\t13.93\t0.09999557522193758\n",
      "episode 205300: \t0.026658445858465107\t14.1\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 205400: \t0.02143865648411491\t13.44\t0.09999557522193758\n",
      "episode 205500: \t0.028564732929190532\t14.57\t0.09999557522193758\n",
      "episode 205600: \t0.02324940142641272\t11.98\t0.09999557522193758\n",
      "episode 205700: \t0.030841613091575102\t15.93\t0.09999557522193758\n",
      "episode 205800: \t0.03093956277841562\t15.68\t0.09999557522193758\n",
      "episode 205900: \t0.02667431043510777\t14.02\t0.09999557522193758\n",
      "episode 206000: \t0.025622417486771666\t14.41\t0.09999557522193758\n",
      "episode 206100: \t0.031370166300334706\t14.26\t0.09999557522193758\n",
      "episode 206200: \t0.03132906181789866\t15.83\t0.09999557522193758\n",
      "episode 206300: \t0.024150713520697923\t13.2\t0.09999557522193758\n",
      "episode 206400: \t0.018952175941450253\t12.35\t0.09999557522193758\n",
      "episode 206500: \t0.02215923656449241\t10.5\t0.09999557522193758\n",
      "episode 206600: \t0.028473665196621006\t13.14\t0.09999557522193758\n",
      "episode 206700: \t0.023566140350386268\t12.11\t0.09999557522193758\n",
      "episode 206800: \t0.02226537211923983\t12.76\t0.09999557522193758\n",
      "episode 206900: \t0.02484235385769855\t12.61\t0.09999557522193758\n",
      "episode 207000: \t0.027944864781460108\t13.96\t0.09999557522193758\n",
      "episode 207100: \t0.0286076878088321\t16.24\t0.09999557522193758\n",
      "episode 207200: \t0.02715253601468878\t13.74\t0.09999557522193758\n",
      "episode 207300: \t0.026686101194065576\t11.9\t0.09999557522193758\n",
      "episode 207400: \t0.027045824999907868\t12.33\t0.09999557522193758\n",
      "episode 207500: \t0.026194669354511244\t14.12\t0.09999557522193758\n",
      "episode 207600: \t0.024824135825428976\t12.13\t0.09999557522193758\n",
      "episode 207700: \t0.03057960860366541\t12.89\t0.09999557522193758\n",
      "episode 207800: \t0.027707108136980074\t14.03\t0.09999557522193758\n",
      "episode 207900: \t0.025957847906383048\t11.43\t0.09999557522193758\n",
      "episode 208000: \t0.025101124587206522\t13.49\t0.09999557522193758\n",
      "episode 208100: \t0.028261785166553935\t13.63\t0.09999557522193758\n",
      "episode 208200: \t0.02300087107074335\t11.8\t0.09999557522193758\n",
      "episode 208300: \t0.025558164349341474\t13.98\t0.09999557522193758\n",
      "episode 208400: \t0.028094063005080428\t15.02\t0.09999557522193758\n",
      "episode 208500: \t0.027966020508502075\t13.46\t0.09999557522193758\n",
      "episode 208600: \t0.02814348531582115\t11.13\t0.09999557522193758\n",
      "episode 208700: \t0.0231130858180044\t12.73\t0.09999557522193758\n",
      "episode 208800: \t0.028341373326366347\t14.28\t0.09999557522193758\n",
      "episode 208900: \t0.027377814164721407\t10.68\t0.09999557522193758\n",
      "episode 209000: \t0.028263880640934345\t12.19\t0.09999557522193758\n",
      "episode 209100: \t0.025829730810845136\t13.74\t0.09999557522193758\n",
      "episode 209200: \t0.02724945472816493\t12.94\t0.09999557522193758\n",
      "episode 209300: \t0.02201785703492267\t12.99\t0.09999557522193758\n",
      "episode 209400: \t0.028801823692333653\t13.07\t0.09999557522193758\n",
      "episode 209500: \t0.030405091868662408\t13.07\t0.09999557522193758\n",
      "episode 209600: \t0.02775571148724236\t12.78\t0.09999557522193758\n",
      "episode 209700: \t0.022672330313283754\t10.72\t0.09999557522193758\n",
      "episode 209800: \t0.028395694747713036\t14.51\t0.09999557522193758\n",
      "episode 209900: \t0.0261535339531597\t12.81\t0.09999557522193758\n",
      "episode 210000: \t0.029216694625047765\t13.65\t0.09999557522193758\n",
      "#Average reward per episode 210000: 0.024282008112157635\n",
      "Saved Model\n",
      "#Intermediate time to execute: 2555.722387774785min\n",
      "episode 210100: \t0.029051356196439816\t16.29\t0.09999557522193758\n",
      "episode 210200: \t0.019402441633123928\t12.91\t0.09999557522193758\n",
      "episode 210300: \t0.031270612443087716\t14.83\t0.09999557522193758\n",
      "episode 210400: \t0.02407814804743694\t11.9\t0.09999557522193758\n",
      "episode 210500: \t0.023066520396519997\t13.73\t0.09999557522193758\n",
      "episode 210600: \t0.033465478378392415\t15.2\t0.09999557522193758\n",
      "episode 210700: \t0.027886132574091883\t12.69\t0.09999557522193758\n",
      "episode 210800: \t0.02552151650287144\t13.66\t0.09999557522193758\n",
      "episode 210900: \t0.028944341487020818\t15.07\t0.09999557522193758\n",
      "episode 211000: \t0.03286603614902086\t15.73\t0.09999557522193758\n",
      "episode 211100: \t0.020257473655078243\t14.91\t0.09999557522193758\n",
      "episode 211200: \t0.025930879996932304\t16.06\t0.09999557522193758\n",
      "episode 211300: \t0.023865047786705184\t15.77\t0.09999557522193758\n",
      "episode 211400: \t0.029213950464212574\t14.09\t0.09999557522193758\n",
      "episode 211500: \t0.025409808479573172\t11.97\t0.09999557522193758\n",
      "episode 211600: \t0.029690075864395683\t13.52\t0.09999557522193758\n",
      "episode 211700: \t0.026638049192815462\t13.31\t0.09999557522193758\n",
      "episode 211800: \t0.02336419799135409\t11.29\t0.09999557522193758\n",
      "episode 211900: \t0.02767012753968153\t13.35\t0.09999557522193758\n",
      "episode 212000: \t0.026833062582463464\t15.42\t0.09999557522193758\n",
      "episode 212100: \t0.032356338214307966\t16.36\t0.09999557522193758\n",
      "episode 212200: \t0.02370221544581413\t13.41\t0.09999557522193758\n",
      "episode 212300: \t0.021031952202417544\t14.9\t0.09999557522193758\n",
      "episode 212400: \t0.021059629662271998\t12.83\t0.09999557522193758\n",
      "episode 212500: \t0.0225007981880466\t13.01\t0.09999557522193758\n",
      "episode 212600: \t0.03638684704225865\t16.31\t0.09999557522193758\n",
      "episode 212700: \t0.02586491727907893\t14.38\t0.09999557522193758\n",
      "episode 212800: \t0.026355674240291192\t16.2\t0.09999557522193758\n",
      "episode 212900: \t0.02652583384570422\t14.76\t0.09999557522193758\n",
      "episode 213000: \t0.025188880723414533\t16.92\t0.09999557522193758\n",
      "episode 213100: \t0.03236285911799363\t17.09\t0.09999557522193758\n",
      "episode 213200: \t0.02342723896403248\t16.21\t0.09999557522193758\n",
      "episode 213300: \t0.02606842020858836\t15.4\t0.09999557522193758\n",
      "episode 213400: \t0.03422760015938089\t18.52\t0.09999557522193758\n",
      "episode 213500: \t0.024385698812698614\t16.65\t0.09999557522193758\n",
      "episode 213600: \t0.028898320360396988\t15.73\t0.09999557522193758\n",
      "episode 213700: \t0.027763791566023936\t15.11\t0.09999557522193758\n",
      "episode 213800: \t0.027327870222386776\t15.31\t0.09999557522193758\n",
      "episode 213900: \t0.024896659003946595\t15.32\t0.09999557522193758\n",
      "episode 214000: \t0.031000632165004673\t14.29\t0.09999557522193758\n",
      "episode 214100: \t0.034525964685915705\t15.96\t0.09999557522193758\n",
      "episode 214200: \t0.023163951027206413\t14.13\t0.09999557522193758\n",
      "episode 214300: \t0.03227128377230235\t17.75\t0.09999557522193758\n",
      "episode 214400: \t0.025625442723779555\t15.63\t0.09999557522193758\n",
      "episode 214500: \t0.027089173131176578\t16.35\t0.09999557522193758\n",
      "episode 214600: \t0.02825873601963893\t16.49\t0.09999557522193758\n",
      "episode 214700: \t0.026519648193333037\t13.82\t0.09999557522193758\n",
      "episode 214800: \t0.03270874809778019\t16.7\t0.09999557522193758\n",
      "episode 214900: \t0.021926171865263477\t13.7\t0.09999557522193758\n",
      "episode 215000: \t0.02364118524905669\t15.21\t0.09999557522193758\n",
      "#Average reward per episode 215000: 0.024345909197712543\n",
      "episode 215100: \t0.029507432523819023\t16.87\t0.09999557522193758\n",
      "episode 215200: \t0.02523132432200616\t15.43\t0.09999557522193758\n",
      "episode 215300: \t0.029308312654490118\t17.78\t0.09999557522193758\n",
      "episode 215400: \t0.023128776059003178\t15.96\t0.09999557522193758\n",
      "episode 215500: \t0.02257071758103474\t15.53\t0.09999557522193758\n",
      "episode 215600: \t0.028273302168434572\t15.2\t0.09999557522193758\n",
      "episode 215700: \t0.024395710537238425\t16.59\t0.09999557522193758\n",
      "episode 215800: \t0.027139162519781386\t17.39\t0.09999557522193758\n",
      "episode 215900: \t0.028141548997329503\t15.46\t0.09999557522193758\n",
      "episode 216000: \t0.022596629815833203\t14.8\t0.09999557522193758\n",
      "episode 216100: \t0.027505582422560234\t18.24\t0.09999557522193758\n",
      "episode 216200: \t0.030341026339586318\t17.64\t0.09999557522193758\n",
      "episode 216300: \t0.01918432668272933\t13.02\t0.09999557522193758\n",
      "episode 216400: \t0.02601249234414525\t14.97\t0.09999557522193758\n",
      "episode 216500: \t0.02848141137440141\t17.61\t0.09999557522193758\n",
      "episode 216600: \t0.02348567679544678\t15.51\t0.09999557522193758\n",
      "episode 216700: \t0.024598223545769012\t17.23\t0.09999557522193758\n",
      "episode 216800: \t0.027737744887937184\t15.1\t0.09999557522193758\n",
      "episode 216900: \t0.024782016824331576\t13.46\t0.09999557522193758\n",
      "episode 217000: \t0.02874442656359915\t16.76\t0.09999557522193758\n",
      "episode 217100: \t0.02890570899142053\t16.82\t0.09999557522193758\n",
      "episode 217200: \t0.022829444845654377\t13.92\t0.09999557522193758\n",
      "episode 217300: \t0.0277616402644587\t17.24\t0.09999557522193758\n",
      "episode 217400: \t0.02662849347668093\t17.66\t0.09999557522193758\n",
      "episode 217500: \t0.02613254592205159\t15.8\t0.09999557522193758\n",
      "episode 217600: \t0.023504457640590695\t14.11\t0.09999557522193758\n",
      "episode 217700: \t0.02437835360031292\t14.3\t0.09999557522193758\n",
      "episode 217800: \t0.027675113313926504\t16.52\t0.09999557522193758\n",
      "episode 217900: \t0.028918490064419055\t13.99\t0.09999557522193758\n",
      "episode 218000: \t0.031241294386241934\t17.4\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 218100: \t0.024647746796693727\t12.87\t0.09999557522193758\n",
      "episode 218200: \t0.02556653316463748\t14.49\t0.09999557522193758\n",
      "episode 218300: \t0.023395851082926168\t15.23\t0.09999557522193758\n",
      "episode 218400: \t0.024585004156733824\t13.17\t0.09999557522193758\n",
      "episode 218500: \t0.02660694587613295\t15.08\t0.09999557522193758\n",
      "episode 218600: \t0.022787430809973145\t13.95\t0.09999557522193758\n",
      "episode 218700: \t0.025057460898906522\t14.5\t0.09999557522193758\n",
      "episode 218800: \t0.020608830156490125\t14.85\t0.09999557522193758\n",
      "episode 218900: \t0.02283918709757258\t15.22\t0.09999557522193758\n",
      "episode 219000: \t0.025740308803619695\t15.3\t0.09999557522193758\n",
      "episode 219100: \t0.025660315156204164\t13.45\t0.09999557522193758\n",
      "episode 219200: \t0.02696325645568665\t14.0\t0.09999557522193758\n",
      "episode 219300: \t0.033988622398429015\t15.28\t0.09999557522193758\n",
      "episode 219400: \t0.026372629435526568\t16.02\t0.09999557522193758\n",
      "episode 219500: \t0.023574848060010773\t14.2\t0.09999557522193758\n",
      "episode 219600: \t0.0246709437980853\t13.18\t0.09999557522193758\n",
      "episode 219700: \t0.022250418590105556\t13.99\t0.09999557522193758\n",
      "episode 219800: \t0.02565089750977538\t12.54\t0.09999557522193758\n",
      "episode 219900: \t0.024179881519605827\t14.39\t0.09999557522193758\n",
      "episode 220000: \t0.029264475165040715\t13.51\t0.09999557522193758\n",
      "#Average reward per episode 220000: 0.02438057170430879\n",
      "Saved Model\n",
      "#Intermediate time to execute: 2686.87763603131min\n",
      "episode 220100: \t0.02623240844952449\t13.51\t0.09999557522193758\n",
      "episode 220200: \t0.02979158151149093\t14.3\t0.09999557522193758\n",
      "episode 220300: \t0.024472374312247632\t13.44\t0.09999557522193758\n",
      "episode 220400: \t0.02708757394721616\t11.99\t0.09999557522193758\n",
      "episode 220500: \t0.026620495687361464\t13.06\t0.09999557522193758\n",
      "episode 220600: \t0.028747208722870937\t14.25\t0.09999557522193758\n",
      "episode 220700: \t0.021172312252995037\t13.2\t0.09999557522193758\n",
      "episode 220800: \t0.02333513527868631\t14.46\t0.09999557522193758\n",
      "episode 220900: \t0.030486574895683766\t15.08\t0.09999557522193758\n",
      "episode 221000: \t0.028699633664265818\t14.97\t0.09999557522193758\n",
      "episode 221100: \t0.027896480126839655\t13.76\t0.09999557522193758\n",
      "episode 221200: \t0.02286553707361819\t12.47\t0.09999557522193758\n",
      "episode 221300: \t0.024948013073533174\t14.32\t0.09999557522193758\n",
      "episode 221400: \t0.021282733177413315\t12.9\t0.09999557522193758\n",
      "episode 221500: \t0.0196423830699341\t11.64\t0.09999557522193758\n",
      "episode 221600: \t0.02675192650851607\t13.2\t0.09999557522193758\n",
      "episode 221700: \t0.025248144249566683\t14.21\t0.09999557522193758\n",
      "episode 221800: \t0.024997251860988362\t14.59\t0.09999557522193758\n",
      "episode 221900: \t0.028974360251098605\t12.9\t0.09999557522193758\n",
      "episode 222000: \t0.027830496002047185\t15.68\t0.09999557522193758\n",
      "episode 222100: \t0.028406322484940284\t14.71\t0.09999557522193758\n",
      "episode 222200: \t0.019963296210847283\t11.96\t0.09999557522193758\n",
      "episode 222300: \t0.0266066790672723\t12.39\t0.09999557522193758\n",
      "episode 222400: \t0.022995710030972276\t15.07\t0.09999557522193758\n",
      "episode 222500: \t0.022729362389415093\t12.58\t0.09999557522193758\n",
      "episode 222600: \t0.026814827093815153\t13.62\t0.09999557522193758\n",
      "episode 222700: \t0.022674069973721424\t14.29\t0.09999557522193758\n",
      "episode 222800: \t0.0316241791463104\t17.53\t0.09999557522193758\n",
      "episode 222900: \t0.028464575166713746\t15.53\t0.09999557522193758\n",
      "episode 223000: \t0.026487844313661486\t17.46\t0.09999557522193758\n",
      "episode 223100: \t0.024708848264252934\t14.26\t0.09999557522193758\n",
      "episode 223200: \t0.027714216010202682\t14.03\t0.09999557522193758\n",
      "episode 223300: \t0.0279560758475112\t14.56\t0.09999557522193758\n",
      "episode 223400: \t0.027465153832453876\t13.68\t0.09999557522193758\n",
      "episode 223500: \t0.030079454991482547\t14.54\t0.09999557522193758\n",
      "episode 223600: \t0.02518398112995872\t15.2\t0.09999557522193758\n",
      "episode 223700: \t0.02342049851301969\t11.74\t0.09999557522193758\n",
      "episode 223800: \t0.023389886978840483\t14.35\t0.09999557522193758\n",
      "episode 223900: \t0.02530819235862665\t11.14\t0.09999557522193758\n",
      "episode 224000: \t0.0256337917675903\t13.48\t0.09999557522193758\n",
      "episode 224100: \t0.026298662658157758\t14.28\t0.09999557522193758\n",
      "episode 224200: \t0.02163471609380785\t11.73\t0.09999557522193758\n",
      "episode 224300: \t0.030109057449653136\t17.15\t0.09999557522193758\n",
      "episode 224400: \t0.02543614114486603\t15.46\t0.09999557522193758\n",
      "episode 224500: \t0.029432235371190215\t16.51\t0.09999557522193758\n",
      "episode 224600: \t0.024524919794418006\t15.08\t0.09999557522193758\n",
      "episode 224700: \t0.026116969365526002\t15.36\t0.09999557522193758\n",
      "episode 224800: \t0.02735494460730501\t16.16\t0.09999557522193758\n",
      "episode 224900: \t0.03410603404961619\t18.68\t0.09999557522193758\n",
      "episode 225000: \t0.02525937167193797\t13.04\t0.09999557522193758\n",
      "#Average reward per episode 225000: 0.024418773507277038\n",
      "episode 225100: \t0.026319288355992922\t14.69\t0.09999557522193758\n",
      "episode 225200: \t0.02913988104357852\t15.07\t0.09999557522193758\n",
      "episode 225300: \t0.03123233179204051\t16.15\t0.09999557522193758\n",
      "episode 225400: \t0.02484162610769108\t14.52\t0.09999557522193758\n",
      "episode 225500: \t0.028903810863063154\t16.44\t0.09999557522193758\n",
      "episode 225600: \t0.02631166112126246\t12.6\t0.09999557522193758\n",
      "episode 225700: \t0.02346852199964089\t15.26\t0.09999557522193758\n",
      "episode 225800: \t0.0249989459449675\t15.49\t0.09999557522193758\n",
      "episode 225900: \t0.02361018687117225\t12.62\t0.09999557522193758\n",
      "episode 226000: \t0.023543835144765747\t12.93\t0.09999557522193758\n",
      "episode 226100: \t0.026606069463794676\t13.41\t0.09999557522193758\n",
      "episode 226200: \t0.023893356900579955\t15.22\t0.09999557522193758\n",
      "episode 226300: \t0.023084777814978318\t13.98\t0.09999557522193758\n",
      "episode 226400: \t0.026290049258761616\t14.31\t0.09999557522193758\n",
      "episode 226500: \t0.025199779132284116\t13.51\t0.09999557522193758\n",
      "episode 226600: \t0.024009916169255435\t14.13\t0.09999557522193758\n",
      "episode 226700: \t0.020784700549578487\t12.43\t0.09999557522193758\n",
      "episode 226800: \t0.02522810635223586\t13.68\t0.09999557522193758\n",
      "episode 226900: \t0.026167853353241562\t13.85\t0.09999557522193758\n",
      "episode 227000: \t0.024566807271595614\t13.99\t0.09999557522193758\n",
      "episode 227100: \t0.03285079816676491\t17.47\t0.09999557522193758\n",
      "episode 227200: \t0.028942017401331004\t14.15\t0.09999557522193758\n",
      "episode 227300: \t0.02404432726508843\t15.35\t0.09999557522193758\n",
      "episode 227400: \t0.0278440897249986\t13.15\t0.09999557522193758\n",
      "episode 227500: \t0.020768605625214008\t11.3\t0.09999557522193758\n",
      "episode 227600: \t0.02419760113047326\t13.89\t0.09999557522193758\n",
      "episode 227700: \t0.02559408095818773\t13.31\t0.09999557522193758\n",
      "episode 227800: \t0.026506833739610807\t14.6\t0.09999557522193758\n",
      "episode 227900: \t0.02596651209956509\t14.04\t0.09999557522193758\n",
      "episode 228000: \t0.02547811354385505\t14.52\t0.09999557522193758\n",
      "episode 228100: \t0.02321985174810121\t10.91\t0.09999557522193758\n",
      "episode 228200: \t0.02674552250560851\t13.28\t0.09999557522193758\n",
      "episode 228300: \t0.022530575720576235\t12.45\t0.09999557522193758\n",
      "episode 228400: \t0.02672163423131608\t14.46\t0.09999557522193758\n",
      "episode 228500: \t0.0288151400517078\t16.03\t0.09999557522193758\n",
      "episode 228600: \t0.031753271914540436\t13.3\t0.09999557522193758\n",
      "episode 228700: \t0.020874395837824675\t13.42\t0.09999557522193758\n",
      "episode 228800: \t0.03245429628482212\t16.91\t0.09999557522193758\n",
      "episode 228900: \t0.023513004596605245\t14.99\t0.09999557522193758\n",
      "episode 229000: \t0.021668229397085986\t12.55\t0.09999557522193758\n",
      "episode 229100: \t0.024626052263828083\t12.68\t0.09999557522193758\n",
      "episode 229200: \t0.02195584194211803\t12.74\t0.09999557522193758\n",
      "episode 229300: \t0.02803086551609328\t13.25\t0.09999557522193758\n",
      "episode 229400: \t0.03216167142268494\t14.61\t0.09999557522193758\n",
      "episode 229500: \t0.024010605752759383\t14.41\t0.09999557522193758\n",
      "episode 229600: \t0.02672161374334903\t13.9\t0.09999557522193758\n",
      "episode 229700: \t0.02148091879177572\t12.83\t0.09999557522193758\n",
      "episode 229800: \t0.02474096641815593\t14.77\t0.09999557522193758\n",
      "episode 229900: \t0.026461492852744413\t13.32\t0.09999557522193758\n",
      "episode 230000: \t0.021075048275908115\t11.92\t0.09999557522193758\n",
      "#Average reward per episode 230000: 0.024444432989481107\n",
      "Saved Model\n",
      "#Intermediate time to execute: 2817.3553860902784min\n",
      "episode 230100: \t0.024863837714325127\t14.21\t0.09999557522193758\n",
      "episode 230200: \t0.024979433889883693\t14.76\t0.09999557522193758\n",
      "episode 230300: \t0.02802659869895722\t15.07\t0.09999557522193758\n",
      "episode 230400: \t0.02625297832199243\t12.02\t0.09999557522193758\n",
      "episode 230500: \t0.022423149448868\t13.35\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 230600: \t0.024588280557593666\t12.91\t0.09999557522193758\n",
      "episode 230700: \t0.020690191595184003\t15.41\t0.09999557522193758\n",
      "episode 230800: \t0.02500115153092633\t13.85\t0.09999557522193758\n",
      "episode 230900: \t0.024396802941631178\t12.47\t0.09999557522193758\n",
      "episode 231000: \t0.027178773028350506\t13.14\t0.09999557522193758\n",
      "episode 231100: \t0.030789343018661354\t13.45\t0.09999557522193758\n",
      "episode 231200: \t0.025553737379798463\t11.94\t0.09999557522193758\n",
      "episode 231300: \t0.02009890263365494\t12.53\t0.09999557522193758\n",
      "episode 231400: \t0.024001134576174386\t12.51\t0.09999557522193758\n",
      "episode 231500: \t0.025396088810800674\t14.71\t0.09999557522193758\n",
      "episode 231600: \t0.031383926582778734\t16.34\t0.09999557522193758\n",
      "episode 231700: \t0.027300801349134908\t13.37\t0.09999557522193758\n",
      "episode 231800: \t0.029521905590320117\t16.42\t0.09999557522193758\n",
      "episode 231900: \t0.028490796736653095\t13.04\t0.09999557522193758\n",
      "episode 232000: \t0.02153392537559061\t13.07\t0.09999557522193758\n",
      "episode 232100: \t0.02938420861179885\t14.15\t0.09999557522193758\n",
      "episode 232200: \t0.0290015660645621\t15.29\t0.09999557522193758\n",
      "episode 232300: \t0.02262728387981607\t13.33\t0.09999557522193758\n",
      "episode 232400: \t0.019315145713326366\t12.44\t0.09999557522193758\n",
      "episode 232500: \t0.020291069712632562\t11.74\t0.09999557522193758\n",
      "episode 232600: \t0.024651719235559772\t10.84\t0.09999557522193758\n",
      "episode 232700: \t0.029120665749410125\t14.51\t0.09999557522193758\n",
      "episode 232800: \t0.02714237075858788\t13.38\t0.09999557522193758\n",
      "episode 232900: \t0.029663630536907015\t15.17\t0.09999557522193758\n",
      "episode 233000: \t0.02632507403626275\t12.63\t0.09999557522193758\n",
      "episode 233100: \t0.02355930751806281\t13.24\t0.09999557522193758\n",
      "episode 233200: \t0.028209256970058157\t16.96\t0.09999557522193758\n",
      "episode 233300: \t0.02552642710160212\t13.57\t0.09999557522193758\n",
      "episode 233400: \t0.02835343654805617\t15.14\t0.09999557522193758\n",
      "episode 233500: \t0.027400919064153557\t14.47\t0.09999557522193758\n",
      "episode 233600: \t0.026718776913086065\t15.49\t0.09999557522193758\n",
      "episode 233700: \t0.0329939068196714\t14.56\t0.09999557522193758\n",
      "episode 233800: \t0.026688757192266953\t13.8\t0.09999557522193758\n",
      "episode 233900: \t0.026293876199429612\t11.69\t0.09999557522193758\n",
      "episode 234000: \t0.029924840289832576\t13.81\t0.09999557522193758\n",
      "episode 234100: \t0.026268634263499645\t13.2\t0.09999557522193758\n",
      "episode 234200: \t0.024221833771288264\t13.07\t0.09999557522193758\n",
      "episode 234300: \t0.023769666953476848\t13.78\t0.09999557522193758\n",
      "episode 234400: \t0.025021395384832314\t16.23\t0.09999557522193758\n",
      "episode 234500: \t0.030152065075788395\t14.29\t0.09999557522193758\n",
      "episode 234600: \t0.028482644228849337\t14.95\t0.09999557522193758\n",
      "episode 234700: \t0.023898667246220025\t12.57\t0.09999557522193758\n",
      "episode 234800: \t0.02904265457031132\t14.34\t0.09999557522193758\n",
      "episode 234900: \t0.024939220943396335\t13.27\t0.09999557522193758\n",
      "episode 235000: \t0.02713998642967476\t12.6\t0.09999557522193758\n",
      "#Average reward per episode 235000: 0.024481190061008632\n",
      "episode 235100: \t0.026293979085151752\t14.77\t0.09999557522193758\n",
      "episode 235200: \t0.02302462023085558\t12.18\t0.09999557522193758\n",
      "episode 235300: \t0.022810180429253292\t12.4\t0.09999557522193758\n",
      "episode 235400: \t0.024392641438055335\t12.99\t0.09999557522193758\n",
      "episode 235500: \t0.024014200098487076\t14.99\t0.09999557522193758\n",
      "episode 235600: \t0.024390966599641805\t13.73\t0.09999557522193758\n",
      "episode 235700: \t0.02635492385943402\t12.46\t0.09999557522193758\n",
      "episode 235800: \t0.02800226002629883\t13.7\t0.09999557522193758\n",
      "episode 235900: \t0.026728883173348063\t15.54\t0.09999557522193758\n",
      "episode 236000: \t0.0252176989138564\t14.1\t0.09999557522193758\n",
      "episode 236100: \t0.018541841933205044\t11.69\t0.09999557522193758\n",
      "episode 236200: \t0.023004230127237676\t14.32\t0.09999557522193758\n",
      "episode 236300: \t0.02888497052925893\t16.11\t0.09999557522193758\n",
      "episode 236400: \t0.020629042580618488\t11.02\t0.09999557522193758\n",
      "episode 236500: \t0.022733962339898727\t13.45\t0.09999557522193758\n",
      "episode 236600: \t0.026285507620540507\t12.47\t0.09999557522193758\n",
      "episode 236700: \t0.03120204450392968\t16.46\t0.09999557522193758\n",
      "episode 236800: \t0.020472355126922276\t13.02\t0.09999557522193758\n",
      "episode 236900: \t0.025082964587539683\t12.12\t0.09999557522193758\n",
      "episode 237000: \t0.028026225592646704\t13.74\t0.09999557522193758\n",
      "episode 237100: \t0.03098877226210381\t15.23\t0.09999557522193758\n",
      "episode 237200: \t0.026606209780794712\t15.26\t0.09999557522193758\n",
      "episode 237300: \t0.023758057464730264\t13.32\t0.09999557522193758\n",
      "episode 237400: \t0.019293857380479257\t14.16\t0.09999557522193758\n",
      "episode 237500: \t0.025093253621735142\t13.13\t0.09999557522193758\n",
      "episode 237600: \t0.026811352634804428\t14.77\t0.09999557522193758\n",
      "episode 237700: \t0.025246598352843673\t15.53\t0.09999557522193758\n",
      "episode 237800: \t0.02512659767051993\t12.54\t0.09999557522193758\n",
      "episode 237900: \t0.029234926170110354\t15.51\t0.09999557522193758\n",
      "episode 238000: \t0.028130939404077487\t14.31\t0.09999557522193758\n",
      "episode 238100: \t0.021289328923704467\t10.73\t0.09999557522193758\n",
      "episode 238200: \t0.023562192303901077\t13.39\t0.09999557522193758\n",
      "episode 238300: \t0.02679429045592777\t13.25\t0.09999557522193758\n",
      "episode 238400: \t0.025674100966529015\t14.07\t0.09999557522193758\n",
      "episode 238500: \t0.027244684194407523\t13.86\t0.09999557522193758\n",
      "episode 238600: \t0.03274880608005909\t16.13\t0.09999557522193758\n",
      "episode 238700: \t0.029434911809240506\t16.52\t0.09999557522193758\n",
      "episode 238800: \t0.021466208362526742\t13.17\t0.09999557522193758\n",
      "episode 238900: \t0.025156153499209237\t12.19\t0.09999557522193758\n",
      "episode 239000: \t0.029918224832002464\t14.17\t0.09999557522193758\n",
      "episode 239100: \t0.028086618335217414\t14.69\t0.09999557522193758\n",
      "episode 239200: \t0.024184748509558086\t12.5\t0.09999557522193758\n",
      "episode 239300: \t0.02710485683603903\t14.26\t0.09999557522193758\n",
      "episode 239400: \t0.02651424266706597\t14.34\t0.09999557522193758\n",
      "episode 239500: \t0.02358610144380846\t11.91\t0.09999557522193758\n",
      "episode 239600: \t0.027105128187748236\t14.91\t0.09999557522193758\n",
      "episode 239700: \t0.02642104797425753\t13.02\t0.09999557522193758\n",
      "episode 239800: \t0.02840288478557505\t12.76\t0.09999557522193758\n",
      "episode 239900: \t0.028585554223387665\t13.22\t0.09999557522193758\n",
      "episode 240000: \t0.021972919752921177\t12.09\t0.09999557522193758\n",
      "#Average reward per episode 240000: 0.024505180712938203\n",
      "Saved Model\n",
      "#Intermediate time to execute: 2946.702307709058min\n",
      "episode 240100: \t0.036546614534564606\t15.35\t0.09999557522193758\n",
      "episode 240200: \t0.02929788891428972\t15.37\t0.09999557522193758\n",
      "episode 240300: \t0.028237201868831177\t12.68\t0.09999557522193758\n",
      "episode 240400: \t0.023364465196770635\t11.81\t0.09999557522193758\n",
      "episode 240500: \t0.027388433115022925\t13.26\t0.09999557522193758\n",
      "episode 240600: \t0.026853746740318547\t13.07\t0.09999557522193758\n",
      "episode 240700: \t0.022895064888286278\t10.69\t0.09999557522193758\n",
      "episode 240800: \t0.027634295317549316\t12.44\t0.09999557522193758\n",
      "episode 240900: \t0.024472024208760643\t13.84\t0.09999557522193758\n",
      "episode 241000: \t0.025148921966968402\t13.97\t0.09999557522193758\n",
      "episode 241100: \t0.018877675411785054\t9.66\t0.09999557522193758\n",
      "episode 241200: \t0.02967286448564783\t13.94\t0.09999557522193758\n",
      "episode 241300: \t0.021924927869877032\t13.37\t0.09999557522193758\n",
      "episode 241400: \t0.027251901314053296\t13.38\t0.09999557522193758\n",
      "episode 241500: \t0.02076673285563378\t10.3\t0.09999557522193758\n",
      "episode 241600: \t0.026460801663403984\t13.01\t0.09999557522193758\n",
      "episode 241700: \t0.027138713409245185\t12.63\t0.09999557522193758\n",
      "episode 241800: \t0.02789458966391339\t12.42\t0.09999557522193758\n",
      "episode 241900: \t0.024961740160908727\t14.09\t0.09999557522193758\n",
      "episode 242000: \t0.028110942223134282\t13.8\t0.09999557522193758\n",
      "episode 242100: \t0.03284511458218753\t15.56\t0.09999557522193758\n",
      "episode 242200: \t0.01972903062117076\t12.59\t0.09999557522193758\n",
      "episode 242300: \t0.020488237733078115\t11.51\t0.09999557522193758\n",
      "episode 242400: \t0.02688935271814792\t14.19\t0.09999557522193758\n",
      "episode 242500: \t0.022007388514878365\t12.6\t0.09999557522193758\n",
      "episode 242600: \t0.027549035756847216\t14.83\t0.09999557522193758\n",
      "episode 242700: \t0.03257449136055952\t13.12\t0.09999557522193758\n",
      "episode 242800: \t0.026487896401588124\t13.25\t0.09999557522193758\n",
      "episode 242900: \t0.024155501729166917\t14.51\t0.09999557522193758\n",
      "episode 243000: \t0.027374238143209943\t13.03\t0.09999557522193758\n",
      "episode 243100: \t0.023543598917399006\t12.11\t0.09999557522193758\n",
      "episode 243200: \t0.030134022669049566\t15.32\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 243300: \t0.02217764640383013\t11.06\t0.09999557522193758\n",
      "episode 243400: \t0.025810579559442687\t13.08\t0.09999557522193758\n",
      "episode 243500: \t0.026419485846509227\t12.43\t0.09999557522193758\n",
      "episode 243600: \t0.027369002146087444\t14.52\t0.09999557522193758\n",
      "episode 243700: \t0.026535221721458765\t13.58\t0.09999557522193758\n",
      "episode 243800: \t0.028346384905164633\t15.95\t0.09999557522193758\n",
      "episode 243900: \t0.02581255994113983\t13.09\t0.09999557522193758\n",
      "episode 244000: \t0.021874185030819563\t13.58\t0.09999557522193758\n",
      "episode 244100: \t0.02771062759939463\t11.77\t0.09999557522193758\n",
      "episode 244200: \t0.023998228313482434\t12.42\t0.09999557522193758\n",
      "episode 244300: \t0.03147077816384372\t14.46\t0.09999557522193758\n",
      "episode 244400: \t0.025976289681489618\t12.41\t0.09999557522193758\n",
      "episode 244500: \t0.028937886296203086\t15.82\t0.09999557522193758\n",
      "episode 244600: \t0.027302526600116814\t14.12\t0.09999557522193758\n",
      "episode 244700: \t0.028879460624071682\t12.9\t0.09999557522193758\n",
      "episode 244800: \t0.029419614623277725\t14.34\t0.09999557522193758\n",
      "episode 244900: \t0.026948865471997863\t13.21\t0.09999557522193758\n",
      "episode 245000: \t0.028061812162856237\t13.33\t0.09999557522193758\n",
      "#Average reward per episode 245000: 0.024544556049428283\n",
      "episode 245100: \t0.026576517827230507\t15.02\t0.09999557522193758\n",
      "episode 245200: \t0.02909277180761833\t14.62\t0.09999557522193758\n",
      "episode 245300: \t0.02201465109350184\t14.24\t0.09999557522193758\n",
      "episode 245400: \t0.02520798092001979\t13.05\t0.09999557522193758\n",
      "episode 245500: \t0.025222750334985267\t13.58\t0.09999557522193758\n",
      "episode 245600: \t0.029702325502219164\t14.88\t0.09999557522193758\n",
      "episode 245700: \t0.022756245160374243\t11.95\t0.09999557522193758\n",
      "episode 245800: \t0.023644081649391278\t14.26\t0.09999557522193758\n",
      "episode 245900: \t0.025138098150483634\t12.46\t0.09999557522193758\n",
      "episode 246000: \t0.028074214691334972\t15.35\t0.09999557522193758\n",
      "episode 246100: \t0.027391979891784476\t13.19\t0.09999557522193758\n",
      "episode 246200: \t0.031167961383973725\t14.7\t0.09999557522193758\n",
      "episode 246300: \t0.03028459319029091\t15.17\t0.09999557522193758\n",
      "episode 246400: \t0.025019588352788825\t13.03\t0.09999557522193758\n",
      "episode 246500: \t0.024793406483328933\t13.98\t0.09999557522193758\n",
      "episode 246600: \t0.03100571544120588\t15.99\t0.09999557522193758\n",
      "episode 246700: \t0.03145526789024114\t15.35\t0.09999557522193758\n",
      "episode 246800: \t0.020400318251672555\t13.98\t0.09999557522193758\n",
      "episode 246900: \t0.031849513615170834\t13.56\t0.09999557522193758\n",
      "episode 247000: \t0.02925014933645323\t14.47\t0.09999557522193758\n",
      "episode 247100: \t0.02856770651599576\t14.3\t0.09999557522193758\n",
      "episode 247200: \t0.02547948026093583\t15.13\t0.09999557522193758\n",
      "episode 247300: \t0.02786199873552786\t13.45\t0.09999557522193758\n",
      "episode 247400: \t0.02585922612418458\t14.78\t0.09999557522193758\n",
      "episode 247500: \t0.023560423978775183\t14.42\t0.09999557522193758\n",
      "episode 247600: \t0.021708139411927226\t13.43\t0.09999557522193758\n",
      "episode 247700: \t0.02142439808636708\t13.5\t0.09999557522193758\n",
      "episode 247800: \t0.030224863654985886\t15.12\t0.09999557522193758\n",
      "episode 247900: \t0.03257565108907427\t14.94\t0.09999557522193758\n",
      "episode 248000: \t0.03178728458025587\t16.26\t0.09999557522193758\n",
      "episode 248100: \t0.02657663060167288\t13.87\t0.09999557522193758\n",
      "episode 248200: \t0.027147531056929776\t14.76\t0.09999557522193758\n",
      "episode 248300: \t0.025116610610947658\t14.7\t0.09999557522193758\n",
      "episode 248400: \t0.025574902681183887\t16.32\t0.09999557522193758\n",
      "episode 248500: \t0.027824259081858798\t16.0\t0.09999557522193758\n",
      "episode 248600: \t0.02827836854674707\t15.45\t0.09999557522193758\n",
      "episode 248700: \t0.02817440858690317\t16.19\t0.09999557522193758\n",
      "episode 248800: \t0.027267685415834134\t17.5\t0.09999557522193758\n",
      "episode 248900: \t0.024190385669241973\t16.17\t0.09999557522193758\n",
      "episode 249000: \t0.026853389320727495\t14.63\t0.09999557522193758\n",
      "episode 249100: \t0.021001814562735296\t13.17\t0.09999557522193758\n",
      "episode 249200: \t0.024974066705349206\t12.99\t0.09999557522193758\n",
      "episode 249300: \t0.025317278034139853\t14.11\t0.09999557522193758\n",
      "episode 249400: \t0.01850024202262126\t11.32\t0.09999557522193758\n",
      "episode 249500: \t0.02348120877863193\t13.94\t0.09999557522193758\n",
      "episode 249600: \t0.031333256322751\t19.94\t0.09999557522193758\n",
      "episode 249700: \t0.027000843812705167\t15.14\t0.09999557522193758\n",
      "episode 249800: \t0.022063169388332082\t13.41\t0.09999557522193758\n",
      "episode 249900: \t0.0250774843310893\t14.46\t0.09999557522193758\n",
      "episode 250000: \t0.02433748156588655\t14.65\t0.09999557522193758\n",
      "#Average reward per episode 250000: 0.024581340256643113\n",
      "Saved Model\n",
      "#Intermediate time to execute: 3076.1193554759025min\n",
      "episode 250100: \t0.02339030984597583\t13.43\t0.09999557522193758\n",
      "episode 250200: \t0.02549364141914055\t13.65\t0.09999557522193758\n",
      "episode 250300: \t0.03225592028425856\t16.3\t0.09999557522193758\n",
      "episode 250400: \t0.02353681392382665\t13.47\t0.09999557522193758\n",
      "episode 250500: \t0.01766044925697793\t10.57\t0.09999557522193758\n",
      "episode 250600: \t0.02683282017167597\t13.71\t0.09999557522193758\n",
      "episode 250700: \t0.030232214384161127\t17.39\t0.09999557522193758\n",
      "episode 250800: \t0.023566986923395247\t16.14\t0.09999557522193758\n",
      "episode 250900: \t0.02381599885048172\t12.16\t0.09999557522193758\n",
      "episode 251000: \t0.02456371158623175\t13.37\t0.09999557522193758\n",
      "episode 251100: \t0.03047139125571906\t14.63\t0.09999557522193758\n",
      "episode 251200: \t0.022672657446166835\t12.24\t0.09999557522193758\n",
      "episode 251300: \t0.024529892338011644\t13.74\t0.09999557522193758\n",
      "episode 251400: \t0.026267822761230034\t15.08\t0.09999557522193758\n",
      "episode 251500: \t0.026354081279193347\t16.51\t0.09999557522193758\n",
      "episode 251600: \t0.024768273421410664\t13.74\t0.09999557522193758\n",
      "episode 251700: \t0.024120123166726265\t13.8\t0.09999557522193758\n",
      "episode 251800: \t0.02873061167979899\t15.37\t0.09999557522193758\n",
      "episode 251900: \t0.024073407286955187\t14.73\t0.09999557522193758\n",
      "episode 252000: \t0.02431945946805193\t14.54\t0.09999557522193758\n",
      "episode 252100: \t0.026997146049160318\t13.59\t0.09999557522193758\n",
      "episode 252200: \t0.02657159477727404\t14.64\t0.09999557522193758\n",
      "episode 252300: \t0.02751397341190458\t15.5\t0.09999557522193758\n",
      "episode 252400: \t0.026002816897380363\t13.88\t0.09999557522193758\n",
      "episode 252500: \t0.024437533585611584\t14.38\t0.09999557522193758\n",
      "episode 252600: \t0.026880788714343618\t13.95\t0.09999557522193758\n",
      "episode 252700: \t0.0224855551369091\t12.15\t0.09999557522193758\n",
      "episode 252800: \t0.02350103704117208\t12.45\t0.09999557522193758\n",
      "episode 252900: \t0.028263024160684953\t11.97\t0.09999557522193758\n",
      "episode 253000: \t0.02204591752423555\t14.02\t0.09999557522193758\n",
      "episode 253100: \t0.027693241543007972\t15.72\t0.09999557522193758\n",
      "episode 253200: \t0.029899829126802415\t15.66\t0.09999557522193758\n",
      "episode 253300: \t0.024914464399277164\t13.59\t0.09999557522193758\n",
      "episode 253400: \t0.0265989926688671\t17.12\t0.09999557522193758\n",
      "episode 253500: \t0.025136153452592867\t13.17\t0.09999557522193758\n",
      "episode 253600: \t0.02560823607981647\t14.76\t0.09999557522193758\n",
      "episode 253700: \t0.0265588345565814\t13.14\t0.09999557522193758\n",
      "episode 253800: \t0.02744758874176766\t14.91\t0.09999557522193758\n",
      "episode 253900: \t0.027254829511948103\t17.99\t0.09999557522193758\n",
      "episode 254000: \t0.026177388766892067\t15.69\t0.09999557522193758\n",
      "episode 254100: \t0.028498806578964163\t15.3\t0.09999557522193758\n",
      "episode 254200: \t0.02884809597984718\t16.0\t0.09999557522193758\n",
      "episode 254300: \t0.02361205197335935\t14.09\t0.09999557522193758\n",
      "episode 254400: \t0.022635021918395906\t13.92\t0.09999557522193758\n",
      "episode 254500: \t0.02553744121035259\t13.58\t0.09999557522193758\n",
      "episode 254600: \t0.021609773291669573\t14.26\t0.09999557522193758\n",
      "episode 254700: \t0.026424853928212113\t13.5\t0.09999557522193758\n",
      "episode 254800: \t0.022724197692904725\t12.1\t0.09999557522193758\n",
      "episode 254900: \t0.029095608894579295\t14.59\t0.09999557522193758\n",
      "episode 255000: \t0.028807997262312878\t18.27\t0.09999557522193758\n",
      "#Average reward per episode 255000: 0.024604231381660326\n",
      "episode 255100: \t0.018103246152145366\t9.67\t0.09999557522193758\n",
      "episode 255200: \t0.03033379218761972\t15.63\t0.09999557522193758\n",
      "episode 255300: \t0.0268073582714128\t13.35\t0.09999557522193758\n",
      "episode 255400: \t0.0310997923086805\t14.28\t0.09999557522193758\n",
      "episode 255500: \t0.020483385146444492\t11.48\t0.09999557522193758\n",
      "episode 255600: \t0.03089451907829245\t15.56\t0.09999557522193758\n",
      "episode 255700: \t0.02834329291959495\t14.83\t0.09999557522193758\n",
      "episode 255800: \t0.020477658682392427\t12.65\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 255900: \t0.025432587640391725\t13.22\t0.09999557522193758\n",
      "episode 256000: \t0.027746254408370922\t15.65\t0.09999557522193758\n",
      "episode 256100: \t0.030600228776435506\t15.2\t0.09999557522193758\n",
      "episode 256200: \t0.026819432223227965\t12.14\t0.09999557522193758\n",
      "episode 256300: \t0.016748112034436824\t11.54\t0.09999557522193758\n",
      "episode 256400: \t0.02594567511645316\t15.53\t0.09999557522193758\n",
      "episode 256500: \t0.02548309293452279\t15.87\t0.09999557522193758\n",
      "episode 256600: \t0.029349949087828092\t14.49\t0.09999557522193758\n",
      "episode 256700: \t0.025768807670377248\t11.69\t0.09999557522193758\n",
      "episode 256800: \t0.026205815749660685\t11.22\t0.09999557522193758\n",
      "episode 256900: \t0.02283565595719699\t11.77\t0.09999557522193758\n",
      "episode 257000: \t0.021038980248671478\t13.12\t0.09999557522193758\n",
      "episode 257100: \t0.025686941624963454\t11.96\t0.09999557522193758\n",
      "episode 257200: \t0.027429787173718592\t13.83\t0.09999557522193758\n",
      "episode 257300: \t0.023598732699940096\t11.78\t0.09999557522193758\n",
      "episode 257400: \t0.025141292347470662\t12.34\t0.09999557522193758\n",
      "episode 257500: \t0.026088825209149905\t12.14\t0.09999557522193758\n",
      "episode 257600: \t0.02629354003213015\t12.81\t0.09999557522193758\n",
      "episode 257700: \t0.02252923390273086\t12.38\t0.09999557522193758\n",
      "episode 257800: \t0.02733597824359582\t13.91\t0.09999557522193758\n",
      "episode 257900: \t0.02445545189573635\t13.42\t0.09999557522193758\n",
      "episode 258000: \t0.02197674893149618\t11.98\t0.09999557522193758\n",
      "episode 258100: \t0.026479770661555588\t14.94\t0.09999557522193758\n",
      "episode 258200: \t0.022770742577187607\t10.4\t0.09999557522193758\n",
      "episode 258300: \t0.026689902328557787\t12.26\t0.09999557522193758\n",
      "episode 258400: \t0.02593907347532725\t13.07\t0.09999557522193758\n",
      "episode 258500: \t0.02365715557784395\t11.54\t0.09999557522193758\n",
      "episode 258600: \t0.02466532913578672\t12.52\t0.09999557522193758\n",
      "episode 258700: \t0.023947650029837148\t11.01\t0.09999557522193758\n",
      "episode 258800: \t0.027707990063443516\t12.41\t0.09999557522193758\n",
      "episode 258900: \t0.026068200186936473\t10.65\t0.09999557522193758\n",
      "episode 259000: \t0.02760712337065748\t12.02\t0.09999557522193758\n",
      "episode 259100: \t0.02493285571287855\t10.62\t0.09999557522193758\n",
      "episode 259200: \t0.023832179332514775\t10.16\t0.09999557522193758\n",
      "episode 259300: \t0.024875389973887323\t12.57\t0.09999557522193758\n",
      "episode 259400: \t0.029414202389208808\t14.89\t0.09999557522193758\n",
      "episode 259500: \t0.0285156151701263\t13.78\t0.09999557522193758\n",
      "episode 259600: \t0.02264826502224155\t12.51\t0.09999557522193758\n",
      "episode 259700: \t0.02609577297269848\t12.37\t0.09999557522193758\n",
      "episode 259800: \t0.02836603297034042\t12.29\t0.09999557522193758\n",
      "episode 259900: \t0.0286110806085119\t12.67\t0.09999557522193758\n",
      "episode 260000: \t0.02202930576597486\t13.35\t0.09999557522193758\n",
      "#Average reward per episode 260000: 0.024621806857390172\n",
      "Saved Model\n",
      "#Intermediate time to execute: 3205.781328121821min\n",
      "episode 260100: \t0.028138810135539608\t13.05\t0.09999557522193758\n",
      "episode 260200: \t0.02534184279301839\t9.74\t0.09999557522193758\n",
      "episode 260300: \t0.02868314289650033\t12.97\t0.09999557522193758\n",
      "episode 260400: \t0.026106769569843723\t13.44\t0.09999557522193758\n",
      "episode 260500: \t0.028660845974691585\t13.23\t0.09999557522193758\n",
      "episode 260600: \t0.02775474138905111\t12.24\t0.09999557522193758\n",
      "episode 260700: \t0.02436191020308267\t10.64\t0.09999557522193758\n",
      "episode 260800: \t0.02892322018250308\t15.42\t0.09999557522193758\n",
      "episode 260900: \t0.028325130251242916\t13.35\t0.09999557522193758\n",
      "episode 261000: \t0.026842548048344274\t14.08\t0.09999557522193758\n",
      "episode 261100: \t0.024842719132776993\t12.29\t0.09999557522193758\n",
      "episode 261200: \t0.023798658548849078\t12.05\t0.09999557522193758\n",
      "episode 261300: \t0.02684210319525053\t12.99\t0.09999557522193758\n",
      "episode 261400: \t0.026743456030025467\t10.99\t0.09999557522193758\n",
      "episode 261500: \t0.02682787967315068\t11.32\t0.09999557522193758\n",
      "episode 261600: \t0.028457155963955212\t12.76\t0.09999557522193758\n",
      "episode 261700: \t0.021814906478644817\t11.45\t0.09999557522193758\n",
      "episode 261800: \t0.026583165077274647\t11.93\t0.09999557522193758\n",
      "episode 261900: \t0.023370953410476413\t12.06\t0.09999557522193758\n",
      "episode 262000: \t0.024003916669763484\t10.9\t0.09999557522193758\n",
      "episode 262100: \t0.024859431480750045\t12.59\t0.09999557522193758\n",
      "episode 262200: \t0.02858096677920476\t11.6\t0.09999557522193758\n",
      "episode 262300: \t0.025516502152019192\t15.07\t0.09999557522193758\n",
      "episode 262400: \t0.02712652180145477\t13.55\t0.09999557522193758\n",
      "episode 262500: \t0.027451090216015217\t12.81\t0.09999557522193758\n",
      "episode 262600: \t0.02633931443785999\t14.63\t0.09999557522193758\n",
      "episode 262700: \t0.025264408209228425\t13.18\t0.09999557522193758\n",
      "episode 262800: \t0.022888208151859456\t10.62\t0.09999557522193758\n",
      "episode 262900: \t0.027602873038306174\t13.09\t0.09999557522193758\n",
      "episode 263000: \t0.02011378141822605\t12.78\t0.09999557522193758\n",
      "episode 263100: \t0.03181796106341606\t14.79\t0.09999557522193758\n",
      "episode 263200: \t0.025129952953037528\t13.67\t0.09999557522193758\n",
      "episode 263300: \t0.019704870874199656\t9.48\t0.09999557522193758\n",
      "episode 263400: \t0.022993454264533406\t12.87\t0.09999557522193758\n",
      "episode 263500: \t0.02949552496442688\t14.94\t0.09999557522193758\n",
      "episode 263600: \t0.03240599710103569\t15.55\t0.09999557522193758\n",
      "episode 263700: \t0.021241325222864184\t12.72\t0.09999557522193758\n",
      "episode 263800: \t0.021339328187099896\t12.23\t0.09999557522193758\n",
      "episode 263900: \t0.0318990998219112\t15.41\t0.09999557522193758\n",
      "episode 264000: \t0.028136179316997544\t13.58\t0.09999557522193758\n",
      "episode 264100: \t0.019319479916966666\t13.05\t0.09999557522193758\n",
      "episode 264200: \t0.029784146981546255\t13.8\t0.09999557522193758\n",
      "episode 264300: \t0.02671291684049778\t14.65\t0.09999557522193758\n",
      "episode 264400: \t0.019173504448059077\t11.57\t0.09999557522193758\n",
      "episode 264500: \t0.026245621762748295\t12.64\t0.09999557522193758\n",
      "episode 264600: \t0.027898656528061103\t14.29\t0.09999557522193758\n",
      "episode 264700: \t0.025984107494996772\t14.31\t0.09999557522193758\n",
      "episode 264800: \t0.025117538632258213\t13.21\t0.09999557522193758\n",
      "episode 264900: \t0.023629686077655445\t11.27\t0.09999557522193758\n",
      "episode 265000: \t0.023590044724576584\t12.9\t0.09999557522193758\n",
      "#Average reward per episode 265000: 0.024645465735735932\n",
      "episode 265100: \t0.02721324553524675\t14.71\t0.09999557522193758\n",
      "episode 265200: \t0.03112917284480637\t13.48\t0.09999557522193758\n",
      "episode 265300: \t0.027391423064629317\t12.94\t0.09999557522193758\n",
      "episode 265400: \t0.02747025353035125\t13.43\t0.09999557522193758\n",
      "episode 265500: \t0.028011401932390028\t11.39\t0.09999557522193758\n",
      "episode 265600: \t0.028358106960139927\t13.73\t0.09999557522193758\n",
      "episode 265700: \t0.03060252340355582\t12.54\t0.09999557522193758\n",
      "episode 265800: \t0.025074590985768773\t13.28\t0.09999557522193758\n",
      "episode 265900: \t0.02412839190718008\t15.24\t0.09999557522193758\n",
      "episode 266000: \t0.029057590860209995\t16.95\t0.09999557522193758\n",
      "episode 266100: \t0.030702297395526375\t14.93\t0.09999557522193758\n",
      "episode 266200: \t0.029713686061690895\t13.77\t0.09999557522193758\n",
      "episode 266300: \t0.030660486184376085\t15.49\t0.09999557522193758\n",
      "episode 266400: \t0.02899668582189201\t12.88\t0.09999557522193758\n",
      "episode 266500: \t0.028845964905370426\t16.49\t0.09999557522193758\n",
      "episode 266600: \t0.027995526802038526\t13.42\t0.09999557522193758\n",
      "episode 266700: \t0.027523459285857504\t14.14\t0.09999557522193758\n",
      "episode 266800: \t0.026602183548231642\t15.78\t0.09999557522193758\n",
      "episode 266900: \t0.02606379839230585\t14.05\t0.09999557522193758\n",
      "episode 267000: \t0.025066560645844543\t14.78\t0.09999557522193758\n",
      "episode 267100: \t0.027524563750280836\t14.05\t0.09999557522193758\n",
      "episode 267200: \t0.026789844109584203\t13.59\t0.09999557522193758\n",
      "episode 267300: \t0.020649560076752414\t11.09\t0.09999557522193758\n",
      "episode 267400: \t0.02854535480786205\t15.5\t0.09999557522193758\n",
      "episode 267500: \t0.026563077376788896\t12.47\t0.09999557522193758\n",
      "episode 267600: \t0.02767995009154416\t15.51\t0.09999557522193758\n",
      "episode 267700: \t0.022607827536979267\t12.28\t0.09999557522193758\n",
      "episode 267800: \t0.023562724943266642\t13.79\t0.09999557522193758\n",
      "episode 267900: \t0.02567605900464276\t14.52\t0.09999557522193758\n",
      "episode 268000: \t0.022806170249308696\t11.24\t0.09999557522193758\n",
      "episode 268100: \t0.022904750541168452\t11.86\t0.09999557522193758\n",
      "episode 268200: \t0.02346390127158358\t11.77\t0.09999557522193758\n",
      "episode 268300: \t0.027375364167751687\t12.27\t0.09999557522193758\n",
      "episode 268400: \t0.025389897377287432\t13.74\t0.09999557522193758\n",
      "episode 268500: \t0.03225288851376892\t13.46\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 268600: \t0.02301171311584159\t12.57\t0.09999557522193758\n",
      "episode 268700: \t0.024809303510740333\t11.42\t0.09999557522193758\n",
      "episode 268800: \t0.029445548700289387\t14.24\t0.09999557522193758\n",
      "episode 268900: \t0.025878119345746256\t12.16\t0.09999557522193758\n",
      "episode 269000: \t0.02360825010029149\t11.6\t0.09999557522193758\n",
      "episode 269100: \t0.02878071016534773\t15.37\t0.09999557522193758\n",
      "episode 269200: \t0.02477913172168603\t15.21\t0.09999557522193758\n",
      "episode 269300: \t0.024828077194314253\t13.27\t0.09999557522193758\n",
      "episode 269400: \t0.027698012383111772\t11.63\t0.09999557522193758\n",
      "episode 269500: \t0.027624076849332168\t15.46\t0.09999557522193758\n",
      "episode 269600: \t0.022955790122211415\t12.46\t0.09999557522193758\n",
      "episode 269700: \t0.02610486763555848\t15.32\t0.09999557522193758\n",
      "episode 269800: \t0.02418244576056047\t11.03\t0.09999557522193758\n",
      "episode 269900: \t0.02923453215354794\t13.34\t0.09999557522193758\n",
      "episode 270000: \t0.024896211676776372\t12.79\t0.09999557522193758\n",
      "#Average reward per episode 270000: 0.024682488990378403\n",
      "Saved Model\n",
      "#Intermediate time to execute: 3334.8648927847544min\n",
      "episode 270100: \t0.027853119313142948\t12.79\t0.09999557522193758\n",
      "episode 270200: \t0.029303609590140837\t15.43\t0.09999557522193758\n",
      "episode 270300: \t0.027769595999093802\t16.04\t0.09999557522193758\n",
      "episode 270400: \t0.022914599344536424\t12.93\t0.09999557522193758\n",
      "episode 270500: \t0.022310432901412693\t12.96\t0.09999557522193758\n",
      "episode 270600: \t0.027016328815740773\t14.04\t0.09999557522193758\n",
      "episode 270700: \t0.022980463886438998\t12.33\t0.09999557522193758\n",
      "episode 270800: \t0.02549185446546141\t12.14\t0.09999557522193758\n",
      "episode 270900: \t0.024982831373434627\t12.25\t0.09999557522193758\n",
      "episode 271000: \t0.02516169956215048\t15.01\t0.09999557522193758\n",
      "episode 271100: \t0.02632046809266343\t13.06\t0.09999557522193758\n",
      "episode 271200: \t0.024745897943984196\t15.49\t0.09999557522193758\n",
      "episode 271300: \t0.024097698671317246\t12.87\t0.09999557522193758\n",
      "episode 271400: \t0.02100955492100519\t13.32\t0.09999557522193758\n",
      "episode 271500: \t0.031385748793452545\t13.0\t0.09999557522193758\n",
      "episode 271600: \t0.02070333153183483\t9.61\t0.09999557522193758\n",
      "episode 271700: \t0.024122071192802554\t11.35\t0.09999557522193758\n",
      "episode 271800: \t0.024230809043522167\t12.57\t0.09999557522193758\n",
      "episode 271900: \t0.025002087734379064\t13.53\t0.09999557522193758\n",
      "episode 272000: \t0.02735826497055584\t13.13\t0.09999557522193758\n",
      "episode 272100: \t0.025680483546620815\t12.76\t0.09999557522193758\n",
      "episode 272200: \t0.023375117169897375\t12.27\t0.09999557522193758\n",
      "episode 272300: \t0.026387607103985113\t12.83\t0.09999557522193758\n",
      "episode 272400: \t0.026320242111432312\t12.07\t0.09999557522193758\n",
      "episode 272500: \t0.026167435081061056\t14.91\t0.09999557522193758\n",
      "episode 272600: \t0.0230783876026451\t12.96\t0.09999557522193758\n",
      "episode 272700: \t0.02738589316378244\t12.13\t0.09999557522193758\n",
      "episode 272800: \t0.02641828720453637\t12.9\t0.09999557522193758\n",
      "episode 272900: \t0.028897151981288637\t14.96\t0.09999557522193758\n",
      "episode 273000: \t0.023402850181332466\t12.93\t0.09999557522193758\n",
      "episode 273100: \t0.02299752248622474\t13.94\t0.09999557522193758\n",
      "episode 273200: \t0.024844532909598024\t11.65\t0.09999557522193758\n",
      "episode 273300: \t0.025943858984600297\t12.37\t0.09999557522193758\n",
      "episode 273400: \t0.02905796643136365\t12.85\t0.09999557522193758\n",
      "episode 273500: \t0.023663137071126664\t12.23\t0.09999557522193758\n",
      "episode 273600: \t0.02605278250871706\t13.79\t0.09999557522193758\n",
      "episode 273700: \t0.0294517390453117\t13.14\t0.09999557522193758\n",
      "episode 273800: \t0.028068070407379263\t13.31\t0.09999557522193758\n",
      "episode 273900: \t0.02542535950058646\t16.26\t0.09999557522193758\n",
      "episode 274000: \t0.028259304749534787\t17.51\t0.09999557522193758\n",
      "episode 274100: \t0.025009240015921988\t12.37\t0.09999557522193758\n",
      "episode 274200: \t0.024256215689005715\t13.08\t0.09999557522193758\n",
      "episode 274300: \t0.022779807202269763\t13.79\t0.09999557522193758\n",
      "episode 274400: \t0.026126263614600173\t14.97\t0.09999557522193758\n",
      "episode 274500: \t0.02702235802729848\t13.52\t0.09999557522193758\n",
      "episode 274600: \t0.027295068544862994\t13.44\t0.09999557522193758\n",
      "episode 274700: \t0.02494605659365926\t13.83\t0.09999557522193758\n",
      "episode 274800: \t0.024064751102631045\t12.21\t0.09999557522193758\n",
      "episode 274900: \t0.02957548504484699\t14.03\t0.09999557522193758\n",
      "episode 275000: \t0.021858576936095095\t11.32\t0.09999557522193758\n",
      "#Average reward per episode 275000: 0.024698651743338535\n",
      "episode 275100: \t0.0256274894695057\t15.53\t0.09999557522193758\n",
      "episode 275200: \t0.023924764255232663\t16.69\t0.09999557522193758\n",
      "episode 275300: \t0.02026723227223068\t11.48\t0.09999557522193758\n",
      "episode 275400: \t0.024840276820649904\t12.5\t0.09999557522193758\n",
      "episode 275500: \t0.02012688577189712\t14.09\t0.09999557522193758\n",
      "episode 275600: \t0.021790253592400652\t10.65\t0.09999557522193758\n",
      "episode 275700: \t0.02874523178280118\t14.03\t0.09999557522193758\n",
      "episode 275800: \t0.025117903094915798\t16.11\t0.09999557522193758\n",
      "episode 275900: \t0.029539601567210277\t16.95\t0.09999557522193758\n",
      "episode 276000: \t0.027006210442216384\t15.02\t0.09999557522193758\n",
      "episode 276100: \t0.029362796222246548\t15.62\t0.09999557522193758\n",
      "episode 276200: \t0.02685712137732528\t13.37\t0.09999557522193758\n",
      "episode 276300: \t0.02406158044304677\t13.79\t0.09999557522193758\n",
      "episode 276400: \t0.01815049127663313\t12.12\t0.09999557522193758\n",
      "episode 276500: \t0.020896026927380795\t13.64\t0.09999557522193758\n",
      "episode 276600: \t0.027793653690047534\t14.09\t0.09999557522193758\n",
      "episode 276700: \t0.027199403050188718\t15.27\t0.09999557522193758\n",
      "episode 276800: \t0.024079280967306927\t14.59\t0.09999557522193758\n",
      "episode 276900: \t0.02669758777588529\t14.61\t0.09999557522193758\n",
      "episode 277000: \t0.024913677490425768\t14.91\t0.09999557522193758\n",
      "episode 277100: \t0.03289734628499832\t17.63\t0.09999557522193758\n",
      "episode 277200: \t0.026790688537419723\t17.68\t0.09999557522193758\n",
      "episode 277300: \t0.024653892571510173\t14.39\t0.09999557522193758\n",
      "episode 277400: \t0.02720540972027983\t16.17\t0.09999557522193758\n",
      "episode 277500: \t0.022807125778140546\t17.36\t0.09999557522193758\n",
      "episode 277600: \t0.028358327531377046\t16.37\t0.09999557522193758\n",
      "episode 277700: \t0.030346451151298647\t16.36\t0.09999557522193758\n",
      "episode 277800: \t0.028686561589483923\t16.64\t0.09999557522193758\n",
      "episode 277900: \t0.02911481102093273\t16.17\t0.09999557522193758\n",
      "episode 278000: \t0.026015419394611293\t15.44\t0.09999557522193758\n",
      "episode 278100: \t0.024086902443713365\t15.17\t0.09999557522193758\n",
      "episode 278200: \t0.029694720986783545\t15.24\t0.09999557522193758\n",
      "episode 278300: \t0.030100373100465917\t16.26\t0.09999557522193758\n",
      "episode 278400: \t0.024406585276821203\t15.92\t0.09999557522193758\n",
      "episode 278500: \t0.024160920261779534\t13.73\t0.09999557522193758\n",
      "episode 278600: \t0.021973489159808443\t16.62\t0.09999557522193758\n",
      "episode 278700: \t0.024006560022702392\t12.25\t0.09999557522193758\n",
      "episode 278800: \t0.023281321848687225\t14.34\t0.09999557522193758\n",
      "episode 278900: \t0.02660197967098659\t15.63\t0.09999557522193758\n",
      "episode 279000: \t0.024537479515916512\t15.81\t0.09999557522193758\n",
      "episode 279100: \t0.02745257844268921\t15.41\t0.09999557522193758\n",
      "episode 279200: \t0.018728356194954353\t12.1\t0.09999557522193758\n",
      "episode 279300: \t0.02134328762539899\t11.72\t0.09999557522193758\n",
      "episode 279400: \t0.03003237766460003\t16.24\t0.09999557522193758\n",
      "episode 279500: \t0.0264465655497517\t13.74\t0.09999557522193758\n",
      "episode 279600: \t0.027401242728008403\t15.43\t0.09999557522193758\n",
      "episode 279700: \t0.02308263680553722\t10.76\t0.09999557522193758\n",
      "episode 279800: \t0.02764465153062152\t15.04\t0.09999557522193758\n",
      "episode 279900: \t0.026757530875971606\t13.1\t0.09999557522193758\n",
      "episode 280000: \t0.026463695613126628\t14.26\t0.09999557522193758\n",
      "#Average reward per episode 280000: 0.024715488946917406\n",
      "Saved Model\n",
      "#Intermediate time to execute: 3464.9235018173854min\n",
      "episode 280100: \t0.023624391673711376\t14.66\t0.09999557522193758\n",
      "episode 280200: \t0.025310435548899522\t14.06\t0.09999557522193758\n",
      "episode 280300: \t0.027776068545216064\t15.77\t0.09999557522193758\n",
      "episode 280400: \t0.02804792547922259\t14.18\t0.09999557522193758\n",
      "episode 280500: \t0.026781664947476427\t14.13\t0.09999557522193758\n",
      "episode 280600: \t0.028247581644167387\t16.25\t0.09999557522193758\n",
      "episode 280700: \t0.02276603415535699\t13.4\t0.09999557522193758\n",
      "episode 280800: \t0.030263203604114705\t14.59\t0.09999557522193758\n",
      "episode 280900: \t0.025386601407516713\t12.53\t0.09999557522193758\n",
      "episode 281000: \t0.02469532509682582\t12.01\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 281100: \t0.023675976360799475\t14.65\t0.09999557522193758\n",
      "episode 281200: \t0.02457026700782994\t13.35\t0.09999557522193758\n",
      "episode 281300: \t0.02498413429110981\t14.54\t0.09999557522193758\n",
      "episode 281400: \t0.029170601512598416\t14.62\t0.09999557522193758\n",
      "episode 281500: \t0.024341204129522273\t14.04\t0.09999557522193758\n",
      "episode 281600: \t0.02701694120667032\t14.45\t0.09999557522193758\n",
      "episode 281700: \t0.02238664151149859\t13.08\t0.09999557522193758\n",
      "episode 281800: \t0.028621932260213444\t15.91\t0.09999557522193758\n",
      "episode 281900: \t0.025471183079861282\t13.85\t0.09999557522193758\n",
      "episode 282000: \t0.028253470854642086\t13.61\t0.09999557522193758\n",
      "episode 282100: \t0.030177494493628942\t14.76\t0.09999557522193758\n",
      "episode 282200: \t0.027376288122608537\t12.44\t0.09999557522193758\n",
      "episode 282300: \t0.022694065773847093\t11.65\t0.09999557522193758\n",
      "episode 282400: \t0.02519295957838846\t12.8\t0.09999557522193758\n",
      "episode 282500: \t0.027577318381576166\t12.36\t0.09999557522193758\n",
      "episode 282600: \t0.032257859384786404\t16.5\t0.09999557522193758\n",
      "episode 282700: \t0.030463324694533354\t13.46\t0.09999557522193758\n",
      "episode 282800: \t0.026188584378238473\t13.52\t0.09999557522193758\n",
      "episode 282900: \t0.028974224914857308\t14.73\t0.09999557522193758\n",
      "episode 283000: \t0.02533057519612949\t14.24\t0.09999557522193758\n",
      "episode 283100: \t0.03049220333957684\t15.0\t0.09999557522193758\n",
      "episode 283200: \t0.024434077460033052\t13.28\t0.09999557522193758\n",
      "episode 283300: \t0.024004688010213018\t13.33\t0.09999557522193758\n",
      "episode 283400: \t0.023978625018034577\t13.45\t0.09999557522193758\n",
      "episode 283500: \t0.029635084839376682\t14.39\t0.09999557522193758\n",
      "episode 283600: \t0.026983511718702884\t12.29\t0.09999557522193758\n",
      "episode 283700: \t0.031455128332871694\t15.37\t0.09999557522193758\n",
      "episode 283800: \t0.02934421610724962\t13.87\t0.09999557522193758\n",
      "episode 283900: \t0.030458849233176856\t16.09\t0.09999557522193758\n",
      "episode 284000: \t0.026780389778540584\t12.98\t0.09999557522193758\n",
      "episode 284100: \t0.02587221798211985\t13.69\t0.09999557522193758\n",
      "episode 284200: \t0.020617844520292125\t12.55\t0.09999557522193758\n",
      "episode 284300: \t0.02699924740145784\t13.75\t0.09999557522193758\n",
      "episode 284400: \t0.024896719625036895\t12.47\t0.09999557522193758\n",
      "episode 284500: \t0.02957851612089529\t15.41\t0.09999557522193758\n",
      "episode 284600: \t0.029586273248482096\t16.18\t0.09999557522193758\n",
      "episode 284700: \t0.027611254464469454\t16.7\t0.09999557522193758\n",
      "episode 284800: \t0.025837544825563562\t12.33\t0.09999557522193758\n",
      "episode 284900: \t0.018019670266814673\t11.98\t0.09999557522193758\n",
      "episode 285000: \t0.02859709580308894\t13.55\t0.09999557522193758\n",
      "#Average reward per episode 285000: 0.024749535610070397\n",
      "episode 285100: \t0.029199929422383496\t14.76\t0.09999557522193758\n",
      "episode 285200: \t0.027465197003901345\t13.26\t0.09999557522193758\n",
      "episode 285300: \t0.02558019286047293\t15.02\t0.09999557522193758\n",
      "episode 285400: \t0.02398616024923088\t13.37\t0.09999557522193758\n",
      "episode 285500: \t0.026747473131643686\t12.58\t0.09999557522193758\n",
      "episode 285600: \t0.025476311910941254\t13.52\t0.09999557522193758\n",
      "episode 285700: \t0.024280872667158806\t14.91\t0.09999557522193758\n",
      "episode 285800: \t0.028776537109763755\t13.91\t0.09999557522193758\n",
      "episode 285900: \t0.02976667482668332\t14.88\t0.09999557522193758\n",
      "episode 286000: \t0.025264939972459776\t13.04\t0.09999557522193758\n",
      "episode 286100: \t0.02603225998049334\t14.98\t0.09999557522193758\n",
      "episode 286200: \t0.027247156989622375\t14.34\t0.09999557522193758\n",
      "episode 286300: \t0.021754315319757002\t11.3\t0.09999557522193758\n",
      "episode 286400: \t0.026384717576015692\t14.01\t0.09999557522193758\n",
      "episode 286500: \t0.026201879984800752\t12.64\t0.09999557522193758\n",
      "episode 286600: \t0.02078255243631797\t15.13\t0.09999557522193758\n",
      "episode 286700: \t0.024782541352521305\t14.61\t0.09999557522193758\n",
      "episode 286800: \t0.024990064360281262\t15.45\t0.09999557522193758\n",
      "episode 286900: \t0.028015943753031448\t15.7\t0.09999557522193758\n",
      "episode 287000: \t0.03266809664862347\t15.74\t0.09999557522193758\n",
      "episode 287100: \t0.030524956619864863\t16.65\t0.09999557522193758\n",
      "episode 287200: \t0.02627222994715498\t14.1\t0.09999557522193758\n",
      "episode 287300: \t0.02430978023537819\t14.55\t0.09999557522193758\n",
      "episode 287400: \t0.029989796913121255\t17.59\t0.09999557522193758\n",
      "episode 287500: \t0.02638351110429872\t17.1\t0.09999557522193758\n",
      "episode 287600: \t0.026111095425820966\t15.7\t0.09999557522193758\n",
      "episode 287700: \t0.02590808271360585\t15.32\t0.09999557522193758\n",
      "episode 287800: \t0.025546653072770334\t14.98\t0.09999557522193758\n",
      "episode 287900: \t0.023080452730328646\t14.78\t0.09999557522193758\n",
      "episode 288000: \t0.022335989466831255\t13.38\t0.09999557522193758\n",
      "episode 288100: \t0.02854111131534283\t15.45\t0.09999557522193758\n",
      "episode 288200: \t0.025250954421745752\t16.36\t0.09999557522193758\n",
      "episode 288300: \t0.02145967592265569\t15.06\t0.09999557522193758\n",
      "episode 288400: \t0.02707543544008822\t15.88\t0.09999557522193758\n",
      "episode 288500: \t0.018811846531814728\t12.43\t0.09999557522193758\n",
      "episode 288600: \t0.025961680842329984\t15.34\t0.09999557522193758\n",
      "episode 288700: \t0.02601877319540634\t13.83\t0.09999557522193758\n",
      "episode 288800: \t0.02863801360439406\t13.62\t0.09999557522193758\n",
      "episode 288900: \t0.03109275063615347\t16.46\t0.09999557522193758\n",
      "episode 289000: \t0.029588066447902035\t15.78\t0.09999557522193758\n",
      "episode 289100: \t0.02907334702565962\t14.94\t0.09999557522193758\n",
      "episode 289200: \t0.02728667239617658\t15.05\t0.09999557522193758\n",
      "episode 289300: \t0.02633051457637048\t13.32\t0.09999557522193758\n",
      "episode 289400: \t0.02651018248006474\t12.39\t0.09999557522193758\n",
      "episode 289500: \t0.030391695409093224\t15.8\t0.09999557522193758\n",
      "episode 289600: \t0.028728463757931397\t14.03\t0.09999557522193758\n",
      "episode 289700: \t0.03358372255923347\t16.81\t0.09999557522193758\n",
      "episode 289800: \t0.02754820192177081\t13.77\t0.09999557522193758\n",
      "episode 289900: \t0.023499095043741834\t12.71\t0.09999557522193758\n",
      "episode 290000: \t0.025316454317333415\t13.57\t0.09999557522193758\n",
      "#Average reward per episode 290000: 0.024780258452527945\n",
      "Saved Model\n",
      "#Intermediate time to execute: 3594.9565120975176min\n",
      "episode 290100: \t0.03112208314631212\t14.98\t0.09999557522193758\n",
      "episode 290200: \t0.024813377704362424\t12.77\t0.09999557522193758\n",
      "episode 290300: \t0.02231293049221263\t13.51\t0.09999557522193758\n",
      "episode 290400: \t0.027831667853477196\t15.2\t0.09999557522193758\n",
      "episode 290500: \t0.02686740712394888\t14.11\t0.09999557522193758\n",
      "episode 290600: \t0.027061571416796926\t13.25\t0.09999557522193758\n",
      "episode 290700: \t0.02798607856188652\t14.17\t0.09999557522193758\n",
      "episode 290800: \t0.026234932751743635\t13.78\t0.09999557522193758\n",
      "episode 290900: \t0.026702599735508387\t13.9\t0.09999557522193758\n",
      "episode 291000: \t0.029377755432821097\t16.76\t0.09999557522193758\n",
      "episode 291100: \t0.025682671741553288\t13.08\t0.09999557522193758\n",
      "episode 291200: \t0.02483547339758046\t15.34\t0.09999557522193758\n",
      "episode 291300: \t0.02399696968945643\t13.24\t0.09999557522193758\n",
      "episode 291400: \t0.029003576011788112\t15.26\t0.09999557522193758\n",
      "episode 291500: \t0.02728421590368959\t13.17\t0.09999557522193758\n",
      "episode 291600: \t0.02059447908926899\t12.16\t0.09999557522193758\n",
      "episode 291700: \t0.026222970964940348\t14.48\t0.09999557522193758\n",
      "episode 291800: \t0.02855417984972036\t16.1\t0.09999557522193758\n",
      "episode 291900: \t0.022810259211426077\t13.25\t0.09999557522193758\n",
      "episode 292000: \t0.025787831640506763\t13.89\t0.09999557522193758\n",
      "episode 292100: \t0.03237039612956982\t16.2\t0.09999557522193758\n",
      "episode 292200: \t0.02929918826287892\t15.96\t0.09999557522193758\n",
      "episode 292300: \t0.026870555406849\t12.67\t0.09999557522193758\n",
      "episode 292400: \t0.026737679266735995\t14.48\t0.09999557522193758\n",
      "episode 292500: \t0.018741930320121062\t12.58\t0.09999557522193758\n",
      "episode 292600: \t0.029869677607766078\t15.27\t0.09999557522193758\n",
      "episode 292700: \t0.02296541748845463\t15.81\t0.09999557522193758\n",
      "episode 292800: \t0.025357513438618463\t11.9\t0.09999557522193758\n",
      "episode 292900: \t0.03246129292466242\t15.39\t0.09999557522193758\n",
      "episode 293000: \t0.02646377502530286\t14.66\t0.09999557522193758\n",
      "episode 293100: \t0.02542297314550907\t16.46\t0.09999557522193758\n",
      "episode 293200: \t0.0267606139796008\t12.36\t0.09999557522193758\n",
      "episode 293300: \t0.031015633737234986\t15.46\t0.09999557522193758\n",
      "episode 293400: \t0.029013340822711974\t16.28\t0.09999557522193758\n",
      "episode 293500: \t0.023016050201469445\t14.72\t0.09999557522193758\n",
      "episode 293600: \t0.02677099776235305\t12.97\t0.09999557522193758\n",
      "episode 293700: \t0.020523520618181273\t12.46\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 293800: \t0.0208901721123779\t12.11\t0.09999557522193758\n",
      "episode 293900: \t0.026971552950729435\t13.68\t0.09999557522193758\n",
      "episode 294000: \t0.02608138115996299\t13.98\t0.09999557522193758\n",
      "episode 294100: \t0.027099135113336965\t17.42\t0.09999557522193758\n",
      "episode 294200: \t0.02393577858039378\t13.82\t0.09999557522193758\n",
      "episode 294300: \t0.03359095249264013\t17.04\t0.09999557522193758\n",
      "episode 294400: \t0.029489945218132693\t19.0\t0.09999557522193758\n",
      "episode 294500: \t0.023045777182444542\t12.56\t0.09999557522193758\n",
      "episode 294600: \t0.02899152033185776\t17.3\t0.09999557522193758\n",
      "episode 294700: \t0.025092390314191432\t13.93\t0.09999557522193758\n",
      "episode 294800: \t0.027552218170561575\t15.72\t0.09999557522193758\n",
      "episode 294900: \t0.026298632788468636\t16.27\t0.09999557522193758\n",
      "episode 295000: \t0.022710210240201086\t13.77\t0.09999557522193758\n",
      "#Average reward per episode 295000: 0.024807878904014598\n",
      "episode 295100: \t0.030131419786189023\t17.91\t0.09999557522193758\n",
      "episode 295200: \t0.021058864546544785\t13.22\t0.09999557522193758\n",
      "episode 295300: \t0.03121951056913598\t17.28\t0.09999557522193758\n",
      "episode 295400: \t0.025639295412935817\t14.95\t0.09999557522193758\n",
      "episode 295500: \t0.026888371239400032\t15.94\t0.09999557522193758\n",
      "episode 295600: \t0.0323918978971934\t18.85\t0.09999557522193758\n",
      "episode 295700: \t0.025286718760801984\t12.2\t0.09999557522193758\n",
      "episode 295800: \t0.03496356448225793\t16.12\t0.09999557522193758\n",
      "episode 295900: \t0.03168913941900127\t16.47\t0.09999557522193758\n",
      "episode 296000: \t0.023885935684948997\t15.14\t0.09999557522193758\n",
      "episode 296100: \t0.02555221574732012\t15.64\t0.09999557522193758\n",
      "episode 296200: \t0.025676348199932916\t14.71\t0.09999557522193758\n",
      "episode 296300: \t0.02227482173957472\t15.79\t0.09999557522193758\n",
      "episode 296400: \t0.027556173958252463\t14.29\t0.09999557522193758\n",
      "episode 296500: \t0.025096273060679457\t14.05\t0.09999557522193758\n",
      "episode 296600: \t0.038555771164787124\t17.14\t0.09999557522193758\n",
      "episode 296700: \t0.025178260223381273\t14.35\t0.09999557522193758\n",
      "episode 296800: \t0.025316780894652235\t14.76\t0.09999557522193758\n",
      "episode 296900: \t0.02799969120108724\t16.7\t0.09999557522193758\n",
      "episode 297000: \t0.02344022274504058\t14.86\t0.09999557522193758\n",
      "episode 297100: \t0.024840017093274058\t14.07\t0.09999557522193758\n",
      "episode 297200: \t0.02730064046390127\t17.61\t0.09999557522193758\n",
      "episode 297300: \t0.02339688223120104\t14.93\t0.09999557522193758\n",
      "episode 297400: \t0.025866775572778788\t15.31\t0.09999557522193758\n",
      "episode 297500: \t0.025072371842619106\t15.46\t0.09999557522193758\n",
      "episode 297600: \t0.02684609364670455\t16.95\t0.09999557522193758\n",
      "episode 297700: \t0.03164635080448412\t16.82\t0.09999557522193758\n",
      "episode 297800: \t0.03614584115312765\t17.51\t0.09999557522193758\n",
      "episode 297900: \t0.025229764827890598\t12.43\t0.09999557522193758\n",
      "episode 298000: \t0.03431891472986114\t18.86\t0.09999557522193758\n",
      "episode 298100: \t0.02328841837807011\t12.91\t0.09999557522193758\n",
      "episode 298200: \t0.022460338895642314\t14.2\t0.09999557522193758\n",
      "episode 298300: \t0.02376714400197639\t16.07\t0.09999557522193758\n",
      "episode 298400: \t0.024059013295495143\t14.58\t0.09999557522193758\n",
      "episode 298500: \t0.021951425041472423\t15.21\t0.09999557522193758\n",
      "episode 298600: \t0.02340966986175943\t15.5\t0.09999557522193758\n",
      "episode 298700: \t0.030941084778509785\t17.41\t0.09999557522193758\n",
      "episode 298800: \t0.03110471634413512\t16.99\t0.09999557522193758\n",
      "episode 298900: \t0.02543964601633708\t16.0\t0.09999557522193758\n",
      "episode 299000: \t0.02822706320569321\t15.38\t0.09999557522193758\n",
      "episode 299100: \t0.026293388569320297\t16.84\t0.09999557522193758\n",
      "episode 299200: \t0.028329186242651464\t18.52\t0.09999557522193758\n",
      "episode 299300: \t0.027006100642621524\t17.41\t0.09999557522193758\n",
      "episode 299400: \t0.024841816373435254\t16.32\t0.09999557522193758\n",
      "episode 299500: \t0.02645843608026726\t14.77\t0.09999557522193758\n",
      "episode 299600: \t0.023375220856145976\t16.33\t0.09999557522193758\n",
      "episode 299700: \t0.028435889158517195\t17.63\t0.09999557522193758\n",
      "episode 299800: \t0.02640601671485768\t17.57\t0.09999557522193758\n",
      "episode 299900: \t0.02195945558751793\t15.19\t0.09999557522193758\n",
      "episode 300000: \t0.023627061058228496\t15.33\t0.09999557522193758\n",
      "#Average reward per episode 300000: 0.024841696262348188\n",
      "Saved Model\n",
      "#Intermediate time to execute: 3725.9937908411025min\n",
      "episode 300100: \t0.025035225942068737\t16.9\t0.09999557522193758\n",
      "episode 300200: \t0.020935181346900474\t14.32\t0.09999557522193758\n",
      "episode 300300: \t0.025581517591677486\t18.49\t0.09999557522193758\n",
      "episode 300400: \t0.03319614711973068\t19.84\t0.09999557522193758\n",
      "episode 300500: \t0.022950959989640033\t15.42\t0.09999557522193758\n",
      "episode 300600: \t0.026536479204790554\t17.75\t0.09999557522193758\n",
      "episode 300700: \t0.02662163710925116\t16.62\t0.09999557522193758\n",
      "episode 300800: \t0.02272709522323227\t13.79\t0.09999557522193758\n",
      "episode 300900: \t0.02617869274481306\t18.09\t0.09999557522193758\n",
      "episode 301000: \t0.02317501856195408\t14.84\t0.09999557522193758\n",
      "episode 301100: \t0.029786109866445212\t16.75\t0.09999557522193758\n",
      "episode 301200: \t0.026440974301933914\t14.86\t0.09999557522193758\n",
      "episode 301300: \t0.029406404322140464\t17.49\t0.09999557522193758\n",
      "episode 301400: \t0.027035355178850057\t17.02\t0.09999557522193758\n",
      "episode 301500: \t0.025653221005429397\t15.18\t0.09999557522193758\n",
      "episode 301600: \t0.02350619316407899\t14.23\t0.09999557522193758\n",
      "episode 301700: \t0.025909719269891305\t16.55\t0.09999557522193758\n",
      "episode 301800: \t0.02095212938784861\t15.01\t0.09999557522193758\n",
      "episode 301900: \t0.02991802581380383\t18.36\t0.09999557522193758\n",
      "episode 302000: \t0.02750697429447449\t17.18\t0.09999557522193758\n",
      "episode 302100: \t0.02479330435175171\t14.84\t0.09999557522193758\n",
      "episode 302200: \t0.022643166724586862\t15.75\t0.09999557522193758\n",
      "episode 302300: \t0.02631456918440672\t17.99\t0.09999557522193758\n",
      "episode 302400: \t0.021041576480473813\t13.68\t0.09999557522193758\n",
      "episode 302500: \t0.024171633149249153\t17.74\t0.09999557522193758\n",
      "episode 302600: \t0.027193925640929994\t15.22\t0.09999557522193758\n",
      "episode 302700: \t0.026561312744956746\t15.26\t0.09999557522193758\n",
      "episode 302800: \t0.02239857711850762\t16.46\t0.09999557522193758\n",
      "episode 302900: \t0.01869377289761343\t14.08\t0.09999557522193758\n",
      "episode 303000: \t0.02469449417647657\t14.42\t0.09999557522193758\n",
      "episode 303100: \t0.023135822776773236\t15.88\t0.09999557522193758\n",
      "episode 303200: \t0.02724658334029722\t17.83\t0.09999557522193758\n",
      "episode 303300: \t0.02937035950618097\t17.26\t0.09999557522193758\n",
      "episode 303400: \t0.025314048616536175\t17.54\t0.09999557522193758\n",
      "episode 303500: \t0.023896077404407082\t14.91\t0.09999557522193758\n",
      "episode 303600: \t0.029366549244192144\t16.91\t0.09999557522193758\n",
      "episode 303700: \t0.025702792217293515\t17.18\t0.09999557522193758\n",
      "episode 303800: \t0.024820714165554533\t16.63\t0.09999557522193758\n",
      "episode 303900: \t0.02888571176671593\t16.79\t0.09999557522193758\n",
      "episode 304000: \t0.022796091248357603\t15.7\t0.09999557522193758\n",
      "episode 304100: \t0.02701962976467055\t16.76\t0.09999557522193758\n",
      "episode 304200: \t0.02708127221414883\t14.66\t0.09999557522193758\n",
      "episode 304300: \t0.025904206207186184\t17.43\t0.09999557522193758\n",
      "episode 304400: \t0.024082611822304666\t15.14\t0.09999557522193758\n",
      "episode 304500: \t0.02307137207998891\t13.33\t0.09999557522193758\n",
      "episode 304600: \t0.031052703936018392\t15.99\t0.09999557522193758\n",
      "episode 304700: \t0.026475757056769612\t15.97\t0.09999557522193758\n",
      "episode 304800: \t0.0254014484359933\t15.24\t0.09999557522193758\n",
      "episode 304900: \t0.024635839355035757\t14.6\t0.09999557522193758\n",
      "episode 305000: \t0.031157688809326588\t16.95\t0.09999557522193758\n",
      "#Average reward per episode 305000: 0.024855431298662436\n",
      "episode 305100: \t0.02736346096963351\t15.49\t0.09999557522193758\n",
      "episode 305200: \t0.024951125952899642\t14.99\t0.09999557522193758\n",
      "episode 305300: \t0.02804159209842652\t14.54\t0.09999557522193758\n",
      "episode 305400: \t0.021100969533057477\t13.76\t0.09999557522193758\n",
      "episode 305500: \t0.028739125122553163\t16.62\t0.09999557522193758\n",
      "episode 305600: \t0.028310979676153782\t13.36\t0.09999557522193758\n",
      "episode 305700: \t0.024485880183178866\t14.28\t0.09999557522193758\n",
      "episode 305800: \t0.03373900623066097\t17.32\t0.09999557522193758\n",
      "episode 305900: \t0.021512063368300572\t13.38\t0.09999557522193758\n",
      "episode 306000: \t0.022321555235978573\t14.36\t0.09999557522193758\n",
      "episode 306100: \t0.025021597601507503\t15.85\t0.09999557522193758\n",
      "episode 306200: \t0.0317204512515072\t15.76\t0.09999557522193758\n",
      "episode 306300: \t0.02664171866498991\t12.25\t0.09999557522193758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 306400: \t0.029005150436108674\t17.17\t0.09999557522193758\n",
      "episode 306500: \t0.026845673664660064\t15.72\t0.09999557522193758\n",
      "episode 306600: \t0.0292623133157123\t15.65\t0.09999557522193758\n",
      "episode 306700: \t0.026263085385508318\t15.38\t0.09999557522193758\n",
      "episode 306800: \t0.023584112391859494\t12.64\t0.09999557522193758\n",
      "episode 306900: \t0.025129245395944036\t16.27\t0.09999557522193758\n",
      "episode 307000: \t0.022103380375788448\t12.59\t0.09999557522193758\n",
      "episode 307100: \t0.023665117315822038\t14.75\t0.09999557522193758\n",
      "episode 307200: \t0.02073663674289123\t12.41\t0.09999557522193758\n",
      "episode 307300: \t0.02666235765502543\t13.04\t0.09999557522193758\n",
      "episode 307400: \t0.027378203170387753\t15.21\t0.09999557522193758\n",
      "episode 307500: \t0.021735655394334308\t13.13\t0.09999557522193758\n",
      "episode 307600: \t0.030885340259489392\t17.83\t0.09999557522193758\n",
      "episode 307700: \t0.027619883339007868\t18.17\t0.09999557522193758\n",
      "episode 307800: \t0.024786383397654075\t14.71\t0.09999557522193758\n",
      "episode 307900: \t0.025381451270721646\t15.16\t0.09999557522193758\n",
      "episode 308000: \t0.02680817750286096\t15.68\t0.09999557522193758\n",
      "episode 308100: \t0.028303190589751538\t15.84\t0.09999557522193758\n",
      "episode 308200: \t0.02934618333578266\t17.0\t0.09999557522193758\n",
      "episode 308300: \t0.027846807236962198\t14.83\t0.09999557522193758\n",
      "episode 308400: \t0.020354935723815467\t11.62\t0.09999557522193758\n",
      "episode 308500: \t0.028507575957069934\t14.22\t0.09999557522193758\n",
      "episode 308600: \t0.023900400764766336\t14.94\t0.09999557522193758\n",
      "episode 308700: \t0.02284526835851913\t15.18\t0.09999557522193758\n",
      "episode 308800: \t0.02071781408772879\t13.86\t0.09999557522193758\n",
      "episode 308900: \t0.026523504791353437\t15.2\t0.09999557522193758\n",
      "episode 309000: \t0.025611996533116913\t15.77\t0.09999557522193758\n",
      "episode 309100: \t0.02210670970206961\t13.6\t0.09999557522193758\n",
      "episode 309200: \t0.027210739282242064\t16.67\t0.09999557522193758\n",
      "episode 309300: \t0.023284489962057543\t13.72\t0.09999557522193758\n",
      "episode 309400: \t0.02423045452828863\t13.37\t0.09999557522193758\n",
      "episode 309500: \t0.021605639038480503\t14.96\t0.09999557522193758\n",
      "episode 309600: \t0.024422346034941575\t15.31\t0.09999557522193758\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "tf.reset_default_graph()\n",
    "#We define the primary and target q-networks\n",
    "mainQN = Qnetwork('main')\n",
    "targetQN = Qnetwork('target')\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau,softUpdate)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "# amounts by which to anneal\n",
    "episodeDrop = (startE - endE)/annealing_episodes\n",
    "\n",
    "episodeDrop2 = (endE - exploitationE)/annealing_exploitation_episodes\n",
    "\n",
    "#create lists to contain total rewards, steps per episode, sell time and epsilon\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "eList = []\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "NonRandom_percentage_rList = []\n",
    "NonRandom_real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "NonRandom_option_percentage_rList = []\n",
    "NonRandom_option_real_percentage_rList = []\n",
    "\n",
    "#Non random day Lists\n",
    "NonRandomrList = []\n",
    "NonRandomsTimeList = [] # sell time list\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "AvgEpisodeListEpoch = []\n",
    "AvgrListEpoch = []\n",
    "AvgsTimeListEpoch = []\n",
    "\n",
    "AvgLossList = []\n",
    "AvgQSellLossList = []\n",
    "AvgMainQList = []\n",
    "AvgTargetQList = []\n",
    "AvgMainMaxQList = []\n",
    "AvgMainHoldQList = []\n",
    "AvgMainSellQList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []\n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "\n",
    "##### Temp\n",
    "AvgLossListEpochTemp = []\n",
    "AvgQSellLossListEpochTemp = []\n",
    "AvgMainQListEpochTemp = []\n",
    "AvgTargetQListEpochTemp = []\n",
    "AvgMainMaxQListEpochTemp = []\n",
    "AvgMainHoldQListEpochTemp = []\n",
    "AvgMainSellQListEpochTemp = []\n",
    "# permanent\n",
    "AvgLossListEpoch = []\n",
    "AvgQSellLossListEpoch = []\n",
    "AvgMainQListEpoch = []\n",
    "AvgTargetQListEpoch = []\n",
    "AvgMainMaxQListEpoch = []\n",
    "AvgMainHoldQListEpoch = []\n",
    "AvgMainSellQListEpoch = []\n",
    "#####\n",
    "\n",
    "# Non random days\n",
    "AvgNonRandomrList = []\n",
    "AvgNonRandomsTimeList = []\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)  \n",
    "\n",
    "#Some config to parralelize and leverage the GPU capabilities.\n",
    "config = tf.ConfigProto()\n",
    "config.intra_op_parallelism_threads = 0 #16 #44\n",
    "config.inter_op_parallelism_threads = 0 #16 #44\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "#config.device_count = {\"CPU\": 4}, # limit to num_cpu_core CPU usage \n",
    "#config.log_device_placement = True\n",
    "#tf.Session(config=config)\n",
    "\n",
    "with tf.Session(config=config) as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    if load_model == True:\n",
    "        print ('Loading Model...')\n",
    "        #ckpt = tf.train.get_checkpoint_state(path)\n",
    "        #saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess,final_trained_model_name)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "   \n",
    "    updateTarget(targetOps,sess) #Update the target network.\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        #print('sP: ' + str(sP))\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #Reset the lstm's hidden state\n",
    "        state = np.zeros((num_layers, 2, 1, h_size))\n",
    "        \n",
    "        if exploration_type == 'Random' and np.random.rand(1) < e:\n",
    "            sell_time = random.randint(build_warm_up_state_t,max_epLength - 1)\n",
    "        else:\n",
    "            sell_time = -1\n",
    "            \n",
    "        while j < max_epLength: \n",
    "            #Choose an action greedily (with e chance of random action) from the Q-network\n",
    "            if env.is_episode_finished(): # fill with empty state till the end to have episodes of equal length to train\n",
    "                a = 0 # arbitrary\n",
    "                s1P,r,d = env.empty_step()\n",
    "            else:\n",
    "                if i < pre_train_episodes or env.get_time() < build_warm_up_state_t or sell_time != -1:    \n",
    "                    #construct the state for following steps of same episode\n",
    "                    if sell_time != -1:\n",
    "                        state1 = np.zeros((num_layers, 2, 1, h_size))\n",
    "                    else:\n",
    "                        state1 = sess.run(mainQN.rnn_state,\\\n",
    "                            feed_dict={mainQN.scalarInput:[s],mainQN.trainLength:1,\n",
    "                                       mainQN.state_in:state,mainQN.batch_size:1,\n",
    "                                       mainQN.num_quantiles:num_quantile_samples,\n",
    "                                       mainQN.quantiles_shape:num_quantile_samples})#*1})\n",
    "                    \n",
    "                    if env.get_time() < build_warm_up_state_t or env.get_payoff() <= 0:\n",
    "                        a = 0 #hold\n",
    "                    elif sell_time != -1:\n",
    "                        if j == sell_time and d == False:\n",
    "                            a = 1\n",
    "                        else:\n",
    "                            a = 0\n",
    "                    elif j == max_epLength - 1 and d == False:\n",
    "                        a = 1\n",
    "                    else:\n",
    "                        a = np.random.randint(0,2)\n",
    "\n",
    "                else:\n",
    "                    a, state1 = sess.run([mainQN.predict,mainQN.rnn_state],\\\n",
    "                        feed_dict={mainQN.scalarInput:[s],mainQN.trainLength:1,\n",
    "                                   mainQN.state_in:state,mainQN.batch_size:1,\n",
    "                                   mainQN.num_quantiles:num_quantile_samples,\n",
    "                                   mainQN.quantiles_shape:num_quantile_samples})#*1})\n",
    "            \n",
    "                s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "            \n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            state = state1\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "        \n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        eList.append(e)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "        \n",
    "        if sell_time == -1:\n",
    "            NonRandomrList.append(rAll)\n",
    "            NonRandomsTimeList.append(env.get_sell_time() + 1)\n",
    "            #NonRandom_percentage_rList.append(env.get_percentage_return())\n",
    "            #NonRandom_real_percentage_rList.append(env.get_real_percentage_return())\n",
    "            \n",
    "            stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "            NonRandom_percentage_rList.append(stock_percentage_return)\n",
    "            NonRandom_option_percentage_rList.append(option_percentage_return)\n",
    "            stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "            NonRandom_real_percentage_rList.append(stock_percentage_return)\n",
    "            NonRandom_option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        if i >= pre_train_episodes:\n",
    "            ##################IQN code\n",
    "            #Reset the lstm's hidden state\n",
    "            state_train = np.zeros((num_layers, 2, batch_size, h_size))\n",
    "            #Get a random batch of experiences.\n",
    "            trainBatch = myBuffer.sample(batch_size)\n",
    "            #Below we perform the Double-DQN update to the target Q-values\n",
    "            \n",
    "            _replay_net_target_quantile_values = sess.run([targetQN.quantile_values], feed_dict={\\\n",
    "                                targetQN.scalarInput:np.vstack(trainBatch[:,3]),\\\n",
    "                                targetQN.trainLength:trace_length,\n",
    "                                targetQN.state_in:state_train,\n",
    "                                targetQN.batch_size:batch_size,\n",
    "                                targetQN.num_quantiles:num_tau_prime_samples, \n",
    "                                targetQN.quantiles_shape:num_tau_prime_samples*num_samples})#self._q_argmax\n",
    "            if double_dqn:\n",
    "                # Shape: (num_quantile_samples x batch_size) x num_actions.\n",
    "                target_quantile_values_action  = sess.run([mainQN.quantile_values], feed_dict={\\\n",
    "                                mainQN.scalarInput:np.vstack(trainBatch[:,3]),\\\n",
    "                                mainQN.trainLength:trace_length,\n",
    "                                mainQN.state_in:state_train,\n",
    "                                mainQN.batch_size:batch_size,\n",
    "                                mainQN.num_quantiles:num_quantile_samples, \n",
    "                                mainQN.quantiles_shape:num_quantile_samples*num_samples})#self._q_argmax\n",
    "            else:\n",
    "                # Shape: (num_quantile_samples x batch_size) x num_actions.\n",
    "                target_quantile_values_action  = sess.run([targetQN.quantile_values], feed_dict={\\\n",
    "                                targetQN.scalarInput:np.vstack(trainBatch[:,3]),\\\n",
    "                                targetQN.trainLength:trace_length,\n",
    "                                targetQN.state_in:state_train,\n",
    "                                targetQN.batch_size:batch_size,\n",
    "                                targetQN.num_quantiles:num_quantile_samples, \n",
    "                                targetQN.quantiles_shape:num_quantile_samples*num_samples})#self._q_argmax\n",
    "            # Shape: num_quantile_samples x batch_size x num_actions.\n",
    "            target_quantile_values_action = np.reshape(target_quantile_values_action,\n",
    "                                               [num_quantile_samples,\n",
    "                                                num_samples,\n",
    "                                                num_actions])\n",
    "            # Shape: batch_size x num_actions.\n",
    "            _replay_net_target_q_values = np.squeeze(np.mean(target_quantile_values_action, axis=0))\n",
    "            \n",
    "            _replay_next_qt_argmax = np.argmax(_replay_net_target_q_values, axis=1)\n",
    "            \n",
    "            target_quantile_values = _build_target_quantile_values_op(_replay_next_qt_argmax,\\\n",
    "                                    _replay_net_target_quantile_values,\\\n",
    "                                    np.array(trainBatch[:,4]),np.array(trainBatch[:,2]))\n",
    "            \n",
    "            # Reshape to self.num_tau_prime_samples x batch_size x 1 since this is\n",
    "            # the manner in which the target_quantile_values are tiled.\n",
    "            target_quantile_values = target_quantile_values.reshape([num_tau_prime_samples,num_samples, 1])\n",
    "            # Transpose dimensions so that the dimensionality is batch_size x\n",
    "            # self.num_tau_prime_samples x 1 to prepare for computation of\n",
    "            # Bellman errors.\n",
    "            # Final shape of target_quantile_values:\n",
    "            # batch_size x num_tau_prime_samples x 1.\n",
    "            target_quantile_values = np.transpose(target_quantile_values, [1, 0, 2])\n",
    "            \n",
    "            loss, main_Q, _ = sess.run([mainQN.loss, mainQN._q_values, mainQN.updateModel],\\\n",
    "                                feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),\\\n",
    "                                mainQN.actions:trainBatch[:,1],\\\n",
    "                                mainQN.trainLength:trace_length,\\\n",
    "                                mainQN.state_in:state_train,\\\n",
    "                                mainQN.batch_size:batch_size,\\\n",
    "                                mainQN.num_quantiles:num_tau_samples, \n",
    "                                mainQN.quantiles_shape:num_tau_samples*num_samples,\n",
    "                                mainQN.target_quantile_values:target_quantile_values})\n",
    "            \n",
    "            # perform soft/hard update frequently\n",
    "            if i % update_target_freq == 0 or update_target_freq == 1 or softUpdate == True:\n",
    "                updateTarget(targetOps,sess)\n",
    "                \n",
    "\n",
    "        #Periodically save the model and print metrics. \n",
    "        if i % save_model_freq == 0 and i != 0:\n",
    "            #saver.save(sess,path+'/model-'+str(i)+'.cptk')\n",
    "            saver.save(sess,trained_model_name, global_step=i)\n",
    "            print (\"Saved Model\")\n",
    "            inter_time = time.time()\n",
    "            print('#Intermediate time to execute: '+ str((inter_time - begin_time)/60) + 'min')\n",
    "        \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            \n",
    "            if i >= pre_train_episodes:\n",
    "                AvgLossList.append(loss)\n",
    "                AvgMainQList.append(np.mean(main_Q))\n",
    "                \n",
    "                #per epoch temporary array to store values per epoch then erase for new epochs\n",
    "                AvgLossListEpochTemp.append(loss)\n",
    "                AvgMainQListEpochTemp.append(np.mean(main_Q))\n",
    "                \n",
    "            print (\"episode \" + str(i+1) + \": \\t\" + str(AvgR)+ \"\\t\" + str(AvgsT)+ \"\\t\"+ str(e))\n",
    "        \n",
    "        if len(NonRandomrList) % summaryLength == 0 and len(NonRandomrList) != 0:\n",
    "            AvgNonRandomR = np.mean(NonRandomrList[-summaryLength:])\n",
    "            AvgNonRandomsT = np.mean(NonRandomsTimeList[-summaryLength:])\n",
    "            AvgNonRandomrList.append(AvgNonRandomR)\n",
    "            AvgNonRandomsTimeList.append(AvgNonRandomsT)\n",
    "                \n",
    "\n",
    "        if i > pre_train_episodes:\n",
    "            if e > endE:\n",
    "                e -= episodeDrop\n",
    "            if i >= pre_exploitation_episodes:\n",
    "                if e > exploitationE:\n",
    "                    e -= episodeDrop2\n",
    "                \n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "        \n",
    "        if len(rList) % summaryEpoch == 0 and len(rList) != 0:\n",
    "            AvgREpoch = np.mean(rList[-summaryEpoch:])\n",
    "            AvgsTEpoch = np.mean(sTimeList[-summaryEpoch:])\n",
    "            AvgEpisodeListEpoch.append(i+1)\n",
    "            AvgrListEpoch.append(AvgREpoch)\n",
    "            AvgsTimeListEpoch.append(AvgsTEpoch)\n",
    "            \n",
    "            #loss\n",
    "            Avgloss = np.mean(AvgLossListEpochTemp)\n",
    "            Avgmain_Q = np.mean(AvgMainQListEpochTemp)\n",
    "            \n",
    "            AvgLossListEpoch.append(Avgloss)\n",
    "            AvgMainQListEpoch.append(np.mean(Avgmain_Q))\n",
    "            # empty arrays\n",
    "            AvgLossListEpochTemp = []\n",
    "            AvgMainQListEpochTemp = []\n",
    "            \n",
    "            \n",
    "    # Do a final save        \n",
    "    #saver.save(sess,path+'/model-'+str(i)+'.cptk')  \n",
    "    saver.save(sess,final_trained_model_name)  \n",
    "\n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Total average reward per non-random episode: \" + str(np.mean(AvgNonRandomrList)))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of Non Random stock returns (Normalized): \" + str(np.mean(NonRandom_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of Non Random stock returns (Real values): \" + str(np.mean(NonRandom_real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of Non Random option returns (Normalized): \" + str(np.mean(NonRandom_option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of Non Random option returns (Real values): \" + str(np.mean(NonRandom_option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(NonRandom_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(NonRandom_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(NonRandom_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(NonRandom_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Total average reward per non-random episode: \" + str(np.mean(AvgNonRandomrList) * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "    \n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingaverage (values):\n",
    "    cum_sum = np.cumsum(values) \n",
    "    div = np.arange(1,len(values) + 1)\n",
    "    sma = np.divide(cum_sum, div)\n",
    "    return sma\n",
    "\n",
    "AvgNonRandomrListMA = movingaverage(AvgNonRandomrList)\n",
    "\n",
    "AvgNonRandomsTimeListMA = movingaverage(AvgNonRandomsTimeList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgNonRandomrList)), AvgNonRandomrList, color='red', label='Episode reward')\n",
    "plt.plot(range(len(AvgNonRandomsTimeList)), AvgNonRandomsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time for non random episodes')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgNonRandomrListMA)), AvgNonRandomrListMA, color='red', label='Episode reward')\n",
    "plt.plot(range(len(AvgNonRandomsTimeListMA)), AvgNonRandomsTimeListMA, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time for non random episodes')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgNonRandomrList)), np.array(AvgNonRandomrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(range(len(AvgNonRandomsTimeList)), AvgNonRandomsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time for non random episodes')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20/ Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgNonRandomrListMA)), np.array(AvgNonRandomrListMA)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(range(len(AvgNonRandomsTimeListMA)), AvgNonRandomsTimeListMA, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time for non random episodes')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20/ Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgNonRandomrList)), np.array(AvgNonRandomrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(range(len(AvgNonRandomsTimeList)), AvgNonRandomsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time for non random episodes')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100/ Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgNonRandomrListMA)), np.array(AvgNonRandomrListMA)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(range(len(AvgNonRandomsTimeListMA)), AvgNonRandomsTimeListMA, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time for non random episodes')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100/ Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgrListMAEpoch = movingaverage(AvgrListEpoch)\n",
    "\n",
    "AvgsTimeListMAEpoch = movingaverage(AvgsTimeListEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgrListEpoch)), AvgrListEpoch, color='red', label='Episode reward')\n",
    "plt.plot(range(len(AvgsTimeListEpoch)), AvgsTimeListEpoch, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics per epoch')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgrListMAEpoch)), AvgrListMAEpoch, color='red', label='Episode reward')\n",
    "plt.plot(range(len(AvgsTimeListMAEpoch)), AvgsTimeListMAEpoch, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics per epoch')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgrListEpoch)), np.array(AvgrListEpoch)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(range(len(AvgsTimeListEpoch)), AvgsTimeListEpoch, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics per epoch')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgrListMAEpoch)), np.array(AvgrListMAEpoch)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(range(len(AvgsTimeListMAEpoch)), AvgsTimeListMAEpoch, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics per epoch')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "# plt.subplot(1,2,1);\n",
    "plt.plot(range(len(AvgrListEpoch)), np.array(AvgrListEpoch)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(range(len(AvgsTimeListEpoch)), AvgsTimeListEpoch, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics per epoch')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "# plt.subplot(1,2,1);\n",
    "plt.plot(range(len(AvgrListMAEpoch)), np.array(AvgrListMAEpoch)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(range(len(AvgsTimeListMAEpoch)), AvgsTimeListMAEpoch, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics per epoch')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgLossListEpoch)), AvgLossListEpoch, color='blue', label='Average batch loss')\n",
    "#plt.plot(range(len(AvgQSellLossListEpoch)), AvgQSellLossListEpoch, color='red', label='Average batch loss for sell')\n",
    "plt.title('Batch loss per Epoch')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Average batch loss')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgMainQListEpoch)), AvgMainQListEpoch, color='blue', label='Average batch Main Q')\n",
    "#plt.plot(range(len(AvgTargetQListEpoch)), AvgTargetQListEpoch, color='red', label='Average batch Target Q')\n",
    "#plt.plot(range(len(AvgMainMaxQListEpoch)), AvgMainMaxQListEpoch, color='green', label='Average batch Main max Q')\n",
    "#plt.plot(range(len(AvgMainHoldQListEpoch)), AvgMainHoldQListEpoch, color='black', label='Average batch Main hold Q')\n",
    "#plt.plot(range(len(AvgMainSellQListEpoch)), AvgMainSellQListEpoch, color='orange', label='Average batch Main sell Q')\n",
    "plt.title('Batch Q per Epoch')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Average batch Q')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgrListMA = movingaverage(AvgrList)\n",
    "\n",
    "AvgsTimeListMA = movingaverage(AvgsTimeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdjSyxKkjME3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrListMA, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeListMA, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "LFX0jsnpgRqI",
    "outputId": "5bd2d8f3-4eff-47be-9bd4-103f41605d0f"
   },
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrListMA)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeListMA, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "QnTu8aKOg8k6",
    "outputId": "4cdc869f-49a3-438b-bfa2-a949c4927432"
   },
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "# plt.subplot(1,2,1);\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "# plt.subplot(1,2,1);\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrListMA)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeListMA, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "dQMHAqTbW4xb",
    "outputId": "767844fb-ab5b-429f-96e1-e81bf7edd632"
   },
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgLossList)), AvgLossList, color='blue', label='Average batch loss')\n",
    "#plt.plot(range(len(AvgQSellLossList)), AvgQSellLossList, color='red', label='Average batch loss for sell')\n",
    "plt.title('Batch loss over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Average batch loss')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(AvgMainQList)), AvgMainQList, color='blue', label='Average batch Main Q')\n",
    "#plt.plot(range(len(AvgTargetQList)), AvgTargetQList, color='red', label='Average batch Target Q')\n",
    "#plt.plot(range(len(AvgMainMaxQList)), AvgMainMaxQList, color='green', label='Average batch Main max Q')\n",
    "#plt.plot(range(len(AvgMainHoldQList)), AvgMainHoldQList, color='black', label='Average batch Main hold Q')\n",
    "#plt.plot(range(len(AvgMainSellQList)), AvgMainSellQList, color='orange', label='Average batch Main sell Q')\n",
    "plt.title('Batch Q over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Average batch Q')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sTimeListMA = movingaverage(sTimeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeListMA)), sTimeListMA, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maJtqlIEdVAN"
   },
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(num_episodes), eList, color='blue', label='Probability of random action')\n",
    "plt.title('Probability of random action over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Probability of random action')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "4n7wbAamjMFB"
   },
   "source": [
    "### Testing the network on train set again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ru9YPlPtjMFD"
   },
   "outputs": [],
   "source": [
    "#e = 0.03 #0.01 #The chance of chosing a random action\n",
    "load_model = True #Whether to load a saved model.\n",
    "is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StockEnv(stocks_train_data, real_stocks_train_data, risk_free_rate, history_t=history_t, option_T=option_T)\n",
    "#max_num_observations = env.max_num_observations\n",
    "num_batch_episodes_per_epoch = env.get_total_num_episodes_per_epoch() // batch_size\n",
    "num_episodes = env.get_total_num_episodes_per_epoch()\n",
    "print('num_batch_episodes_per_epoch: ' + str(num_batch_episodes_per_epoch))\n",
    "print('num_episodes_per_epoch: ' + str(env.get_total_num_episodes_per_epoch()))\n",
    "print('min value of stock: '+str(min(test_data)) + ', max value of stock: '+str(max(test_data)))\n",
    "plt.plot(range(len(test_data)), test_data, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_time = time.time()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mainQN = Qnetwork('main')\n",
    "targetQN = Qnetwork('target')\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []\n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "\n",
    "#num_short_sell = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path) \n",
    "  \n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    if load_model == True:\n",
    "        print ('Loading Model...')\n",
    "        #ckpt = tf.train.get_checkpoint_state(path)\n",
    "        #saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess,final_trained_model_name)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #Reset the recurrent layer's hidden state\n",
    "        state = np.zeros((num_layers, 2, 1, h_size))\n",
    "        while j < max_epLength: \n",
    "\n",
    "            if j == max_epLength - 1 and env.is_episode_finished() == False:\n",
    "                a = 1\n",
    "            else:\n",
    "                a, state1 = sess.run([mainQN.predict,mainQN.rnn_state],\\\n",
    "                        feed_dict={mainQN.scalarInput:[s],mainQN.trainLength:1,\\\n",
    "                                   mainQN.state_in:state,mainQN.batch_size:1,\\\n",
    "                                   mainQN.num_quantiles:num_quantile_samples,\\\n",
    "                                   mainQN.quantiles_shape:num_quantile_samples})\n",
    "                if env.get_time() < build_warm_up_state_t:\n",
    "                    a = 0 #hold\n",
    "                elif env.get_payoff() <= 0:\n",
    "                    a = 0 #hold\n",
    "                    #num_short_sell += 1\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "            \n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            state = state1\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "\n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT))\n",
    "            \n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Number of short selling: \" + str(num_short_sell))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Test\n",
    "# 4000 episodes\n",
    "#Average reward per episode: -0.0004459820152409164%\n",
    "#Time to execute: 1.0273285110791524min\n",
    "\n",
    "# 10000 episodes of training (23000 episodes)\n",
    "#Average reward per episode: -0.0006903839079534307%\n",
    "#Time to execute: 18.210397080580393min\n",
    "\n",
    "# 30000 episodes of training (23000 episodes)\n",
    "#Average reward per episode: -0.0015529333479744412%\n",
    "#Time to execute: 27.645483565330505min\n",
    "\n",
    "# 20000 episodes of training\n",
    "#Average reward per episode: -0.0049713977980137885%\n",
    "#Time to execute: 31.664522131284077min\n",
    "\n",
    "# 100000 episodes of training # architecture 0\n",
    "#Total average reward per episode: -0.0031459276190924593\n",
    "#Time to execute: 27.598839151859284min\n",
    "\n",
    "#20000 episodes training\n",
    "#Total average reward per episode: 0.0024760915583103395\n",
    "#Time to execute: 2.219494903087616min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "4n7wbAamjMFB"
   },
   "source": [
    "### Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ru9YPlPtjMFD"
   },
   "outputs": [],
   "source": [
    "#e = 0.03 #0.01 #The chance of chosing a random action\n",
    "load_model = True #Whether to load a saved model.\n",
    "is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StockEnv(stocks_test_data, real_stocks_test_data, risk_free_rate, history_t=history_t, option_T=option_T)\n",
    "#max_num_observations = env.max_num_observations\n",
    "num_batch_episodes_per_epoch = env.get_total_num_episodes_per_epoch() // batch_size\n",
    "num_episodes = env.get_total_num_episodes_per_epoch()\n",
    "print('num_batch_episodes_per_epoch: ' + str(num_batch_episodes_per_epoch))\n",
    "print('num_episodes_per_epoch: ' + str(env.get_total_num_episodes_per_epoch()))\n",
    "print('min value of stock: '+str(min(test_data)) + ', max value of stock: '+str(max(test_data)))\n",
    "plt.plot(range(len(test_data)), test_data, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_time = time.time()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mainQN = Qnetwork('main')\n",
    "targetQN = Qnetwork('target')\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []\n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "\n",
    "#num_short_sell = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path) \n",
    "  \n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    if load_model == True:\n",
    "        print ('Loading Model...')\n",
    "        #ckpt = tf.train.get_checkpoint_state(path)\n",
    "        #saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess,final_trained_model_name)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #Reset the recurrent layer's hidden state\n",
    "        state = np.zeros((num_layers, 2, 1, h_size))\n",
    "        while j < max_epLength: \n",
    "\n",
    "            if j == max_epLength - 1 and env.is_episode_finished() == False:\n",
    "                a = 1\n",
    "            else:\n",
    "                a, state1 = sess.run([mainQN.predict,mainQN.rnn_state],\\\n",
    "                        feed_dict={mainQN.scalarInput:[s],mainQN.trainLength:1,\\\n",
    "                                   mainQN.state_in:state,mainQN.batch_size:1,\\\n",
    "                                   mainQN.num_quantiles:num_quantile_samples,\\\n",
    "                                   mainQN.quantiles_shape:num_quantile_samples})\n",
    "                if env.get_time() < build_warm_up_state_t:\n",
    "                    a = 0 #hold\n",
    "                elif env.get_payoff() <= 0:\n",
    "                    a = 0 #hold\n",
    "                    #num_short_sell += 1\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "            \n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            state = state1\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "\n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT))\n",
    "            \n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Number of short selling: \" + str(num_short_sell))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Test\n",
    "# 4000 episodes\n",
    "#Average reward per episode: -0.0004459820152409164%\n",
    "#Time to execute: 1.0273285110791524min\n",
    "\n",
    "# 10000 episodes of training (23000 episodes)\n",
    "#Average reward per episode: -0.0006903839079534307%\n",
    "#Time to execute: 18.210397080580393min\n",
    "\n",
    "# 30000 episodes of training (23000 episodes)\n",
    "#Average reward per episode: -0.0015529333479744412%\n",
    "#Time to execute: 27.645483565330505min\n",
    "\n",
    "# 20000 episodes of training\n",
    "#Average reward per episode: -0.0049713977980137885%\n",
    "#Time to execute: 31.664522131284077min\n",
    "\n",
    "# 100000 episodes of training # architecture 0\n",
    "#Total average reward per episode: -0.0031459276190924593\n",
    "#Time to execute: 27.598839151859284min\n",
    "\n",
    "#20000 episodes training\n",
    "#Total average reward per episode: 0.0024760915583103395\n",
    "#Time to execute: 2.219494903087616min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select day of Min price over history [Benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset_new_test() # reset to first observation in data\n",
    "begin_time = time.time()\n",
    "\n",
    "test = 'MinValue' #'Random'\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []\n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "  \n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        \n",
    "        if test == 'Random':\n",
    "          sell_time = random.randint(build_warm_up_state_t,max_epLength - 1)\n",
    "        elif test == 'MinValue' or test == 'Normal':\n",
    "          sell_time = -1\n",
    "        \n",
    "        while j < max_epLength: \n",
    "            if test == 'MinValue':\n",
    "              if env.get_time() >= build_warm_up_state_t and (s[-1] <= min(s) or j == max_epLength - 1) and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "            elif test == 'Random':\n",
    "              if j == sell_time and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "            \n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "            \n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "\n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT)+ '\\t'+ str(e))\n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select day of Max price over history [Benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset_new_test() # reset to first observation in data\n",
    "begin_time = time.time()\n",
    "\n",
    "test = 'MaxValue' #'Random'\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []\n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "  \n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        \n",
    "        if test == 'Random':\n",
    "          sell_time = random.randint(build_warm_up_state_t,max_epLength - 1)\n",
    "        elif test == 'MaxValue' or test == 'Normal':\n",
    "          sell_time = -1\n",
    "        \n",
    "        while j < max_epLength: \n",
    "            if test == 'MaxValue':\n",
    "              if env.get_time() >= build_warm_up_state_t and (s[-1] >= max(s) or j == max_epLength - 1) and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "            elif test == 'Random':\n",
    "              if j == sell_time and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "            \n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "            \n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "\n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT)+ '\\t'+ str(e))\n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4000 episodes\n",
    "# Select state of Max price over history [Benchmark]\n",
    "#Average reward per episode: 0.0005877807673596729%\n",
    "#Time to execute: 0.09947771628697713min\n",
    "\n",
    "# 10000 episodes of training\n",
    "#Average reward per episode: 0.0004938414456624297%\n",
    "#Time to execute: 0.5947879354159037min\n",
    "\n",
    "# 23000 episodes of training\n",
    "#Average reward per episode: 0.0005705326210584273%\n",
    "#Time to execute: 0.8882605234781901min\n",
    "\n",
    "# 23000 episodes\n",
    "#Average reward per episode: 0.0010192164676906157%\n",
    "#Time to execute: 0.5056182742118835min\n",
    "\n",
    "# 23000 episodes\n",
    "#Total average reward per episode: 0.0009947041707927247\n",
    "#Time to execute: 0.6030449350674947min\n",
    "\n",
    "# 23000 episodes\n",
    "#Total average reward per episode: 0.0009401450698119521\n",
    "#Time to execute: 0.9448242465655009min\n",
    "\n",
    "# 23000 episodes\n",
    "#Total average reward per episode: 0.0003986495802468716\n",
    "#Time to execute: 0.5700281739234925min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select random day over history to sell [Benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset_new_test() # reset to first observation in data\n",
    "begin_time = time.time()\n",
    "\n",
    "test = 'Random'\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []\n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "  \n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        \n",
    "        if test == 'Random':\n",
    "          sell_time = random.randint(build_warm_up_state_t,max_epLength - 1)\n",
    "        elif test == 'MaxValue' or test == 'Normal':\n",
    "          sell_time = -1\n",
    "        \n",
    "        while j < max_epLength: \n",
    "            if test == 'MaxValue':\n",
    "              if (s[-1] >= max(s) or j == max_epLength - 1) and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "            elif test == 'Random':\n",
    "              if j == sell_time and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "            \n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "            \n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "        \n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT)+ '\\t'+ str(e))\n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))   \n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4000 episodes\n",
    "# Select random state over history [Benchmark]\n",
    "#Average reward per episode: 0.0015505754102431175%\n",
    "#Time to execute: 0.07682177225748697min\n",
    "\n",
    "#23000 episodes\n",
    "# Average reward per episode: 0.0012894304336377236%\n",
    "#Time to execute: 0.40911168257395425min\n",
    "\n",
    "#23000 episodes\n",
    "#Average reward per episode: 0.002274329489706149%\n",
    "#Time to execute: 0.6566788395245869min\n",
    "\n",
    "#23000 episodes\n",
    "#Average reward per episode: 0.001215791565711024%\n",
    "#Time to execute: 0.36365593671798707min\n",
    "\n",
    "# 23000 episodes\n",
    "#Total average reward per episode: 0.00036678919435973405\n",
    "#Time to execute: 0.4333968202273051min\n",
    "\n",
    "# 23000 episodes\n",
    "#Total average reward per episode: 0.0010562361629312214\n",
    "#Time to execute: 0.6513438741366069min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select last day over history to sell [Benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset_new_test() # reset to first observation in data\n",
    "begin_time = time.time()\n",
    "\n",
    "test = 'LastDay'\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []  \n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        \n",
    "        if test == 'Random':\n",
    "          sell_time = random.randint(build_warm_up_state_t,max_epLength - 1)\n",
    "        elif test == 'LastDay':\n",
    "          sell_time = max_epLength - 1  \n",
    "        elif test == 'MaxValue' or test == 'Normal':\n",
    "          sell_time = -1\n",
    "        \n",
    "        while j < max_epLength: \n",
    "            if test == 'MaxValue':\n",
    "              if (s[-1] >= max(s) or j == max_epLength - 1) and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "            elif test == 'Random' or test == 'LastDay':\n",
    "              if j == sell_time and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "\n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "            \n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT)+ '\\t'+ str(e))\n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))   \n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4600 episodes\n",
    "#Average reward per episode: 0.001350523388538691%\n",
    "#Time to execute: 0.08548296292622884min\n",
    "\n",
    "#23000 episodes\n",
    "#Average reward per episode: 0.002919471458257028%\n",
    "#Time to execute: 0.32947063048680625min\n",
    "\n",
    "# 23000 episodes\n",
    "#Total average reward per episode: 0.003380776061516078\n",
    "#Time to execute: 0.36532406012217206min\n",
    "\n",
    "# 23000 episodes\n",
    "#Total average reward per episode: 0.002987836452606828\n",
    "#Time to execute: 0.5932944019635519min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select first day over history to sell [Benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset_new_test() # reset to first observation in data\n",
    "begin_time = time.time()\n",
    "\n",
    "test = 'FirstDay'\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = [] \n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        \n",
    "        if test == 'Random':\n",
    "          sell_time = random.randint(build_warm_up_state_t,max_epLength - 1)\n",
    "        elif test == 'FirstDay':\n",
    "          sell_time = build_warm_up_state_t \n",
    "        elif test == 'MaxValue' or test == 'Normal':\n",
    "          sell_time = -1\n",
    "        \n",
    "        while j < max_epLength: \n",
    "            if test == 'MaxValue':\n",
    "              if (s[-1] >= max(s) or j == max_epLength - 1) and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "            elif test == 'Random' or test == 'FirstDay':\n",
    "              if j == sell_time and env.get_payoff() > 0:\n",
    "                a = 1\n",
    "              else:\n",
    "                a = 0\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "\n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "            \n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT)+ '\\t'+ str(e))\n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))   \n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"stock_names = ['t.us.txt', 'gm.us.txt', 'cvs.us.txt', 'unh.us.txt',\n",
    "               'xom.us.txt', 'brk-a.us.txt', 'wmt.us.txt', 'mck.us.txt',\n",
    "               'aat.us.txt', 'abc.us.txt', 'acre.us.txt', 'acta.us.txt',\n",
    "               'fn.us.txt','fnb.us.txt', 'ford.us.txt', 'krg.us.txt',\n",
    "              'pay.us.txt', 'peg.us.txt', 'tg.us.txt', 'tis.us.txt',\n",
    "              'nflx.us.txt', 'acn.us.txt', 'utx.us.txt','lmt.us.txt',\n",
    "              'nvda.us.txt', 'avgo.us.txt', 'azn.us.txt', 'tmo.us.txt',\n",
    "               'unp.us.txt', 'lfc.us.txt', 'bhp.us.txt','sny.us.txt',\n",
    "               'bbl.us.txt', 'ry.us.txt', 'asml.us.txt', 'nee.us.txt', \n",
    "              'txn.us.txt', 'gsk.us.txt', 'lly.us.txt', 'nvo.us.txt',\n",
    "               'td.us.txt', 'qcom.us.txt', 'dhr.us.txt', 'chtr.us.txt',\n",
    "               'sbux.us.txt', 'mmm.us.txt', 'axp.us.txt', 'hdb.us.txt',\n",
    "              'csco.us.txt', 'orcl.us.txt', 'c.us.txt']\n",
    "# unvalid stocks: 'kst.us.txt', 'ddt.us.txt', 'lgl.us.txt', 'aac.us.txt','adom.us.txt','acrs.us.txt', 'delt.us.txt', 'lcahu.us.txt', 'tpge.us.txt', 'wear.us.txt'\n",
    "\n",
    "stocks_train_data = []\n",
    "stocks_test_data = []\n",
    "real_stocks_train_data = []\n",
    "real_stocks_test_data = []\n",
    "for stock_name in stock_names:\n",
    "    #train_data, test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    train_data, test_data, real_train_data, real_test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    stocks_train_data.append(train_data)\n",
    "    stocks_test_data.append(test_data)\n",
    "    real_stocks_train_data.append(real_train_data)\n",
    "    real_stocks_test_data.append(real_test_data)\n",
    "    plt.plot(range(len(train_data)), train_data, color='b')\n",
    "    plt.plot(range(len(test_data)), test_data, color='r') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate stocks data\n",
    "stocks_data, _ = GBM(num_seeds, is_training).generate_stock_paths(mu, sigma, 928, num_seeds, is_training)\n",
    "stocks_train_data = []\n",
    "stocks_test_data = []\n",
    "real_stocks_train_data = []\n",
    "real_stocks_test_data = []\n",
    "for stock_data in stocks_data:\n",
    "    #train_data, test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    #train_data, test_data, real_train_data, real_test_data = prepare_company_stock(stock_name, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    train_data, test_data, real_train_data, real_test_data = prepare_company_stock(stock_data, Normalization, Window_Normalization, scriptDirectory, test_data_ratio)\n",
    "    stocks_train_data.append(train_data)\n",
    "    stocks_test_data.append(test_data)\n",
    "    real_stocks_train_data.append(real_train_data)\n",
    "    real_stocks_test_data.append(real_test_data)\n",
    "    plt.plot(range(len(train_data)), train_data, color='b')\n",
    "    plt.plot(range(len(train_data), len(train_data) + len(test_data)), test_data, color='r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StockEnv(stocks_test_data, real_stocks_test_data, risk_free_rate, history_t=history_t, option_T=option_T)\n",
    "#max_num_observations = env.max_num_observations\n",
    "num_batch_episodes_per_epoch = env.get_total_num_episodes_per_epoch() // batch_size\n",
    "num_episodes = env.get_total_num_episodes_per_epoch()\n",
    "print('num_batch_episodes_per_epoch: ' + str(num_batch_episodes_per_epoch))\n",
    "print('num_episodes_per_epoch: ' + str(env.get_total_num_episodes_per_epoch()))\n",
    "print('min value of stock: '+str(min(test_data)) + ', max value of stock: '+str(max(test_data)))\n",
    "plt.plot(range(len(test_data)), test_data, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_time = time.time()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mainQN = Qnetwork('main')\n",
    "targetQN = Qnetwork('target')\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []\n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "\n",
    "#num_short_sell = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path) \n",
    "  \n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    if load_model == True:\n",
    "        print ('Loading Model...')\n",
    "        #ckpt = tf.train.get_checkpoint_state(path)\n",
    "        #saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess,final_trained_model_name)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #Reset the recurrent layer's hidden state\n",
    "        state = np.zeros((num_layers, 2, 1, h_size))\n",
    "        while j < max_epLength: \n",
    "\n",
    "            if j == max_epLength - 1 and env.is_episode_finished() == False:\n",
    "                a = 1\n",
    "            else:\n",
    "                a, state1 = sess.run([mainQN.predict,mainQN.rnn_state],\\\n",
    "                        feed_dict={mainQN.scalarInput:[s],mainQN.trainLength:1,\\\n",
    "                                   mainQN.state_in:state,mainQN.batch_size:1,\\\n",
    "                                   mainQN.num_quantiles:num_quantile_samples,\\\n",
    "                                   mainQN.quantiles_shape:num_quantile_samples})\n",
    "                if env.get_time() < build_warm_up_state_t:\n",
    "                    a = 0 #hold\n",
    "                elif env.get_payoff() <= 0:\n",
    "                    a = 0 #hold\n",
    "                    #num_short_sell += 1\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "            \n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            state = state1\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "\n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT))\n",
    "            \n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Number of short selling: \" + str(num_short_sell))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Test\n",
    "# 4000 episodes\n",
    "#Average reward per episode: -0.0004459820152409164%\n",
    "#Time to execute: 1.0273285110791524min\n",
    "\n",
    "# 10000 episodes of training (23000 episodes)\n",
    "#Average reward per episode: -0.0006903839079534307%\n",
    "#Time to execute: 18.210397080580393min\n",
    "\n",
    "# 30000 episodes of training (23000 episodes)\n",
    "#Average reward per episode: -0.0015529333479744412%\n",
    "#Time to execute: 27.645483565330505min\n",
    "\n",
    "# 20000 episodes of training\n",
    "#Average reward per episode: -0.0049713977980137885%\n",
    "#Time to execute: 31.664522131284077min\n",
    "\n",
    "# 100000 episodes of training # architecture 0\n",
    "#Total average reward per episode: -0.0031459276190924593\n",
    "#Time to execute: 27.598839151859284min\n",
    "\n",
    "#20000 episodes training\n",
    "#Total average reward per episode: 0.0024760915583103395\n",
    "#Time to execute: 2.219494903087616min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StockEnv(stocks_train_data, real_stocks_train_data, risk_free_rate, history_t=history_t, option_T=option_T)\n",
    "#max_num_observations = env.max_num_observations\n",
    "num_batch_episodes_per_epoch = env.get_total_num_episodes_per_epoch() // batch_size\n",
    "num_episodes = env.get_total_num_episodes_per_epoch()\n",
    "print('num_batch_episodes_per_epoch: ' + str(num_batch_episodes_per_epoch))\n",
    "print('num_episodes_per_epoch: ' + str(env.get_total_num_episodes_per_epoch()))\n",
    "print('min value of stock: '+str(min(train_data)) + ', max value of stock: '+str(max(train_data)))\n",
    "plt.plot(range(len(train_data)), train_data, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_time = time.time()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mainQN = Qnetwork('main')\n",
    "targetQN = Qnetwork('target')\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "sTimeList = [] # sell time list\n",
    "\n",
    "percentage_rList = []\n",
    "real_percentage_rList = []\n",
    "\n",
    "option_percentage_rList = []\n",
    "option_real_percentage_rList = []\n",
    "\n",
    "# Average metrics per 100 episodes\n",
    "AvgEpisodeList = []\n",
    "AvgrList = []\n",
    "AvgsTimeList = []\n",
    "maxPossiblerList = []\n",
    "\n",
    "maxPossibleP_returnList = []\n",
    "maxPossibleR_P_returnList = []\n",
    "\n",
    "maxPossibleOptionP_returnList = []\n",
    "maxPossibleOptionR_P_returnList = []\n",
    "\n",
    "#num_short_sell = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path) \n",
    "  \n",
    "\n",
    "with tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    set_seed(seed)\n",
    "    if load_model == True:\n",
    "        print ('Loading Model...')\n",
    "        #ckpt = tf.train.get_checkpoint_state(path)\n",
    "        #saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess,final_trained_model_name)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        #Reset environment and get first new observation\n",
    "        sP = env.reset()\n",
    "        s = processState(sP, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #Reset the recurrent layer's hidden state\n",
    "        state = np.zeros((num_layers, 2, 1, h_size))\n",
    "        while j < max_epLength: \n",
    "\n",
    "            if j == max_epLength - 1 and env.is_episode_finished() == False:\n",
    "                a = 1\n",
    "            else:\n",
    "                a, state1 = sess.run([mainQN.predict,mainQN.rnn_state],\\\n",
    "                        feed_dict={mainQN.scalarInput:[s],mainQN.trainLength:1,\\\n",
    "                                   mainQN.state_in:state,mainQN.batch_size:1,\\\n",
    "                                   mainQN.num_quantiles:num_quantile_samples,\\\n",
    "                                   mainQN.quantiles_shape:num_quantile_samples})\n",
    "                if env.get_time() < build_warm_up_state_t:\n",
    "                    a = 0 #hold\n",
    "                elif env.get_payoff() <= 0:\n",
    "                    a = 0 #hold\n",
    "                    #num_short_sell += 1\n",
    "                \n",
    "            s1P,r,d = env.step(a)\n",
    "            \n",
    "            s1 = processState(s1P, input_size)\n",
    "            \n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5])) # store experience\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            sP = s1P\n",
    "            state = state1\n",
    "            j+=1 # episode length till selling or reaching last day of option\n",
    "\n",
    "            if env.is_episode_finished():\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        sTimeList.append(env.get_sell_time() + 1)\n",
    "        #maxPossiblerList.append(env.get_best_possible_reward())\n",
    "        #best_reward, percentage_return, real_percentage_return = env.get_best_possible_reward()\n",
    "        best_reward, stock_percentage_return, option_percentage_return, stock_real_percentage_return,\\\n",
    "        option_real_percentage_return = env.get_best_possible_reward()\n",
    "        \n",
    "        maxPossiblerList.append(best_reward)\n",
    "        maxPossibleP_returnList.append(stock_percentage_return)\n",
    "        maxPossibleR_P_returnList.append(stock_real_percentage_return)\n",
    "        maxPossibleOptionP_returnList.append(option_percentage_return)\n",
    "        maxPossibleOptionR_P_returnList.append(option_real_percentage_return)\n",
    "        #real_percentage_rList.append(env.get_real_percentage_return())\n",
    "        stock_percentage_return, option_percentage_return = env.get_percentage_return()\n",
    "        percentage_rList.append(stock_percentage_return)\n",
    "        option_percentage_rList.append(option_percentage_return)\n",
    "        stock_percentage_return, option_percentage_return = env.get_real_percentage_return()\n",
    "        real_percentage_rList.append(stock_percentage_return)\n",
    "        option_real_percentage_rList.append(option_percentage_return)\n",
    "\n",
    "        #Periodically print metrics. \n",
    "        if len(rList) % summaryLength == 0 and len(rList) != 0:\n",
    "            AvgR = np.mean(rList[-summaryLength:])\n",
    "            AvgsT = np.mean(sTimeList[-summaryLength:])\n",
    "            AvgEpisodeList.append(i+1)\n",
    "            AvgrList.append(AvgR)\n",
    "            AvgsTimeList.append(AvgsT)\n",
    "            print('episode ' + str(i+1) + ': \\t' + str(AvgR) \n",
    "                  + '\\t' + str(AvgsT))\n",
    "            \n",
    "        if len(rList) % summaryAverageReward == 0 and len(rList) != 0:\n",
    "            print (\"#Average reward per episode \" + str(i+1) + \": \" + str(sum(rList)/len(rList)))\n",
    "                \n",
    "option_percentage_rList = [value for value in option_percentage_rList if not math.isnan(value)]\n",
    "maxPossibleOptionP_returnList = [value for value in maxPossibleOptionP_returnList if not math.isnan(value)]\n",
    "\n",
    "print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes))\n",
    "\n",
    "print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 90%: \" + str(env.getConfidenceInterval(rList)))\n",
    "\n",
    "print (\"#Confidence Interval with prob of 95%: \" + str(env.getConfidenceInterval95(rList)))\n",
    "\n",
    "print (\"#Sell time entropy: \" + str(env.getEntropy(sTimeList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Normalized): \" + str(np.mean(percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of stock returns (Real values): \" + str(np.mean(real_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Normalized): \" + str(np.mean(option_percentage_rList)))\n",
    "\n",
    "print (\"#Percentage of option returns (Real values): \" + str(np.mean(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Max possible average stock percentage return per episode: \" + str(np.mean(maxPossibleP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real stock percentage return per episode: \" + str(np.mean(maxPossibleR_P_returnList)))\n",
    "\n",
    "print (\"#Max possible average option percentage return per episode: \" + str(np.mean(maxPossibleOptionP_returnList)))\n",
    "\n",
    "print (\"#Max possible average real option percentage return per episode: \" + str(np.mean(maxPossibleOptionR_P_returnList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 90%: \" + str(env.getConfidenceInterval(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Normalized) with prob of 95%: \" + str(env.getConfidenceInterval95(option_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 90%: \" + str(env.getConfidenceInterval(option_real_percentage_rList)))\n",
    "\n",
    "print (\"#Confidence Interval of Percentage of option returns (Real values) with prob of 95%: \" + str(env.getConfidenceInterval95(option_real_percentage_rList)))\n",
    "\n",
    "#print (\"#Number of short selling: \" + str(num_short_sell))\n",
    "\n",
    "#print (\"#Discounted rewards:\")\n",
    "\n",
    "#print (\"#Total average reward per episode: \" + str(sum(rList)/num_episodes * discount_factor))\n",
    "\n",
    "#print (\"#Max possible average reward per episode: \" + str(np.mean(maxPossiblerList) * discount_factor))\n",
    "\n",
    "end_time = time.time()\n",
    "print('#Time to execute: '+ str((end_time - begin_time)/60) + 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Test\n",
    "# 4000 episodes\n",
    "#Average reward per episode: -0.0004459820152409164%\n",
    "#Time to execute: 1.0273285110791524min\n",
    "\n",
    "# 10000 episodes of training (23000 episodes)\n",
    "#Average reward per episode: -0.0006903839079534307%\n",
    "#Time to execute: 18.210397080580393min\n",
    "\n",
    "# 30000 episodes of training (23000 episodes)\n",
    "#Average reward per episode: -0.0015529333479744412%\n",
    "#Time to execute: 27.645483565330505min\n",
    "\n",
    "# 20000 episodes of training\n",
    "#Average reward per episode: -0.0049713977980137885%\n",
    "#Time to execute: 31.664522131284077min\n",
    "\n",
    "# 100000 episodes of training # architecture 0\n",
    "#Total average reward per episode: -0.0031459276190924593\n",
    "#Time to execute: 27.598839151859284min\n",
    "\n",
    "#20000 episodes training\n",
    "#Total average reward per episode: 0.0024760915583103395\n",
    "#Time to execute: 2.219494903087616min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, AvgrList, color='red', label='Episode reward')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*20, color='red', label='Episode reward x20')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x20 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(AvgEpisodeList, np.array(AvgrList)*100, color='red', label='Episode reward x100')\n",
    "plt.plot(AvgEpisodeList, AvgsTimeList, color='blue', label='Episode Length')\n",
    "plt.title('Average metrics over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Reward x100 / Ep Length')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show evolution of metrics over time\n",
    "plt.figure(figsize=(15, 10));\n",
    "plt.plot(range(len(sTimeList)), sTimeList, color='blue', label='Sell time')\n",
    "plt.title('Sell time over time')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Sell time')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print size of remaining objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "#sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "list_objects = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "#print(list_objects)\n",
    "for x,y in list_objects:\n",
    "    print(str(x)+\": \"+str(y))\n",
    "    del x"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Conv_Stock_cudnn_Stock_Deep_Recurrent_Q_Network.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
